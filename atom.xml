<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Arvense</title>
  
  
  <link href="/blog/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/blog/"/>
  <updated>2020-07-21T03:48:18.485Z</updated>
  <id>http://yoursite.com/blog/</id>
  
  <author>
    <name>Arvense</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>join中on和where的区别</title>
    <link href="http://yoursite.com/blog/2020/07/21/7-21%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/blog/2020/07/21/7-21技术笔记/</id>
    <published>2020-07-21T02:36:35.000Z</published>
    <updated>2020-07-21T03:48:18.485Z</updated>
    
    <content type="html"><![CDATA[<p>两个表在，join时，首先做一个笛卡尔积，on后面的条件是对这个笛卡尔积做一个过滤形成一张临时表，如果没有where就直接返回结果，如果有where就对上一步的临时表再进行过滤。</p><p>在使用left jion时，on和where条件的区别如下：</p><p>1、on条件是在生成临时表时使用的条件，它不管on中的条件是否为真，都会返回左边表中的记录。</p><p>2、where条件是在临时表生成好后，再对临时表进行过滤的条件。这时已经没有left join的含义（必须返回左边表的记录）了，条件不为真的就全部过滤掉。</p><p>从这来看，从结果的角度，对于inner join来说，条件在where还是on没有区别，只是在哪一层过滤而已。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> orders <span class="keyword">inner</span> <span class="keyword">join</span> sub_orders <span class="keyword">on</span> orders.order_id = sub_orders.order_id <span class="keyword">and</span> orders.order_id=<span class="number">6851559448792635150</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> orders <span class="keyword">inner</span> <span class="keyword">join</span> sub_orders <span class="keyword">on</span> orders.order_id = sub_orders.order_id <span class="keyword">where</span> orders.order_id=<span class="number">6851559448792635150</span></span><br></pre></td></tr></table></figure><p>对于left join就不一样了，因为left join要留下左表所有的数据。对于left join，on是连接右表的条件，而不是查找左边的条件。也就是说，on 后面的and，筛不了左表。比如这么写</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> sub_orders <span class="keyword">left</span> <span class="keyword">join</span> orders <span class="keyword">on</span> (orders.order_id = sub_orders.order_id <span class="keyword">and</span> sub_orders.order_id=<span class="number">6843974166572439310</span>)</span><br></pre></td></tr></table></figure><p>会返回左表所有数据，右表只有order_id=6843974166572439310的数据，其他全是null。</p><p>如果条件写在where里</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> sub_orders <span class="keyword">left</span> <span class="keyword">join</span> orders <span class="keyword">on</span> orders.order_id = sub_orders.order_id <span class="keyword">where</span> orders.order_id=<span class="number">6843974166572439310</span></span><br></pre></td></tr></table></figure><p>可获得想要的结果。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;两个表在，join时，首先做一个笛卡尔积，on后面的条件是对这个笛卡尔积做一个过滤形成一张临时表，如果没有where就直接返回结果，如果有where就对上一步的临时表再进行过滤。&lt;/p&gt;
&lt;p&gt;在使用left jion时，on和where条件的区别如下：&lt;/p&gt;
&lt;p&gt;1、
      
    
    </summary>
    
      <category term="技术" scheme="http://yoursite.com/blog/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="数据库" scheme="http://yoursite.com/blog/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>undo日志</title>
    <link href="http://yoursite.com/blog/2020/06/08/6-8%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/blog/2020/06/08/6-8技术笔记/</id>
    <published>2020-06-08T07:14:53.000Z</published>
    <updated>2020-06-08T08:06:34.471Z</updated>
    
    <content type="html"><![CDATA[<h2 id="undo-log"><a href="#undo-log" class="headerlink" title="undo log"></a>undo log</h2><h3 id="产生原因"><a href="#产生原因" class="headerlink" title="产生原因"></a>产生原因</h3><p><strong>undo log的意义有两个，保证原子性，mvcc</strong></p><p>事务执行过程中，系统异常或者手动callback，都要求数据回滚到之前的版本，解决方法看起来很简单，就是记录之前的版本，即undo log.</p><h3 id="事务id"><a href="#事务id" class="headerlink" title="事务id"></a>事务id</h3><p>如果某个事务执行过程中对某个表执行了增、删、改操作，那么InnoDB存储引擎就会给它分配一个独一无二的<code>事务id</code></p><p>服务器会在内存中维护一个全局变量，每当需要为某个事务分配一个<code>事务id</code>时，就会把该变量的值当作<code>事务id</code>分配给该事务，并且把该变量自增1。</p><p>数据行有一隐藏列，即事务id，修改了它的事务的id。</p><h3 id="日志格式"><a href="#日志格式" class="headerlink" title="日志格式"></a>日志格式</h3><p>undolog，如果做成物理日志，并不合理，因为涉及页比较多。所以做法是反向的逻辑日志。</p><h2 id="mvcc"><a href="#mvcc" class="headerlink" title="mvcc"></a>mvcc</h2><p>每行数据有两个隐藏列，trx_id和roll_pointer。</p><ul><li><p>trx_id：每次一个事务对某条聚簇索引记录进行改动时，都会把该事务的<code>事务id</code>赋值给trx_id隐藏列。</p></li><li><p>roll_pointer：每次对某条聚簇索引记录进行改动时，都会把旧的版本写入到undo日志中，然后这个隐藏列就相当于一个指针，可以通过它来找到该记录修改前的信息。</p></li></ul><p>这两个隐藏列结合undo log，就完成了mvcc。</p><p>因为他们把undolog链了起来。</p><p><img src="https://s1.ax1x.com/2020/06/08/tfAXaq.png" alt="dd"></p><h3 id="读已提交"><a href="#读已提交" class="headerlink" title="读已提交"></a>读已提交</h3><p>有事务id为100和200两个事务，修改了同一行数据，此时他们都还未提交。这时有个select语句，应该读到最之前的那条数据。</p><p>从系统变量中读取，当前活跃的最小的事务id100，和最大的事务id200。顺着链表读数据，凡事数据行的事务id，在这个范围内的，都是还未提交的事务对其的修改，都不该读到，知道读到第一个小于活跃的最小的事务id的数据行。</p><p>即抛弃200，200，100，100，四条记录，拿到最后一条80的记录。</p><p>然后100这事务提交了，此时再读，最小的事务id已经变成200了。只抛弃200，200两条数据，拿得到100提交的数据。</p><h3 id="可重复读"><a href="#可重复读" class="headerlink" title="可重复读"></a>可重复读</h3><p>可重复读的区别在于，事务中最小的事务id不变的，这样别的事务提交了，也读不到它提交的数据。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;undo-log&quot;&gt;&lt;a href=&quot;#undo-log&quot; class=&quot;headerlink&quot; title=&quot;undo log&quot;&gt;&lt;/a&gt;undo log&lt;/h2&gt;&lt;h3 id=&quot;产生原因&quot;&gt;&lt;a href=&quot;#产生原因&quot; class=&quot;headerlink&quot; 
      
    
    </summary>
    
      <category term="技术" scheme="http://yoursite.com/blog/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="数据库" scheme="http://yoursite.com/blog/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>redo日志</title>
    <link href="http://yoursite.com/blog/2020/06/02/6-2%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/blog/2020/06/02/6-2技术笔记/</id>
    <published>2020-06-02T08:03:42.000Z</published>
    <updated>2020-06-08T07:18:47.244Z</updated>
    
    <content type="html"><![CDATA[<h2 id="物理日志和逻辑日志"><a href="#物理日志和逻辑日志" class="headerlink" title="物理日志和逻辑日志"></a>物理日志和逻辑日志</h2><p>mysql数据最终落盘是分页的，undo log和bin log是并没有记录最终落盘的数据，而是执行的操作，增删改，所以是逻辑日志。redo log记录的纬度不是操作，而是最终落盘的数据，是物理日志。</p><h2 id="redo-log"><a href="#redo-log" class="headerlink" title="redo log"></a>redo log</h2><h3 id="产生原因"><a href="#产生原因" class="headerlink" title="产生原因"></a>产生原因</h3><p> <strong>redo log的意义有两个，保证持久性，提高性能</strong></p><p>对事务的操作，并不是直接落盘的，而是先到缓冲区，即页缓存上的，为了保证持久性，即重启等操作后，缓冲区清空，已提交的事务只在缓冲区，没有落盘。</p><p>最简单的办法是，每当有事务提交，在事务提交完成之前把该事务所修改的所有页面都刷新到磁盘。但是有两个问题。</p><ul><li><p>刷新一个完整的数据页太浪费了</p><p>有时候我们仅仅修改了某个页面中的一个字节，但是我们知道在<code>InnoDB</code>中是以页为单位来进行磁盘IO的，也就是说我们在该事务提交时不得不将一个完整的页面从内存中刷新到磁盘，我们又知道一个页面默认是16KB大小，只修改一个字节就要刷新16KB的数据到磁盘上显然是太浪费了。</p></li><li><p>随机IO刷起来比较慢</p><p>一个事务可能包含很多语句，即使是一条语句也可能修改许多页面，倒霉催的是该事务修改的这些页面可能并不相邻，这就意味着在将某个事务修改的<code>Buffer Pool</code>中的页面刷新到磁盘时，需要进行很多的随机IO，随机IO比顺序IO要慢。</p></li></ul><p>更好解决的方法是redo log。即事务提交时，把修改的字段写入一个文件中，比如重启恢复时，按照该文件恢复即可。</p><h3 id="redo日志格式"><a href="#redo日志格式" class="headerlink" title="redo日志格式"></a>redo日志格式</h3><p>如果简单的想，记录一下在某个页面的某个偏移量处修改了几个字节的值，具体被修改的内容是啥就好了。那么redo日志只需要类型、表空间ID、页号、偏移量、修改的内容长度，修改的内容即可。（实际上修改的内容长度被隐含在类型中，比如MLOG_8BYTE表示在页面的某个偏移量处写入8个字节的redo日志类型。）</p><p>但实际上，很多时候没这么简单，因为修改一条数据，会涉及多页的变化，比如插入数据导致页分裂，更新字段有索引要更新索引的b+树，目录页的统计信息会改变。</p><p>解决的方式是逻辑的方式，即redo类型是插入/删除，物理层面看，这些日志都指明了对哪个表空间的哪个页进行了修改。但是逻辑层面看，在系统崩溃重启时，并不能直接根据这些日志里的记载，将页面内的某个偏移量处恢复成某个数据，而是需要调用一些事先准备好的函数，执行完这些函数后才可以将页面恢复成系统崩溃前的样子。</p><h3 id="redo日志刷盘时机"><a href="#redo日志刷盘时机" class="headerlink" title="redo日志刷盘时机"></a>redo日志刷盘时机</h3><p>1.发出commit动作时。已经说明过，commit发出后是否刷日志由变量 innodb_flush_log_at_trx_commit 控制。</p><p>2.每秒刷一次。这个刷日志的频率由变量 innodb_flush_log_at_timeout 值决定，默认是1秒。要注意，这个刷日志频率和commit动作无关。</p><p>3.当log buffer中已经使用的内存超过一半时。</p><p>4.当有checkpoint时，checkpoint在一定程度上代表了刷到磁盘时日志所处的LSN位置。</p><h3 id="LSN"><a href="#LSN" class="headerlink" title="LSN"></a>LSN</h3><p>LSN称为日志的逻辑序列号(log sequence number)，在innodb存储引擎中，lsn占用8个字节。LSN的值会随着日志的写入而逐渐增大。</p><p>LSN不仅存在于redo log中，还存在于数据页中，在每个数据页的头部，有一个<em>fil_page_lsn</em>记录了当前页最终的LSN值是多少。通过数据页中的LSN值和redo log中的LSN值比较，如果页中的LSN值小于redo log中LSN值，则表示数据丢失了一部分，这时候可以通过redo log的记录来恢复到redo log中记录的LSN值时的状态。</p><p>flushed_to_disk_lsn表示刷新到磁盘中的redo日志量的全局变量</p><p>当有新的redo日志写入到log buffer时，首先lsn的值会增长，但flushed_to_disk_lsn不变，随后随着不断有log buffer中的日志被刷新到磁盘上，flushed_to_disk_lsn`的值也跟着增长。如果两者的值相同时，说明log buffer中的所有redo日志都已经刷新到磁盘中了。</p><h3 id="checkpoint"><a href="#checkpoint" class="headerlink" title="checkpoint"></a>checkpoint</h3><p>如果重做日志可以无限地增大，同时缓冲池也足够大，那么是不需要将缓冲池中页的新版本刷新回磁盘。因为当发生宕机时，完全可以通过重做日志来恢复整个数据库系统中的数据到宕机发生的时刻。</p><p>实际上不存在的，第一redolog越写越多后来没地方写了，第二缓冲区不少数据已经刷回了磁盘，这些数据不用再刷盘。所以需要checkPoint。</p><p>Checkpoint发生的时间、条件及脏页的选择等都非常复杂。而Checkpoint所做的事情无外乎是将缓冲池中的脏页刷回到磁盘，不同之处在于每次刷新多少页到磁盘，每次从哪里取脏页，以及什么时间触发Checkpoint。</p><p>Checkpoint分为两种Sharp Checkpoint、Fuzzy Checkpoint，前者全量刷脏页，后者刷一部分的，全量只发生在数据库关闭时，不然会很影响性能。</p><p>检查点触发想来也就这么几种，定时出发， 脏页比例达到一定值时触发。</p><p>checkpoint对应LSN.</p><p>Innodb每次取最老的modified page(last checkpoint)对应的LSN，再将此脏页的LSN作为Checkpoint点记录到日志文件，意思就是“此LSN之前的LSN对应的日志和数据都已经flush到redo log</p><p>当mysql crash的时候，Innodb扫描redo log，从last checkpoint开始apply redo log到buffer pool，直到last checkpoint对应的LSN等于Log flushed up to对应的LSN，则恢复完成</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;物理日志和逻辑日志&quot;&gt;&lt;a href=&quot;#物理日志和逻辑日志&quot; class=&quot;headerlink&quot; title=&quot;物理日志和逻辑日志&quot;&gt;&lt;/a&gt;物理日志和逻辑日志&lt;/h2&gt;&lt;p&gt;mysql数据最终落盘是分页的，undo log和bin log是并没有记录最终落盘
      
    
    </summary>
    
      <category term="技术" scheme="http://yoursite.com/blog/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="数据库" scheme="http://yoursite.com/blog/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>&lt;form&gt; 标签的 enctype</title>
    <link href="http://yoursite.com/blog/2020/06/01/6-1%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/blog/2020/06/01/6-1技术笔记/</id>
    <published>2020-06-01T08:43:41.000Z</published>
    <updated>2020-06-01T08:56:29.558Z</updated>
    
    <content type="html"><![CDATA[<table><thead><tr><th>值</th><th>描述</th></tr></thead><tbody><tr><td>application/x-www-form-urlencoded</td><td>在发送前编码所有字符（默认）</td></tr><tr><td>multipart/form-data</td><td>不对字符编码。数据通过二进制的形式传送。</td></tr><tr><td>text/plain</td><td>空格转换为 “+” 加号，但不对特殊字符编码。</td></tr></tbody></table><p>在Form元素的语法中，EncType表明提交数据的格式 用 Enctype 属性指定将数据回发到服务器时浏览器使用的编码类型。 例如： application/x-www-form-urlencoded： 窗体数据被编码为名称/值对。这是标准的编码格式。 multipart/form-data： 窗体数据被编码为一条消息，页上的每个控件对应消息中的一个部分，这个一般文件上传时用。浏览器会把整个表单以控件为单位分割，并为每个部分加上Content-Disposition(form-data或者file),Content-Type(默认为text/plain),name(控件name)等信息，并加上分割符(boundary)。</p><p> text/plain： 窗体数据以纯文本形式进行编码，其中不含任何控件或格式字符</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;值&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;application/x-www-form-urlencoded&lt;/td&gt;
&lt;td&gt;在发送前编码所有字符（默认）&lt;/td&gt;
&lt;
      
    
    </summary>
    
      <category term="技术" scheme="http://yoursite.com/blog/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="计算机网络" scheme="http://yoursite.com/blog/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>exist</title>
    <link href="http://yoursite.com/blog/2020/05/11/5-11%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/blog/2020/05/11/5-11技术笔记/</id>
    <published>2020-05-11T03:04:16.000Z</published>
    <updated>2020-05-11T04:00:22.071Z</updated>
    
    <content type="html"><![CDATA[<h3 id="选了语文没选英语的"><a href="#选了语文没选英语的" class="headerlink" title="选了语文没选英语的"></a>选了语文没选英语的</h3><p>exist语法可以理解为：将主查询的数据，放到子查询中做条件验证，根据验证结果（TRUE 或 FALSE）来决定主查询的数据结果是否得以保留。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">distinct</span> uid <span class="keyword">from</span> qtest <span class="keyword">as</span> T</span><br><span class="line"><span class="keyword">where</span> <span class="keyword">exists</span> (<span class="keyword">select</span> <span class="number">1</span> <span class="keyword">from</span> qtest <span class="keyword">where</span> subject=<span class="string">"数学"</span> <span class="keyword">and</span> T.uid=uid)</span><br><span class="line"><span class="keyword">and</span> <span class="keyword">not</span> <span class="keyword">exists</span> (<span class="keyword">select</span> <span class="number">1</span> <span class="keyword">from</span> qtest <span class="keyword">where</span> subject=<span class="string">"英语"</span> <span class="keyword">and</span> T.uid=uid)</span><br></pre></td></tr></table></figure><h3 id="同时选了两科的"><a href="#同时选了两科的" class="headerlink" title="同时选了两科的"></a>同时选了两科的</h3><p>其实group by 后的having 的字段，不一定得是选的字段</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span>  <span class="keyword">name</span> <span class="keyword">from</span> student <span class="keyword">where</span> uid <span class="keyword">in</span>(</span><br><span class="line"><span class="keyword">select</span> uid <span class="keyword">from</span> score <span class="keyword">group</span> <span class="keyword">by</span> uid </span><br><span class="line"><span class="keyword">having</span> <span class="keyword">count</span>(<span class="keyword">sid</span>)=<span class="number">3</span>)</span><br></pre></td></tr></table></figure><p>考察下里面的自查询</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> uid <span class="keyword">from</span> score <span class="keyword">group</span> <span class="keyword">by</span> <span class="keyword">name</span></span><br><span class="line"> <span class="keyword">having</span> <span class="keyword">count</span>(<span class="keyword">sid</span>)=<span class="number">3</span></span><br></pre></td></tr></table></figure><p>其实和这也是一样的</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> uid,<span class="keyword">count</span>(<span class="keyword">sid</span>)=<span class="number">3</span> <span class="keyword">as</span> <span class="keyword">num</span> <span class="keyword">from</span> score <span class="keyword">group</span> <span class="keyword">by</span> <span class="keyword">name</span></span><br><span class="line"> <span class="keyword">having</span> <span class="keyword">num</span>=<span class="number">3</span></span><br></pre></td></tr></table></figure><p>但是子查询里只能有一列</p><p>其实这里count啥没区别，因为是按uid来group by的。这里uid和sid是联合unique的，所以按uid行数就是该生科目数。</p><p>如果不是联合unique的。比如带上补考的。</p><h3 id="有课补考过"><a href="#有课补考过" class="headerlink" title="有课补考过"></a>有课补考过</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">name</span> <span class="keyword">from</span> student</span><br><span class="line"><span class="keyword">where</span> uid <span class="keyword">in</span>(</span><br><span class="line"><span class="keyword">select</span> <span class="keyword">distinct</span> uid <span class="keyword">from</span> score</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> uid,<span class="keyword">sid</span></span><br><span class="line"><span class="keyword">having</span> <span class="keyword">count</span>(*)=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;选了语文没选英语的&quot;&gt;&lt;a href=&quot;#选了语文没选英语的&quot; class=&quot;headerlink&quot; title=&quot;选了语文没选英语的&quot;&gt;&lt;/a&gt;选了语文没选英语的&lt;/h3&gt;&lt;p&gt;exist语法可以理解为：将主查询的数据，放到子查询中做条件验证，根据验证结果（TR
      
    
    </summary>
    
      <category term="技术" scheme="http://yoursite.com/blog/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="数据库" scheme="http://yoursite.com/blog/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>不及格，优秀，前三名sql</title>
    <link href="http://yoursite.com/blog/2020/05/06/5-6%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>http://yoursite.com/blog/2020/05/06/5-6技术笔记-1/</id>
    <published>2020-05-06T07:37:13.000Z</published>
    <updated>2020-05-11T03:25:59.582Z</updated>
    
    <content type="html"><![CDATA[<h3 id="不及格的学生"><a href="#不及格的学生" class="headerlink" title="不及格的学生"></a>不及格的学生</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> uid,<span class="keyword">name</span>,<span class="keyword">avg</span>(score) <span class="keyword">as</span> avg_score <span class="keyword">from</span> qtest </span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> uid <span class="keyword">having</span> avg_score&lt;<span class="number">60</span></span><br></pre></td></tr></table></figure><h3 id="每门课成绩都不低于80的学生"><a href="#每门课成绩都不低于80的学生" class="headerlink" title="每门课成绩都不低于80的学生"></a>每门课成绩都不低于80的学生</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">distinct</span> uid </span><br><span class="line"><span class="keyword">from</span> qtest</span><br><span class="line"><span class="keyword">where</span> uid <span class="keyword">not</span> <span class="keyword">in</span> (</span><br><span class="line"><span class="keyword">select</span> uid </span><br><span class="line"><span class="keyword">from</span> qtest </span><br><span class="line"><span class="keyword">where</span> score&lt;<span class="number">80</span>)</span><br></pre></td></tr></table></figure><h3 id="总成绩前三名"><a href="#总成绩前三名" class="headerlink" title="总成绩前三名"></a>总成绩前三名</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span>  uid,<span class="keyword">sum</span>(score) <span class="keyword">as</span> sum_score <span class="keyword">from</span> qtest</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> uid</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> sum_score <span class="keyword">desc</span> <span class="keyword">limit</span> <span class="number">3</span></span><br></pre></td></tr></table></figure><h3 id="语文第二名"><a href="#语文第二名" class="headerlink" title="语文第二名"></a>语文第二名</h3><p>先查第三名语文的分数</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> score <span class="keyword">from</span> qtest <span class="keyword">where</span> subject = <span class="string">"语文"</span> <span class="keyword">order</span> <span class="keyword">by</span> score <span class="keyword">desc</span> <span class="keyword">limit</span> <span class="number">2</span>,<span class="number">1</span>;</span><br></pre></td></tr></table></figure><p>再找人</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">name</span>,uid <span class="keyword">from</span> qtest</span><br><span class="line"><span class="keyword">where</span> subject = <span class="string">"语文"</span> <span class="keyword">and</span> score=(</span><br><span class="line"><span class="keyword">select</span> score <span class="keyword">from</span> qtest <span class="keyword">where</span> subject = <span class="string">"语文"</span> <span class="keyword">order</span> <span class="keyword">by</span> score <span class="keyword">desc</span> <span class="keyword">limit</span> <span class="number">2</span>,<span class="number">1</span>)</span><br></pre></td></tr></table></figure><h3 id="各门功课前三"><a href="#各门功课前三" class="headerlink" title="各门功课前三"></a>各门功课前三</h3><p>相同思路，先找第三名分数，再找人</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> qtest <span class="keyword">as</span> x <span class="keyword">where</span> score &gt;</span><br><span class="line">(<span class="keyword">select</span> score <span class="keyword">from</span> qtest <span class="keyword">where</span> subject=x.subject <span class="keyword">ORDER</span> <span class="keyword">BY</span> score <span class="keyword">desc</span> <span class="keyword">limit</span> <span class="number">2</span>,<span class="number">1</span>);</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;不及格的学生&quot;&gt;&lt;a href=&quot;#不及格的学生&quot; class=&quot;headerlink&quot; title=&quot;不及格的学生&quot;&gt;&lt;/a&gt;不及格的学生&lt;/h3&gt;&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutte
      
    
    </summary>
    
    
      <category term="数据库" scheme="http://yoursite.com/blog/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>重名，前三名sql</title>
    <link href="http://yoursite.com/blog/2020/04/28/4-28%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>http://yoursite.com/blog/2020/04/28/4-28技术笔记-1/</id>
    <published>2020-04-28T10:27:10.000Z</published>
    <updated>2020-05-08T13:45:37.327Z</updated>
    
    <content type="html"><![CDATA[<h3 id="查询student表中重名的学生"><a href="#查询student表中重名的学生" class="headerlink" title="查询student表中重名的学生"></a>查询student表中重名的学生</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">id</span>,<span class="keyword">name</span></span><br><span class="line"><span class="keyword">from</span> student</span><br><span class="line"><span class="keyword">where</span> <span class="keyword">name</span> <span class="keyword">in</span> (</span><br><span class="line"><span class="keyword">select</span> <span class="keyword">name</span> <span class="keyword">from</span> student <span class="keyword">group</span> <span class="keyword">by</span> <span class="keyword">name</span> <span class="keyword">having</span>(<span class="keyword">count</span>(*) &gt; <span class="number">1</span>)</span><br><span class="line">) <span class="keyword">order</span> <span class="keyword">by</span> <span class="keyword">name</span>;</span><br></pre></td></tr></table></figure><h3 id="每门课第一名（支持并列）"><a href="#每门课第一名（支持并列）" class="headerlink" title="每门课第一名（支持并列）"></a>每门课第一名（支持并列）</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> qtest <span class="keyword">as</span> x <span class="keyword">where</span> score=</span><br><span class="line">(<span class="keyword">select</span> <span class="keyword">max</span>(score) <span class="keyword">from</span> qtest  <span class="keyword">where</span> subject=x.subject);</span><br></pre></td></tr></table></figure><p>即自连接，看成ab两张表，a中等于b中该学科最高成绩的。</p><h3 id="每门课前三名"><a href="#每门课前三名" class="headerlink" title="每门课前三名"></a>每门课前三名</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> qtest x <span class="keyword">where</span></span><br><span class="line"><span class="number">3</span>&gt;(<span class="keyword">select</span> <span class="keyword">count</span>(*) <span class="keyword">from</span> qtest  <span class="keyword">where</span> subject=x.subject <span class="keyword">and</span> score&gt;x.score)</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> subject,score <span class="keyword">desc</span>;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;查询student表中重名的学生&quot;&gt;&lt;a href=&quot;#查询student表中重名的学生&quot; class=&quot;headerlink&quot; title=&quot;查询student表中重名的学生&quot;&gt;&lt;/a&gt;查询student表中重名的学生&lt;/h3&gt;&lt;figure class=&quot;hi
      
    
    </summary>
    
      <category term="技术" scheme="http://yoursite.com/blog/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="数据库" scheme="http://yoursite.com/blog/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>TIME_AWAIT大量出现及解决办法</title>
    <link href="http://yoursite.com/blog/2020/04/24/4-24%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/blog/2020/04/24/4-24技术笔记/</id>
    <published>2020-04-24T03:05:52.000Z</published>
    <updated>2020-06-01T08:50:43.211Z</updated>
    
    <content type="html"><![CDATA[<h2 id="TIME-WAIT状态产生背景"><a href="#TIME-WAIT状态产生背景" class="headerlink" title="TIME_WAIT状态产生背景"></a>TIME_WAIT状态产生背景</h2><p><img src="https://s1.ax1x.com/2020/06/01/tGDc2d.jpg" alt></p><p>在tcp四次挥手中，断联一方，收到被断联方的FIN后，发出ACK，并不会直接到close状态，而是先处于TIME—WAIT，等待两个MSL（报文最大生存时间）后，才会到closed态。</p><p>这样做是为了保证可靠性，由于网络原因，ACK可能会发送失败，那么这个时候，被动一方会主动重新发送一次FIN，这个时候如果主动方在TIME_WAIT状态，则还会再发送一次ACK，从而保证可靠性。那么从这个解释来说，2MSL的时长设定是可以理解的，MSL是报文最大生存时间，如果重新发送，一个FIN＋一个ACK，再加上不定期的延迟时间，大致是在2MSL的范围。</p><h3 id="服务端TIME-WAIT过多"><a href="#服务端TIME-WAIT过多" class="headerlink" title="服务端TIME_WAIT过多"></a>服务端TIME_WAIT过多</h3><p>在HTTP1.1协议中，有个 Connection 头，Connection有两个值，close和keep-alive，这个头就相当于客户端告诉服务端，服务端你执行完成请求之后，是关闭连接还是保持连接，保持连接就意味着在保持连接期间，只能由客户端主动断开连接。还有一个keep-alive的头，设置的值就代表了服务端保持连接保持多久。</p><p>HTTP默认的Connection值为close，那么就意味着关闭请求的一方几乎都会是由服务端这边发起的。那么这个服务端产生TIME_WAIT过多的情况就很正常了。</p><p>虽然HTTP默认Connection值为close，但是现在的浏览器发送请求的时候一般都会设置Connection为keep-alive了。所以，也有人说，现在没有必要通过调整参数来使TIME_WAIT降低了。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;TIME-WAIT状态产生背景&quot;&gt;&lt;a href=&quot;#TIME-WAIT状态产生背景&quot; class=&quot;headerlink&quot; title=&quot;TIME_WAIT状态产生背景&quot;&gt;&lt;/a&gt;TIME_WAIT状态产生背景&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://
      
    
    </summary>
    
      <category term="技术" scheme="http://yoursite.com/blog/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="计算机网络" scheme="http://yoursite.com/blog/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Mysql-proxy</title>
    <link href="http://yoursite.com/blog/2020/03/11/3-11%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/blog/2020/03/11/3-11技术笔记/</id>
    <published>2020-03-11T12:40:31.000Z</published>
    <updated>2020-03-11T12:42:50.079Z</updated>
    
    <content type="html"><![CDATA[<p> MySQL Proxy就是这么一个中间层代理，简单的说，MySQL Proxy就是一个连接池，负责将前台应用的连接请求转发给后台的数据库，并且通过使用lua脚本，可以实现复杂的连接控制和过滤，<br>    从而实现读写分离和负载平衡。对于应用来说，MySQL Proxy是完全透明的，应用则只需要连接到MySQL Proxy的监听端口即可。</p><p>当然，这样proxy机器可能成为单点失效，但完全可以使用多个proxy机器做为冗余，在应用服务器的连接池配置中配置到多 个proxy的连接参数即可。</p><p>这么看MySQL Proxy就类似nginx，通过代理能实现负载均衡/主写从读/失败重试等功能。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt; MySQL Proxy就是这么一个中间层代理，简单的说，MySQL Proxy就是一个连接池，负责将前台应用的连接请求转发给后台的数据库，并且通过使用lua脚本，可以实现复杂的连接控制和过滤，&lt;br&gt;    从而实现读写分离和负载平衡。对于应用来说，MySQL Proxy
      
    
    </summary>
    
      <category term="技术" scheme="http://yoursite.com/blog/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="数据库" scheme="http://yoursite.com/blog/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>group by和聚合函数</title>
    <link href="http://yoursite.com/blog/2020/03/03/3-3%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/blog/2020/03/03/3-3技术笔记/</id>
    <published>2020-03-03T11:30:41.000Z</published>
    <updated>2020-03-03T13:20:06.047Z</updated>
    
    <content type="html"><![CDATA[<h2 id="sum"><a href="#sum" class="headerlink" title="sum"></a>sum</h2><p>比如说简单的一张表，学生-学科-成绩。</p><p>要查每个学生的总成绩，用sum和group by可以写</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">name</span>， <span class="keyword">SUM</span>(score) <span class="keyword">as</span> totalscore </span><br><span class="line"><span class="keyword">from</span> stuscore </span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> <span class="keyword">name</span> </span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> totalscore <span class="keyword">desc</span></span><br></pre></td></tr></table></figure><h2 id="group-by-多字段"><a href="#group-by-多字段" class="headerlink" title="group by 多字段"></a>group by 多字段</h2><p>如果 group by 多个字段，那么这些不同的多条数据之间，只有这些字段的值<strong>全部</strong>一致，才会被合并到一条记录中，如果有各别字段不一致，将会生成更多的组。</p><h2 id="同一张表多条件"><a href="#同一张表多条件" class="headerlink" title="同一张表多条件"></a>同一张表多条件</h2><p>比如说，有数学课，并且没有语文课的学生</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> *</span><br><span class="line"><span class="keyword">from</span> qtest</span><br><span class="line"><span class="keyword">where</span> subject =<span class="string">"数学"</span> <span class="keyword">and</span> subject !=<span class="string">"语文"</span></span><br></pre></td></tr></table></figure><p>这些写显然是<strong>不对</strong>的，where条件里满足了数学，肯定自然满足了没有语文。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">distinct</span> <span class="keyword">NAME</span> <span class="keyword">FROM</span> qtest T </span><br><span class="line"><span class="keyword">WHERE</span> <span class="keyword">EXISTS</span>(<span class="keyword">SELECT</span> <span class="number">1</span> <span class="keyword">FROM</span> qtest <span class="keyword">WHERE</span> uid=T.uid  <span class="keyword">AND</span> subject=<span class="string">'数学'</span>) <span class="keyword">AND</span> </span><br><span class="line"><span class="keyword">NOT</span> <span class="keyword">EXISTS</span>(<span class="keyword">SELECT</span> <span class="number">1</span> <span class="keyword">FROM</span> qtest <span class="keyword">WHERE</span> uid=T.uid  <span class="keyword">AND</span> subject=<span class="string">'语文'</span>)</span><br></pre></td></tr></table></figure><p>EXISTS在SQL中的作用是：检验查询是否返回数据。</p><p>select a.* from tb a where exists(select 1 from tb where name =a.name)返回真假，当 where 后面的条件成立，则列出数据，否则为空。</p><h2 id="HAVING"><a href="#HAVING" class="headerlink" title="HAVING"></a>HAVING</h2><p>在 SQL 中增加 HAVING 子句原因是，WHERE 关键字无法与合计函数一起使用。</p><p>找出平均分大于70的学生</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">name</span> </span><br><span class="line"><span class="keyword">from</span> qtest</span><br><span class="line"><span class="keyword">having</span> <span class="keyword">avg</span>(score)&gt;<span class="number">70</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;sum&quot;&gt;&lt;a href=&quot;#sum&quot; class=&quot;headerlink&quot; title=&quot;sum&quot;&gt;&lt;/a&gt;sum&lt;/h2&gt;&lt;p&gt;比如说简单的一张表，学生-学科-成绩。&lt;/p&gt;
&lt;p&gt;要查每个学生的总成绩，用sum和group by可以写&lt;/p&gt;
&lt;figure
      
    
    </summary>
    
      <category term="技术" scheme="http://yoursite.com/blog/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="数据库" scheme="http://yoursite.com/blog/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>数字签名、数字证书与PKI系统</title>
    <link href="http://yoursite.com/blog/2020/02/26/2-26%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/blog/2020/02/26/2-26技术笔记/</id>
    <published>2020-02-26T11:53:44.000Z</published>
    <updated>2020-02-26T12:18:20.971Z</updated>
    
    <content type="html"><![CDATA[<p>实际上网络传输的加密应该分为三部分</p><ol><li>文件内容不能被读取</li><li>文件内容不能被篡改</li><li>文件不能被掉包</li></ol><h1 id="加密"><a href="#加密" class="headerlink" title="加密"></a>加密</h1><p>对称加密需要同一份密钥，密钥在传输时可能被截获，非对称加密密钥不怕被截获，解决了文件内容不能被读取问题。</p><p>算法重要的概念是公钥和私匙。</p><p>先有私钥，再用函数生成公钥。公钥包含了私钥的信息，但也掺杂了其他随机变量，因此不能反推。</p><p>私匙不要泄露，公钥要告诉和你通信的对方。公钥加密，只有对应私钥能解开（保密）；私钥加密，只有对应公钥能解开（不可抵赖）。</p><p>具体有两种情形：</p><p>（1）对方用你的公钥加密信息，你收到后用私钥解开。</p><p>只有你有私钥，所以只有你能解开，换句话说，有私钥才能看到信息，很安全。</p><p>（2）你拿私钥加密信息，对方收到后用你的公钥解开。</p><p>公钥是公开的，所以其他人也可以看到你的信息，不保密。</p><p>私钥加密，只有对应公钥能解开。既然用你的公钥能解开，说明加密一定是你的私钥。私钥只有你有，所以一定是你发送的，你不可抵赖。</p><p>但是假设传输内容被截取，第三方虽然无法解析出文件内容，但是他可以自己生成一个私钥，并用接收方的公钥加密，然后把自己的文件冒充传给接收方，这种情况下接收方收到的就是被篡改的文件。</p><h1 id="数字签名"><a href="#数字签名" class="headerlink" title="数字签名"></a>数字签名</h1><p>数字签名就是用<strong>摘要算法</strong>（sha1,md5）提取出源文件的摘要并用私钥进行加密后的内容。</p><p>针对上面那个问题，甲在发送文件时再附带上源文件的数字签名。如果被黑客截取到加密后的文件和数字签名，黑客即使使用甲的公钥解出了文件摘要，由于摘要算法的特性黑客也无法还原出原始内容。但乙可以解密出文件内容再用同样的摘要算法提取出摘要来和数字签名里的摘要进行比对，摘要一致则说明文件没有被篡改过。</p><p>数字签名在发送方，分两步：（1）从内容算摘要（哈希算法）（2）从摘要明文到摘要密文，也称数字签名（发送方私钥+加密算法）</p><p>数字签名验证在接收方，分两步：（1）从摘要密文（数字签名）到摘要明文（发送方公钥+解密算法）（2）从收到的内容当场计算摘要（哈希算法），与（1）的结果比对是否一致</p><p>如果一致，可以说明两点：</p><p>（1）内容未被篡改（摘要一致）</p><p>（2）内容只能是私钥拥方发送，不可抵赖（密文能够用对方的公钥解开）</p><p>还有一个风险就是乙无法确定自己用的公钥就是甲提供的，如果黑客将乙手里的甲的公钥替换成自己的并用自己的私钥生成数字签名，那么乙还是会受到被篡改的文件。</p><h1 id="数字证书"><a href="#数字证书" class="headerlink" title="数字证书"></a>数字证书</h1><p>数字证书的出现就是为了解决上述提到的问题，数字证书是一个经证书授权中心数字签名的包含公开密钥拥有者信息以及公开密钥的文件。</p><p>数字证书里一般会包含公钥、公钥拥有者名称、CA 的数字签名、有效期、授权中心名称、证书序列号等信息。</p><p>数字证书如何确保列出的用户就是公钥的拥有者呢？关键点是 CA 的数字签名，CA会用自己的私钥将证书内容的摘要进行加密。因为 CA 的公钥是公开的，任何人都可以用公钥解密出 CA 的数字签名的摘要，再用同样的摘要算法提取出证书的摘要和解密 CA 数字签名后的摘要比对，一致则说明这个证书没有被篡改过，可以信任。</p><p>数字证书里有个重要概念，CA,发送方先把自己的公钥给CA，CA对其进行加密得到加密后的发送方公钥（用的是CA的私钥和CA加密算法），也就是CA的数字证书。</p><p>注意这里有两个不同的非对称算法（对应2个公钥私钥对），一个算法是发送方加密摘要的，用于生成数字签名；另一个算法是CA加密发送方公钥的，用于生成数字证书。两个算法相互独立，没有必然联系。</p><p>发送时不仅发送内容、数字签名，还包含发送方的数字证书。接收方拿到后，首先从数字证书中解密出发送方公钥（用的是CA的公钥和CA解密算法），这个公钥必然是可信的。然后就是和前面一样的流程，拿发送方公钥去解密数字证书，得到摘要；最后比对摘要是否一致。</p><h1 id="https"><a href="#https" class="headerlink" title="https"></a>https</h1><p>1、认证服务器。浏览器内置一个受信任的CA机构列表，并保存了这些CA机构的证书。第一阶段服务器会提供经CA机构认证颁发的服务器证书，如果签发该证书的CA，存在于浏览器的受信任CA列表中（也就是签发该证书的CA的根证书，能够与客户端中保存的CA根证书比对上），说明这个CA是可信任的，可以保证证书不假。然后，再进一步判断服务器证书中的信息与当前正在访问的网站（域名等）一致，那么浏览器就认为服务端是可信的，并从服务器证书中取得服务器公钥，用于后续流程。否则，浏览器将提示用户，根据用户的选择，决定是否继续。 <strong>客户端是否能够信任这个站点的证书，首先取决于客户端程序是否导入了证书颁发者的根证书。</strong>  </p><p>2、协商会话密钥。客户端在认证完服务器，获得服务器的公钥之后，利用该公钥与服务器进行加密通信，协商出两个会话密钥，分别是用于加密客户端往服务端发送数据的客户端会话密钥，用于加密服务端往客户端发送数据的服务端会话密钥。在已有服务器公钥，可以加密通讯的前提下，还要协商两个对称密钥的原因，是因为非对称加密相对复杂度更高，在数据传输过程中，使用对称加密，可以节省计算资源。另外，会话密钥是随机生成，每次协商都会有不一样的结果，所以安全性也比较高。  </p><p>3、加密通讯。此时客户端服务器双方都有了本次通讯的会话密钥，之后传输的所有Http数据，都通过会话密钥加密。这样网路上的其它用户，将很难窃取和篡改客户端和服务端之间传输的数据，从而保证了数据的私密性和完整性。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;实际上网络传输的加密应该分为三部分&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;文件内容不能被读取&lt;/li&gt;
&lt;li&gt;文件内容不能被篡改&lt;/li&gt;
&lt;li&gt;文件不能被掉包&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;加密&quot;&gt;&lt;a href=&quot;#加密&quot; class=&quot;headerlink&quot; titl
      
    
    </summary>
    
      <category term="技术" scheme="http://yoursite.com/blog/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="计算机网络" scheme="http://yoursite.com/blog/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Http1.1\2.0</title>
    <link href="http://yoursite.com/blog/2020/02/25/2-25%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>http://yoursite.com/blog/2020/02/25/2-25技术笔记-1/</id>
    <published>2020-02-25T09:06:21.000Z</published>
    <updated>2020-02-25T13:09:04.312Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-1"><a href="#1-1" class="headerlink" title="1.1"></a>1.1</h1><p>1.0只是初创版本，1.1自1999年至今广泛使用，是真正完善的版本。</p><p>主要区别在于长连接，HTTP 1.1支持长连接（PersistentConnection）和请求的流水线（Pipelining）处理，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟，在HTTP1.1中默认开启Connection： keep-alive，一定程度上弥补了HTTP1.0每次请求都要创建连接的缺点。</p><p>其他一些小区别，更多的缓存策略，断点续传/请求资源的部分，更多的错误码，必须带主机名。</p><h2 id="2-0"><a href="#2-0" class="headerlink" title="2.0"></a>2.0</h2><p>2.0是基于<strong>SPDY</strong>协议的。主要区别在于</p><ol><li><p>基于二进制而不是1.1的文本，实现方便且健壮。</p></li><li><p>多路复用，一个request对应一个id，这样一个连接上可以有多个request，每个连接的request可以随机的混杂在一起，接收方可以根据request的 id将request再归属到各自不同的服务端请求里面。多路复用的实现基础就是协议基于二进制的，这样是分帧传输的，请求和响应可以交错甚至可以复用。</p></li><li><p>header压缩，1.1的header里有大量信息，2.0使用了Hpack算法压缩了头部，大概原理是双方同时维护缩写的动态和静态表，后来可以增量更改。</p></li><li><p>服务端推送。</p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-1&quot;&gt;&lt;a href=&quot;#1-1&quot; class=&quot;headerlink&quot; title=&quot;1.1&quot;&gt;&lt;/a&gt;1.1&lt;/h1&gt;&lt;p&gt;1.0只是初创版本，1.1自1999年至今广泛使用，是真正完善的版本。&lt;/p&gt;
&lt;p&gt;主要区别在于长连接，HTTP 1.1支持长连接
      
    
    </summary>
    
    
      <category term="计算机网络" scheme="http://yoursite.com/blog/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>三次握手与time_awiat</title>
    <link href="http://yoursite.com/blog/2020/02/24/2-24%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/blog/2020/02/24/2-24技术笔记/</id>
    <published>2020-02-24T06:59:48.000Z</published>
    <updated>2020-02-24T07:25:27.505Z</updated>
    
    <content type="html"><![CDATA[<h2 id="为什么建立链接需要三次"><a href="#为什么建立链接需要三次" class="headerlink" title="为什么建立链接需要三次"></a>为什么建立链接需要三次</h2><p>在这里我们假设是俩次握手：</p><p>客户端第一次向服务器发送一个请求，由于网络阻塞服务器没有收到该请求。</p><p>客户端等不及了，又向服务器发送了一次请求，这次网络不阻塞了，双方经过俩次握手成功建立了一次对话。</p><p>与此同时，客户端第一次发送的请求到达了服务器，服务器又向客户端发送一个请求，但是此时客户端不认账了，不回去理会这个请求报文，而服务器以为已经建立好了链接，傻傻的等待客户端发送数据过来，这样的链接如果太多，使得服务器性能大大降低。</p><p>俩次握手不能阻止客户端失效的请求链接到达服务器，而且造成服务器以为建立好链接的假象，造成系统的性能降低；</p><h2 id="TIME-WAIT"><a href="#TIME-WAIT" class="headerlink" title="TIME_WAIT"></a>TIME_WAIT</h2><p>为了理解 TIME_WAIT 状态的必要性，我们先来假设没有这么一种状态会导致的问题。暂以 A、B 来代指 TCP 连接的两端，A 为主动关闭的一端。</p><ul><li><p>四次挥手中，A 发 FIN， B 响应 ACK，B 再发 FIN，A 响应 ACK 实现连接的关闭。而如果 A 响应的 ACK 包丢失，B 会以为 A 没有收到自己的关闭请求，然后会重试向 A 再发 FIN 包。</p><p>如果没有 TIME_WAIT 状态，A 不再保存这个连接的信息，收到一个不存在的连接的包，A 会响应 RST 包，导致 B 端异常响应。</p><p>此时， TIME_WAIT 是为了保证全双工的 TCP 连接正常终止。</p></li><li><p>我们还知道，TCP 下的 IP 层协议是无法保证包传输的先后顺序的。如果双方挥手之后，一个网络四元组（src/dst ip/port）被回收，而此时网络中还有一个迟到的数据包没有被 B 接收，A 应用程序又立刻使用了同样的四元组再创建了一个新的连接后，这个迟到的数据包才到达 B，那么这个数据包就会让 B 以为是 A 刚发过来的。</p><p>此时， TIME_WAIT 的存在是为了保证网络中迷失的数据包正常过期。</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;为什么建立链接需要三次&quot;&gt;&lt;a href=&quot;#为什么建立链接需要三次&quot; class=&quot;headerlink&quot; title=&quot;为什么建立链接需要三次&quot;&gt;&lt;/a&gt;为什么建立链接需要三次&lt;/h2&gt;&lt;p&gt;在这里我们假设是俩次握手：&lt;/p&gt;
&lt;p&gt;客户端第一次向服务器发送一
      
    
    </summary>
    
      <category term="技术" scheme="http://yoursite.com/blog/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="计算机网络" scheme="http://yoursite.com/blog/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>子网掩码作用</title>
    <link href="http://yoursite.com/blog/2020/02/21/2-21%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/blog/2020/02/21/2-21技术笔记/</id>
    <published>2020-02-21T08:36:26.000Z</published>
    <updated>2020-02-21T08:55:36.354Z</updated>
    
    <content type="html"><![CDATA[<p>1.子网掩码是用来区分广播域的，同一个广播域可以直接互相通信，不需要路由转发。</p><p>2。发送数据报时，知道ip地址是不够的，还需要知道MAC地址，而数据链路层又没有ip地址。这时需要arp协议。</p><p>3.如果在同一个网络内，arp可以直接查到ip地址。如果不在，就必须得arp广播，查询申请。</p><p>所以子网掩码就是用来确定是否在同一个网络（广播域）内，3做策略选择的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;1.子网掩码是用来区分广播域的，同一个广播域可以直接互相通信，不需要路由转发。&lt;/p&gt;
&lt;p&gt;2。发送数据报时，知道ip地址是不够的，还需要知道MAC地址，而数据链路层又没有ip地址。这时需要arp协议。&lt;/p&gt;
&lt;p&gt;3.如果在同一个网络内，arp可以直接查到ip地址。如
      
    
    </summary>
    
      <category term="技术" scheme="http://yoursite.com/blog/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="计算机网络" scheme="http://yoursite.com/blog/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>TCP粘包/拆包</title>
    <link href="http://yoursite.com/blog/2020/02/20/2-20%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>http://yoursite.com/blog/2020/02/20/2-20技术笔记-1/</id>
    <published>2020-02-20T06:27:37.000Z</published>
    <updated>2020-02-20T06:47:35.007Z</updated>
    
    <content type="html"><![CDATA[<h1 id="伪概念"><a href="#伪概念" class="headerlink" title="伪概念"></a>伪概念</h1><p>TCP是基于流的协议，所谓流，就是没有界限的一串数据。TCP底层并不了解上层业务数据的具体含义，它会根据TCP缓冲区的实际情况进行包的划分，所以在业务上认为，一个完整的包可能会被TCP拆分成多个包进行发送，也有可能把多个小的包封装成一个大的数据包发送，这就是所谓的TCP粘包和拆包问题。<br>即应用层的请求和传输层是不对应的。</p><p>假设客户端分别发送了两个数据包D1和D2给服务端，由于服务端一次读取的字节数是不定的，故可能存在以下四种情况。<br>(1) 服务端分两次读取到了两个独立的数据包，分别是D1和D2，没有粘包和拆包；<br>(2) 服务端一次接收到了两个数据包，D1和D2粘合在一起，被称为TCP粘包；<br>(3) 服务端分两次读取到了两个数据包，第一次读取到了完整的D1包和D2包的部分内容，第二次读取到了D2包的剩余内容，这被称为TCP拆包；<br>(4) 服务端分两次读取到了两个数据包，第一次读取到了D1包的部分内容D1_1，第二次读取到了D1包的剩余内容D1_2和D2包的整包。</p><h1 id="传输层解决是耍流氓"><a href="#传输层解决是耍流氓" class="headerlink" title="传输层解决是耍流氓"></a>传输层解决是耍流氓</h1><p>比如关闭Nagle算法，接受方立刻从缓冲池里拿数据，都是基于传输层的，是没有意义的。</p><p>因为tcp是基于流的，传输层没有包，包是应用层自己规定的，那么自然应该在应用层再解析出包来。</p><h1 id="应用层分割"><a href="#应用层分割" class="headerlink" title="应用层分割"></a>应用层分割</h1><p>以netty为例，有4种粘包处理器，分别是基于回车，基于指定分割符，定长，基于协议。</p><p>其实也就是发送接收双方约定好应用层“包”的接口，接收方在应用层把流解析成包即可。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;伪概念&quot;&gt;&lt;a href=&quot;#伪概念&quot; class=&quot;headerlink&quot; title=&quot;伪概念&quot;&gt;&lt;/a&gt;伪概念&lt;/h1&gt;&lt;p&gt;TCP是基于流的协议，所谓流，就是没有界限的一串数据。TCP底层并不了解上层业务数据的具体含义，它会根据TCP缓冲区的实际情况进行包
      
    
    </summary>
    
      <category term="技术" scheme="http://yoursite.com/blog/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="计算机网络" scheme="http://yoursite.com/blog/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>rudp协议</title>
    <link href="http://yoursite.com/blog/2020/02/18/2-18%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>http://yoursite.com/blog/2020/02/18/2-18技术笔记-1/</id>
    <published>2020-02-18T08:47:53.000Z</published>
    <updated>2020-02-18T09:21:59.557Z</updated>
    
    <content type="html"><![CDATA[<h1 id="RUDP保证可靠性的机制"><a href="#RUDP保证可靠性的机制" class="headerlink" title="RUDP保证可靠性的机制"></a>RUDP保证可靠性的机制</h1><p>重传：RUDP的重传方式有三类：<strong>定时重传</strong>、<strong>请求重传</strong>和<strong>FEC选择重传</strong></p><h2 id="定时重传"><a href="#定时重传" class="headerlink" title="定时重传"></a>定时重传</h2><p>发送端如果在发出数据包（T1）时刻一个RTO之后还没有收到这个数据包的ACK消息，那么就会重发该数据包。</p><p>有如下两个问题，一是ack包丢失，二是ack包延迟超过1RTO。</p><p>如果场景是一个对<strong>延迟敏感但对流量成本要求不高</strong>的场景，就可以将<strong>RTO的计算设计比较小</strong>，这样能尽最大可能呢保证你的延迟足够小。如：<strong>实时操作类网游</strong>、<strong>教育领域的书写同步</strong>。如果是<strong>大带宽实时传输</strong>，定时重传对带宽的消耗是很大的，极端情况会用20%的重复重传率，所以在大带宽模式下一般采用<strong>请求重传模式</strong>。</p><h2 id="请求重传"><a href="#请求重传" class="headerlink" title="请求重传"></a>请求重传</h2><p>请求重传就是接收端在发送ACK的时候携带自己丢失报文的信息反馈，发送端接收到ACK信息时根据丢包反馈进行报文重传。</p><p>问题在于如何在网络抖动的乱序下评估丢包：当发现丢包的时候记录一个时刻t1,当t1 + rtt_var（RTT方差值） &lt; curr_t(当前时刻)，我们就认为它丢失了，，这个时候后续的ACK就需要携带这个丢包信息并更新丢包时刻t2,后续持续扫描丢包队列，如果他t2 + RTO &lt;curr_t，再次在ACK携带这个丢包信息，以此类推，直到收到报文为止。</p><p>这种方式是由<strong>丢包请求</strong>引起的重发，如果<strong>网络很不好，</strong>接收端会不断发起重传请求，造成发送端不停的重传，引起<strong>网络风暴</strong>，<strong>通信质量会下降</strong>，所以我们再发送端设置一个拥塞控制模块来限流。</p><p><strong>请求重传</strong>这种方式比<strong>定时重传</strong>方式的延迟会大，一般适合于<strong>带宽较大</strong>的传输场景，如：<strong>视频</strong>、<strong>文件传输</strong>和<strong>数据同步</strong>等。</p><h3 id="FEC选择重传"><a href="#FEC选择重传" class="headerlink" title="FEC选择重传"></a>FEC选择重传</h3><p>除了定时重传和请求重传模式外，还有一种方式就是以<strong>FEC分组</strong>方式<strong>选择重传</strong>，<strong><code>FEC</code></strong>（Forward Error Correction）是一种<strong>前向纠错技术</strong>，一般是通过<strong><code>XOR</code></strong>类似的算法实现，也有<strong>多层的EC算法和raptor涌泉码技术</strong>，其实就是一个<strong>解方程</strong>的过程。</p><p>在<strong>发送方</strong>发送报文时，会根据<strong>FEC方式</strong>把几个<strong>报文</strong>进行<strong>FEC分组</strong>，通过<strong>XOR</strong>的方式得到<strong>若干个冗余包</strong>，然后一起发往接收端，如果<strong>接收端</strong>发现丢包但能通过<strong>FEC分组</strong>算法<strong>还原</strong>，就不向发送端请求重发，如果分组内包是不能进行FEC恢复，则请求发送端发送原始的数据包。</p><p><strong>FEC分组方式</strong>适合要求<strong>延迟敏感</strong>且<strong>随机丢包</strong>的<strong>传输场景</strong>，在一个<strong>带宽不是很充裕</strong>的条件下，FEC会<strong>增加多余的冗余包</strong>，可能会使得<strong>网络更加不好</strong>。FECC方式不仅可以配合请求重传模式，也可以配合定时重传模式。</p><h1 id="窗口与拥塞控制"><a href="#窗口与拥塞控制" class="headerlink" title="窗口与拥塞控制"></a>窗口与拥塞控制</h1><h2 id="窗口"><a href="#窗口" class="headerlink" title="窗口"></a>窗口</h2><p>RUDP需要一个收发的滑动窗口系统来配合对应的拥塞算法来做流量控制，有些RUDP需要严格的发送端和接收端的窗口对应，有些RUDP是不要收发窗口严格对应。</p><p>如果涉及到<strong>可靠有序</strong>的RUDP，<strong>接收端</strong>要做<strong>窗口</strong>就要做<strong>排序和缓冲</strong>，如果是<strong>无序可靠</strong>或者<strong>尽力可靠</strong>的场景，<strong>接收端</strong>一般就<strong>不作窗口缓冲</strong>，<strong>只做位置滑动</strong>。</p><h2 id="拥塞控制"><a href="#拥塞控制" class="headerlink" title="拥塞控制"></a>拥塞控制</h2><h3 id="模仿tcp"><a href="#模仿tcp" class="headerlink" title="模仿tcp"></a>模仿tcp</h3><p><strong>TCP</strong>经典拥塞算法分为四部分：<strong>慢启动</strong>、<strong>拥塞避免</strong>、<strong>拥塞处理</strong>和<strong>快速恢复</strong></p><p>若<strong>RUDP</strong>采用这个算法来做拥塞控制，一般的<strong>场景</strong>是为了保证<strong>有序可靠传输</strong>的同时又兼顾<strong>网络传输的公平性原则</strong>。</p><h3 id="BRR拥塞算法"><a href="#BRR拥塞算法" class="headerlink" title="BRR拥塞算法"></a>BRR拥塞算法</h3><p>对于经典拥塞算法的延迟和带宽压榨问题，google设计了基于发送端延迟和带宽评估的BBR拥塞控制算法。</p><p>这种拥塞算法致力于解决<strong>两个问题</strong>：</p><p>（1）<strong>在一定丢包率网络传输链路上充分利用带宽</strong></p><p>（2）<strong>降低网络传输中的buffer延迟</strong></p><p>BBR的主要策略就是周期性通过ACK和NACK返回来评估链路的min_rtt和max_bandwidth。最大吞吐量（cwnd）的大小是：</p><p><code>cwnd = max_bandwidth / min_rtt</code></p><h2 id="webRTC-gcc"><a href="#webRTC-gcc" class="headerlink" title="webRTC gcc"></a>webRTC gcc</h2><p>音视频传输就必然会想到webRTC系统，在webRTC总对于视频传输也实现了一个拥塞控制算法（gcc），webRTC的gcc是一个基于<strong>发送端丢包率</strong>和<strong>接收端延迟带宽</strong>统计的拥塞控制，而且是一个<strong>尽力可靠</strong>的传输算法。</p><h3 id="弱窗口拥塞控制"><a href="#弱窗口拥塞控制" class="headerlink" title="弱窗口拥塞控制"></a>弱窗口拥塞控制</h3><p>其实在很多场景是<strong>不用拥塞控制</strong>或者只要<strong>很弱的拥塞控制</strong>即可，如：<strong>师生双方书写同步</strong>、<strong>实时游戏</strong>，因为本身的<strong>传输的数据量不大</strong>，只要确保<code>足够小的延迟和可靠性</code><strong>即可，一般是采用</strong>固定窗口大小<strong>来进行流控，我们在系统中一般采用一个</strong><code>cwnd = 32</code><strong>这样的窗口来流控，ACK确认也是通过整个接收窗口反馈给发送方，</strong>简单直接<strong>、也</strong>很容易适应弱网环境。</p><h1 id="传输路径"><a href="#传输路径" class="headerlink" title="传输路径"></a>传输路径</h1><p>RUDP除了优化连接、压榨带宽、适合弱网环境等外，它还继承了UDP天然的动态性，可以在中间应用层链路上做传输优化，一般分为多点串联优化和多点并联优化</p><h2 id="多点串联relay"><a href="#多点串联relay" class="headerlink" title="多点串联relay"></a>多点串联relay</h2><p>在实时通信中一些对业务场景对延迟非常敏感，例如：实时语音、同步书写、实时互动、直播连麦等，如果单纯的服务中转或者P2P通信，很难无法满足其需求，尤其是在物理距离很大的情况下。在解决这个问题上SKYPE率先提出全球RTN（实时多点传输网络），其实就是在通信双方之间通过几个relay节点来动态智能选路，这种传输方式很适合RUDP，我们只要在通信双方构建一个RUDP通道，中间链路只是一个无状态的relay cache集合，relay与relay之间进行路由探测和选路，以此来做到链路的高可用和实时性</p><h2 id="多点并联relay"><a href="#多点并联relay" class="headerlink" title="多点并联relay"></a>多点并联relay</h2><p>在服务与服务进行媒体数据传输或者分发过程中，需要保证传输路径高可用和提高带宽并发，这类使用场景也会使用传输双方构建一个RUDP通道，中间通过多relay节点的并联来解决，这种模型需要在发送端设计一个多点路由表探测机制，以此来判断各个路径同时发送数据的比例和可以用性，这个模型除了链路备份和增大传输并发带宽外，还有个辅助的功能，如果是流媒体分发系统，我们一般会用BGP来做中转，如果节点与节点之间可以直连，这样还可以减少对BGP带宽的占用，以此来减少成本问题。</p><h1 id="RUDP优势"><a href="#RUDP优势" class="headerlink" title="RUDP优势"></a>RUDP优势</h1><h2 id="弱网环境传输问题"><a href="#弱网环境传输问题" class="headerlink" title="弱网环境传输问题"></a>弱网环境传输问题</h2><p>弱网环境如果用TCP通信延迟可能会非常大，这会影响用户体验。</p><p>场景有：<strong>实时的操作类网游通信</strong>、<strong>语音对话</strong>、<strong>多方白板书写</strong>等。</p><h2 id="资源优化"><a href="#资源优化" class="headerlink" title="资源优化"></a>资源优化</h2><p><strong>避免TCP</strong>的<strong>三次握手和四次挥手</strong>的过程，会采用RUDP来<strong>优化资源</strong>的<strong>占用率</strong>和<strong>响应时间</strong>，提高系统的<strong>并发能力</strong>，如：QUIC。</p><h2 id="端对端连通性问题"><a href="#端对端连通性问题" class="headerlink" title="端对端连通性问题"></a>端对端连通性问题</h2><p>一般终端直接和终端通信都涉及NAT穿越，TCP在<code>NAT</code>穿越实现非常困难，相对来说UDP穿越NAT却简单很多，如果是<strong>端到端的可靠通信</strong>一般用<strong><code>RUDP</code></strong>方式解决。</p><p>场景有：<strong>端到端的文件传输</strong>、<strong>音视频传输</strong>、<strong>交互指令传输</strong>等等。</p><h2 id="传输路径优化问题"><a href="#传输路径优化问题" class="headerlink" title="传输路径优化问题"></a>传输路径优化问题</h2><p>在一些对<strong>延时要求很高</strong>的场景下，会用<strong>应用层</strong><code>relay</code>的方式来做<strong>传输路由优化</strong>，也就是动态智能选路，这时双方采用RUDP方式来传输，中间的延迟进行relay选路优化延时。还有一类基于<strong>传输吞吐量</strong>的场景，例如：<strong>服务与服务之间数据分发</strong>、<strong>数据备份</strong>等，这类场景一般会采用<strong><code>多点并联relay</code></strong>来<strong>提高传输的速度</strong>，也是要建立在RUDP上的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;RUDP保证可靠性的机制&quot;&gt;&lt;a href=&quot;#RUDP保证可靠性的机制&quot; class=&quot;headerlink&quot; title=&quot;RUDP保证可靠性的机制&quot;&gt;&lt;/a&gt;RUDP保证可靠性的机制&lt;/h1&gt;&lt;p&gt;重传：RUDP的重传方式有三类：&lt;strong&gt;定时重传&lt;/
      
    
    </summary>
    
      <category term="技术" scheme="http://yoursite.com/blog/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="计算机网络" scheme="http://yoursite.com/blog/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>同步I/O</title>
    <link href="http://yoursite.com/blog/2020/02/16/2-16%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/blog/2020/02/16/2-16技术笔记/</id>
    <published>2020-02-16T09:19:52.000Z</published>
    <updated>2020-02-19T08:20:40.168Z</updated>
    
    <content type="html"><![CDATA[<h2 id="缓冲区"><a href="#缓冲区" class="headerlink" title="缓冲区"></a>缓冲区</h2><p>在调用函数write()时，似乎该函数一旦返回，数据便已经写到了文件中.</p><p>但显然，写磁盘速度很慢，如果加个内存缓冲区，只写入缓冲区，后续再把缓冲区写入磁盘，可以低速的输入输出设备长时间占用CPU，提高效率。</p><h2 id="write函数"><a href="#write函数" class="headerlink" title="write函数"></a>write函数</h2><p>当调用write()函数写出数据时，数据一旦写到该缓冲区（关键：只是写到缓冲区），函数便立即返回.此时写出的数据可以用read()读回，也可以被其他进程读到，但是并不意味着它们已经被写到了外部永久存储介质上，即使调用close()关闭文件后也可能如此. 因为缓冲区的数据可能还在等待输出.<br>因此，从数据被实际写到磁盘的角度来看，用write()写出的文件数据与外部存储设备并不是完全同步的.不同步的时间间隔非常短，一般只有几秒或十几秒，具体取决于写出的数据量和I/O数据缓冲区的状态.尽管不同步的时间间隔很短，但是如果在此期间发生掉电或者系统崩溃，则会导致所写数据来不及写至磁盘而丢失的情况.</p><h2 id="sync函数"><a href="#sync函数" class="headerlink" title="sync函数"></a>sync函数</h2><p>sync负责将系统缓冲区的数据“写入”磁盘，以确保数据的一致性和同步性.注意：sync函数只是将所有修改过的块缓冲区排入写队列，然后就返回，他并不等待实际I/O操作结束.所以不要认为调用了sync函数，就觉得数据已安全的送到磁盘文件上，有可能会出现问题，但是sync函数是无法得知的.<br>系统守候进程一般每隔一段时间调用一次sync函数，确保定期刷新内核的块缓存.UNIX系统中，系统守候进程update会周期性地（一般每个30秒）调用sync函数.命令sync(1)也调用sync函数.</p><h2 id="fsync函数"><a href="#fsync函数" class="headerlink" title="fsync函数"></a>fsync函数</h2><p>与sync函数不同，fsync函数只对由文件描符filedes指定的单一文件起作用，强制与描述字fildes相连文件的所有修改过的数据（包括核内I/O缓冲区中的数据）传送到外部永久介质，即刷新fildes给出的文件的所有信息，并且等待写磁盘操作结束，然后返回.调用 fsync()的进程将阻塞直到设备报告传送已经完成.这个fsync就安全点了.<br>一个程序在写出数据之后，如果继续进行后续处理之前要求确保所写数据已写到磁盘，则应当调用fsync().例如，数据库应用通常会在调用write()保存关键交易数据的同时也调用fsync().这样更能保证数据的安全可靠.</p><h2 id="fdatasync函数"><a href="#fdatasync函数" class="headerlink" title="fdatasync函数"></a>fdatasync函数</h2><p>fdatasync函数类似于fsync函数，但它只影响文件数据部分，强制传送用户已写出的数据至物理存储设备，不包括文件本身的特征数据.这样可以适当减少文件刷新时的数据传送量.而除数据外，fdatasync还会同步更新文件的属性.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;缓冲区&quot;&gt;&lt;a href=&quot;#缓冲区&quot; class=&quot;headerlink&quot; title=&quot;缓冲区&quot;&gt;&lt;/a&gt;缓冲区&lt;/h2&gt;&lt;p&gt;在调用函数write()时，似乎该函数一旦返回，数据便已经写到了文件中.&lt;/p&gt;
&lt;p&gt;但显然，写磁盘速度很慢，如果加个内存缓冲区，
      
    
    </summary>
    
      <category term="技术" scheme="http://yoursite.com/blog/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="操作系统" scheme="http://yoursite.com/blog/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="linux" scheme="http://yoursite.com/blog/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>内存碎片与内存整理</title>
    <link href="http://yoursite.com/blog/2020/02/13/2-13%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>http://yoursite.com/blog/2020/02/13/2-13技术笔记-1/</id>
    <published>2020-02-13T09:57:03.000Z</published>
    <updated>2020-02-13T10:39:01.321Z</updated>
    
    <content type="html"><![CDATA[<p>内存碎片分为两种，内部碎片和外部碎片。可以简单认为，内部碎片是分页导致的，外部碎片是分段导致的。</p><h1 id="slub"><a href="#slub" class="headerlink" title="slub"></a>slub</h1><p>linux kernel 通过把整个物理内存划分成以一个个page进行管理，管理器就是伙伴系统，它的最小分配单元就是page。但是对于小于page的内存分配，如果直接分配一个page，是一个很大的浪费。linux kernel 通过slab来实现对小于page大小的内存分配。slab把page按2的m次幂进行划分一个个字节块，当kmalloc申请内存时，通过slab管理器返回需要满足申请大小的最小空闲内存块。</p><p>解决了内部碎片的问题。</p><p>slab是Linux操作系统的一种内存分配机制。其工作是针对一些经常分配并释放的对象，如进程描述符等，这些对象的大小一般比较小，如果直接采用伙伴系统来进行分配和释放，不仅会造成大量的内存碎片，而且处理速度也太慢。<br>而slab分配器是基于对象进行管理的，相同类型的对象归为一类(如进程描述符就是一类)，每当要申请这样一个对象，slab分配器就从一个slab列表中分配一个这样大小的单元出去，而当要释放时，将其重新保存在该列表中，而不是直接返回给伙伴系统，从而避免这些内碎片。slab分配器并不丢弃已分配的对象，而是释放并把它们保存在内存中。当以后又要请求新的对象时，就可以从内存直接获取而不用重复初始化。</p><h1 id="buddy"><a href="#buddy" class="headerlink" title="buddy"></a>buddy</h1><p>Linux采用著名的伙伴系统(buddy system)算法来解决外碎片问题。把所有的空闲页框分组为11个块链表，每个链表分别包含大小为1,2,4,8,16,32,64,128,256,512,1024个连续的页框，对1024个页框的最大请求对应着4MB大小的连续RAM（每页大小为4KB），每个块的第一个页框的物理地址是该块大小的整数倍，例如，大小为16个页框的块，其起始地址是16*2^12的倍数。</p><p>假设现在要请求一个256个页框的块（1MB），算法步骤如下：<br>• 在256个页框的链表中检查是否有一个空闲快，如果没有，查找下一个更大的块，如果有，请求满足。<br>• 在512个页框的链表中检查是否有一个空闲块，如果有，把512个页框的空闲块分为两份，第一份用于满足请求，第二份链接到256个页框的链表中。如果没有空闲块，继续寻找下一个更大的块。<br>以上过程的逆过程，就是页框块的释放过程，也是该算法名字的由来，内核试图把大小为B的一对空闲伙伴块合并为一个2B的单独块，满足以下条件的两个块称之为伙伴：<br>• 两个块具有相同的大小<br>• 他们的物理地址是连续的<br>第一块的第一个页框的物理地址是2 <em> B </em> 2^12<br>该算法是递归的，如果它成功合并了B，就会试图去合并2B，以再次试图形成更大的块。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;内存碎片分为两种，内部碎片和外部碎片。可以简单认为，内部碎片是分页导致的，外部碎片是分段导致的。&lt;/p&gt;
&lt;h1 id=&quot;slub&quot;&gt;&lt;a href=&quot;#slub&quot; class=&quot;headerlink&quot; title=&quot;slub&quot;&gt;&lt;/a&gt;slub&lt;/h1&gt;&lt;p&gt;linux 
      
    
    </summary>
    
      <category term="技术" scheme="http://yoursite.com/blog/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="操作系统" scheme="http://yoursite.com/blog/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="linux" scheme="http://yoursite.com/blog/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>VIRT(虚拟内存)，RES(常驻内存)，SHR(共享内存)</title>
    <link href="http://yoursite.com/blog/2020/02/12/2-12%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-2/"/>
    <id>http://yoursite.com/blog/2020/02/12/2-12技术笔记-2/</id>
    <published>2020-02-12T13:31:56.000Z</published>
    <updated>2020-02-13T09:57:14.274Z</updated>
    
    <content type="html"><![CDATA[<p>可以通过top命令查看进程占用了多少内存。这里可以看到VIRT、RES和SHR三个重要的指标。</p><h2 id="虚拟内存"><a href="#虚拟内存" class="headerlink" title="虚拟内存"></a>虚拟内存</h2><p>1、进程“需要的”虚拟内存大小，包括进程使用的库、代码、数据，以及malloc、new分配的堆空间和分配的栈空间等；</p><p>2、假如进程新申请10MB的内存，但实际只使用了1MB，那么它会增长10MB，而不是实际的1MB使用量。</p><h2 id="常驻内存"><a href="#常驻内存" class="headerlink" title="常驻内存"></a>常驻内存</h2><p>驻留内存，顾名思义是指那些被映射到进程虚拟内存空间的物理内存。</p><h2 id="共享内存"><a href="#共享内存" class="headerlink" title="共享内存"></a>共享内存</h2><p>进程在运行过程中，会加载许多操作系统的动态库，比如 libc.so、libld.so等。这些库对于每个进程而言都是公用的，它们在内存中实际只会加载一份，这部分称为共享内存。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;可以通过top命令查看进程占用了多少内存。这里可以看到VIRT、RES和SHR三个重要的指标。&lt;/p&gt;
&lt;h2 id=&quot;虚拟内存&quot;&gt;&lt;a href=&quot;#虚拟内存&quot; class=&quot;headerlink&quot; title=&quot;虚拟内存&quot;&gt;&lt;/a&gt;虚拟内存&lt;/h2&gt;&lt;p&gt;1、进程“需要
      
    
    </summary>
    
      <category term="技术" scheme="http://yoursite.com/blog/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="操作系统" scheme="http://yoursite.com/blog/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="linux" scheme="http://yoursite.com/blog/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>内存管理</title>
    <link href="http://yoursite.com/blog/2020/02/11/2-11%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/blog/2020/02/11/2-11技术笔记/</id>
    <published>2020-02-11T03:43:04.000Z</published>
    <updated>2020-02-11T09:23:15.948Z</updated>
    
    <content type="html"><![CDATA[<h1 id="分段和分页"><a href="#分段和分页" class="headerlink" title="分段和分页"></a>分段和分页</h1><h2 id="分页"><a href="#分页" class="headerlink" title="分页"></a>分页</h2><p>用户程序的地址空间被划分成若干固定大小的区域，称为“页”，相应地，内存空间分成若干个物理块，页和块的大小相等，称为帧。可将用户程序的任一页放在内存的任一块中，实现了离散分配。</p><p>这样每个页和每个帧存在一个映射关系。即页表。</p><p>每次要取地址，把地址前几位解析出，即页号，后几位即页内偏移。在页表中把页号转换成帧号（找不到即缺页中断），然后加上页内偏移，即物理地址。</p><h2 id="分段"><a href="#分段" class="headerlink" title="分段"></a>分段</h2><p>将用户程序地址空间分成若干个<strong>大小不等</strong>的段，每段可以定义一组相对完整的逻辑信息。存储分配时，以段为单位，段与段在内存中可以不相邻接，也实现了离散分配。</p><p>作业的地址空间被划分为若干个段，每个段定义了一组逻辑信息。例程序段、数据段等。每个段都从0开始编址，并采用一段连续的地址空间。</p><p>段的长度由相应的逻辑信息组的长度决定，因而各段长度不等。整个作业的地址空间是二维的。</p><p>显然也有个段表。要取地址，需要两个信息，第几段和段内偏移，然后段表解析出物理地址。</p><h2 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h2><p>分页是强行物理划分的，分段是逻辑划分。</p><p>页大小固定，段大小按需求。</p><p>分页的作业地址空间是一维的.分段的地址空间是二维的。实际上分页也是二维的，两个维度放在了一个数高位和地位而已。</p><h1 id="物理地址、虚拟地址（线性地址）、逻辑地址"><a href="#物理地址、虚拟地址（线性地址）、逻辑地址" class="headerlink" title="物理地址、虚拟地址（线性地址）、逻辑地址"></a>物理地址、虚拟地址（线性地址）、逻辑地址</h1><p>现代计算机，其实结合了分段和分页，即段内分页。具体内存寻址</p><p>首先，肯定是给一个段号+段内偏移，即<strong>逻辑地址</strong></p><p>然后段表把段号哈希出来，解读到它的<strong>虚拟地址</strong>，即<strong>线性地址</strong></p><p>在接下来，页表，把虚拟地址，解析出<strong>物理地址</strong></p><p>CPU要<strong>利用其段式内存管理单元，先将为个逻辑地址转换成一个线程地址，再利用其页式内存管理单元，转换为最终物理地址</strong>。这样做两次转换，的确是非常麻烦而且没有必要的，因为直接可以把线性地址抽像给进程。之所以这样冗余，Intel完全是为了向前兼容而已。</p><h1 id="大内存分页"><a href="#大内存分页" class="headerlink" title="大内存分页"></a>大内存分页</h1><h2 id="TLB"><a href="#TLB" class="headerlink" title="TLB"></a><strong>TLB</strong></h2><p>页表是储存在内存中的，每次查询都要查内存未免太慢，可以在寄存器中缓存一份最常使用的，即TLB（<strong>页表寄存器缓冲</strong>）。</p><p>TLB是有限的，这点毫无疑问。当超出TLB的存储极限时，就会发生 TLB miss，之后，OS就会命令CPU去访问内存上的页表。如果频繁的出现TLB miss，程序的性能会下降地很快。</p><p>为了让TLB可以存储更多的页地址映射关系，我们的做法是调大内存分页大小。</p><p>如果一个页4M，对比一个页4K，前者可以让TLB多存储1000个页地址映射关系，性能的提升是比较可观的。</p><h1 id="缺页中断和置换算法"><a href="#缺页中断和置换算法" class="headerlink" title="缺页中断和置换算法"></a>缺页中断和置换算法</h1><p>在请求分页系统中，可以通过查询页表中的状态位来确定所要访问的页面是否存在于内存中。每当所要访问的页面不在内存时，会产生一次缺页中断，此时操作系统会根据页表中的外存地址在外存中找到所缺的一页，将其调入内存。 </p><p>缺页本身是一种中断，与一般的中断一样，需要经过4个处理步骤：<br>　　1. 保护CPU现场<br>　　2. 分析中断原因<br>　　3. 转入缺页中断处理程序进行处理<br>　　4. 恢复CPU现场，继续执行<br>但是缺页中断时由于所要访问的页面不存在与内存时，有硬件所产生的一种特殊的中断，因此，与一般的中断存在区别：<br>　　 1. 在指令执行期间产生和处理缺页中断信号<br>　　 2. 一条指令在执行期间，可能产生多次缺页中断<br>　　 3. 缺页中断返回时，执行产生中断的那一条指令，而一般的中断返回时，执行下一条指令</p><p>于是问题来了，页表一直是满的，把哪一页换出？</p><p>理论上来说，置换以后不再被访问，或者在将来最迟才回被访问的页面，缺页中断率最低。这就是最优解，即 最佳置换（Optimal， OPT)，但实际上未来不止，该算法不可实现。</p><p>如果我们洞悉过去，即可预测未来。置换最近一段时间以来最长时间未访问过的页面。根据程序局部性原理，刚被访问的页面，可能马上又要被访问；而较长时间内没有被访问的页面，可能最近不会被访问。   最近最久未使用置换算法（ Least Recently Used， LRU）普偏地适用于各种类型的程序，但是系统要时时刻刻对各页的访问历史情况加以记录和更新，开销太大，因此LRU算法必须要有硬件的支持。</p><p>当然最简单的是先进先出。（First In First Out, FIFO)</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;分段和分页&quot;&gt;&lt;a href=&quot;#分段和分页&quot; class=&quot;headerlink&quot; title=&quot;分段和分页&quot;&gt;&lt;/a&gt;分段和分页&lt;/h1&gt;&lt;h2 id=&quot;分页&quot;&gt;&lt;a href=&quot;#分页&quot; class=&quot;headerlink&quot; title=&quot;分页&quot;&gt;&lt;/a&gt;分
      
    
    </summary>
    
      <category term="技术" scheme="http://yoursite.com/blog/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="操作系统" scheme="http://yoursite.com/blog/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
</feed>
