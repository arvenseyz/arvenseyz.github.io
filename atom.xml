<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Arvense</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://arvenseyz.github.io/"/>
  <updated>2022-03-04T09:07:03.120Z</updated>
  <id>https://arvenseyz.github.io/</id>
  
  <author>
    <name>Arvense</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>mongo的checkpoint和Journaling</title>
    <link href="https://arvenseyz.github.io/2022/03/04/3-4%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>https://arvenseyz.github.io/2022/03/04/3-4技术笔记/</id>
    <published>2022-03-04T07:41:57.000Z</published>
    <updated>2022-03-04T09:07:03.120Z</updated>
    
    <content type="html"><![CDATA[<h1 id="page"><a href="#page" class="headerlink" title="page"></a>page</h1><p>WiredTiger存储引擎里面，磁盘里集合数据和索引都是通过B+ Tree来组织的，但是提供给应用读写的数据都是发生在内存里的，WiredTiger会按需将磁盘的数据以page为单位加载到内存，同时在内存会构造相应的B+ Tree来存储这些数据。应用都是在内存中对Page进行增删改，内存中的Page会利用一些数据结构来记录应用的修改，然后经过reconcile(调和)生成新的Page(基于原Page修改后的Page)，然后等待evict线程将生成的新的Page写到磁盘，并丢弃旧的Page。</p><p>第一步：pages从磁盘读到内存；</p><p>第二步：pages在内存中被修改；</p><p>第三步：被修改的脏pages在内存被reconcile，完成后将discard这些pages。</p><p>第四步：pages被选中，加入淘汰队列，等待被evict线程淘汰出内存；</p><p>第五步：evict线程会将“干净“的pages直接从内存丢弃（因为相对于磁盘page来说没做任何修改），将经过reconcile处理后的磁盘映像写到磁盘再丢弃“脏的”pages。</p><h1 id="checkPoint"><a href="#checkPoint" class="headerlink" title="checkPoint"></a>checkPoint</h1><p>WiredTiger的写操作会默认写入 Cache ,并持久化到 WAL (Write Ahead Log)，每60s或Log文件达到2G做一次 checkpoint (当然我们也可以通过在写入时传入 j: true 的参数强制 journal 文件的同步 ，writeConcern { w: , j: , wtimeout: }) 产生快照文件。WiredTiger初始化时，恢复至最新的快照状态，然后再根据WAL恢复数据，保证数据的完整性。<br>本质上来说，Checkpoint相当于一个日志，记录了上次Checkpoint后相关数据文件的变化。</p><p>checkpoint 中文名为检查点，顾名思义，是检查某一时刻内存和磁盘中的数据状态，即从上一次检查点到现在哪些Page被删除，哪些Page被新建等，可以说是记录了数据库中内存数据相对于上一次检查点的一个快照。当向Disk写入数据时，WiredTiger将Snapshot中的所有数据以一致性方式写入到数据文件（Disk Files）中。一旦Checkpoint创建成功，WiredTiger保证数据文件和内存数据是一致性的，因此，Checkpoint担当的是还原点（Recovery Point），一旦发生系统故障，可以根据检查点恢复出最新一次检查点的状态，然后通过回放从检查点之后的journal日志恢复出断电前的数据。<br>总的来说，Checkpoint主要有两个目的：</p><p>一是将内存里面发生修改的数据写到数据文件进行持久化保存，确保数据一致性；</p><p>二是实现数据库在某个时刻意外发生故障，再次启动时，缩短数据库的恢复时间。</p><p>Checkpoint技术通过在内存中维护一定的数据结构(B+ Tree)，记录应用对数据的改动，即从上次checkpoint到现在的内存页的改动，和要删除的页等，然后通过定时刷新等触发方式，将内存中的Checkpoint 的B+ Tree刷新到磁盘。一旦checkpoint完成，磁盘中数据就和内存数据同步了，checkpoint可以生成新的live Tress来继续记录应用新的改动。</p><h3 id="journal日志"><a href="#journal日志" class="headerlink" title="journal日志"></a>journal日志</h3><p>checkpoint保证了每个检查点之间，内存数据同步到磁盘。但是两个checkpoint时间间隔内的数据也需要保证持久化，这个就要靠journal日志来实现了。</p><p>journal 是顺序写入的二进制日志文件，用于记录上一个Checkpoint之后发生的数据更新，能够将数据库从系统异常终止事件中还原到一个有效的状态。journal日志文件是预分配的，从图6: MongoDB数据目录文件可以看出，journal目录下的文件都是100MB，是预分配好的，可以提高性能。WiredTiger 为每个客户端发起的写操作创建一个日志记录。日志记录包括由初始写入引起的任何内部写入操作。例如，对集合中文档的更新可能会导致对索引的修改；WiredTiger 创建单个日志记录，其中包括文档更新操作及其关联的索引修改。每条日志记录都有一个唯一的标识符，<br>WiredTiger 的最小日志记录大小为 128 字节。MongoDB 将 WiredTiger 配置为使用内存缓冲来存储日志记录。线程协调分配并复制到它们的缓冲区部分，缓冲最大 128 kB 的所有日志记录。当满足以下条件时，journal会被刷入到磁盘中：</p><ul><li><p>每100ms</p></li><li><p>写操作时加了选项<code>{j:true}</code>  </p></li><li><p>当 WiredTiger 创建一个新的日志文件时。由于 MongoDB 使用 100 MB 的日志文件大小限制，WiredTiger 大约每 100 MB 数据创建一个新日志文件。</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;page&quot;&gt;&lt;a href=&quot;#page&quot; class=&quot;headerlink&quot; title=&quot;page&quot;&gt;&lt;/a&gt;page&lt;/h1&gt;&lt;p&gt;WiredTiger存储引擎里面，磁盘里集合数据和索引都是通过B+ Tree来组织的，但是提供给应用读写的数据都是发生在内存
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="mongo" scheme="https://arvenseyz.github.io/tags/mongo/"/>
    
  </entry>
  
  <entry>
    <title>redis与Reactor模式</title>
    <link href="https://arvenseyz.github.io/2022/03/01/3-1%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-2/"/>
    <id>https://arvenseyz.github.io/2022/03/01/3-1技术笔记-2/</id>
    <published>2022-03-01T07:18:04.000Z</published>
    <updated>2022-03-01T09:11:52.004Z</updated>
    
    <content type="html"><![CDATA[<h1 id="同步和阻塞"><a href="#同步和阻塞" class="headerlink" title="同步和阻塞"></a>同步和阻塞</h1><p>很多时候同步和阻塞是同义词，nio这里会分开说，怎么理解</p><p>首先，所有的io分为两步，第一步等待数据，第二步写入数据到输出。</p><p>比如等待打字是第一步，把键盘输入解析处理屏幕显示是第二步。</p><blockquote><p>阻塞：是否阻塞主要体现在调用的线程是否可以干别的，关注的是程序的等待状态</p><p>同步：是否同步体现在<strong>消息通信机制上</strong> 。</p><p>也就是说同步和异步说的是消息的通知机制，阻塞非阻塞说的是线程的状态 。</p></blockquote><p><strong>是否同步的判断依据是:是否针对的是整个过程，也就是2个阶段，是否有阻塞。</strong></p><p><strong>是否阻塞的判断依据是:按程序（线程）等待消息通知时的状态角度来说的，也就是主要是针对第一阶段来说。</strong></p><h1 id="五种IO模型"><a href="#五种IO模型" class="headerlink" title="五种IO模型"></a>五种IO模型</h1><h3 id="bio"><a href="#bio" class="headerlink" title="bio"></a>bio</h3><p>最传统当然是阻塞式的IO，即blocking，BIO</p><p>在这个IO模型中，用户空间的应用程序执行一个系统调用（recvform），这会导致应用程序阻塞，什么也不干，直到数据准备好，等待kernel准备好从网络上接收到的数据报 + 等待收到的报文被从kernel复制到buf中，recvfrom方法才会返回，最后进程再处理数据。</p><p>这就是阻塞式IO模型。</p><p>即起一个线程等待键盘输入（第一步），输入后，处理输出到屏幕（第二步）</p><h3 id="非阻塞式I-O"><a href="#非阻塞式I-O" class="headerlink" title="非阻塞式I/O"></a>非阻塞式I/O</h3><p>优化第一步为轮询，即为非阻塞io。</p><p>非阻塞的recvform系统调用调用之后，进程并没有被阻塞，内核马上返回给进程，如果数据还没准备好，此时会返回一个error。进程在返回之后，可以干点别的事情，然后再发起recvform系统调用。如此循环的进行recvform系统调用，检查内核数据，直到数据准备好，再拷贝数据到进程。<strong>拷贝数据整个过程，进程仍然是属于阻塞的状态</strong>。</p><h3 id="I-O复用"><a href="#I-O复用" class="headerlink" title="I/O复用"></a>I/O复用</h3><p>第一步优化为回调，这样一个线程可以监听多个回调，即为I/O复用</p><p>IO multiplexing就是我们说的select，poll，epoll 。为何叫多路复用，是因为它I/O多路复用可以同时监听多个fd，如此就减少了为每个需要监听的fd开启线程的开销。</p><p>select调用是内核级别的，可以等待多个socket，能实现同时对多个IO端口进行监听<code>，当其中任何一个socket的数据准好了，</code>就能返回进行可读<code>，</code>然后进程再进行recvform系统调用，将数据由内核拷贝到用户进程，这个过程是阻塞的。</p><p>I/O复用模型会用到select、poll、epoll函数，这几个函数也会使进程阻塞，但是和阻塞I/O所不同的的，这几个函数可以同时阻塞多个I/O操作`。而且可以同时对多个读操作，多个写操作的I/O函数进行检测，直到有数据可读或可写时（不是等到socket数据全部到达再处理, 而是有了一部分数据就会调用用户进程来处理），才真正调用I/O操作函数。</p><p>IO复用有人把其成为同步非阻塞的，也有称为同步阻塞。其实这个是否阻塞还需要看第一个阶段，第一个阶段有的阻塞，有的不阻塞。主要也是阻塞在select阶段，属于用户主动等待阶段，我们且规范为阻塞状态，所以，<code>把IO多路复用归为同步阻塞模式</code></p><h2 id="信号驱动式I-O"><a href="#信号驱动式I-O" class="headerlink" title="信号驱动式I/O"></a>信号驱动式I/O</h2><p>等待回调可以再优化，由一个线程阻塞等待，优化为信号驱动，这样监听回调线程也不阻塞。</p><p>信号驱动式I/O：首先我们允许Socket进行信号驱动IO,并安装一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，进程会收到一个SIGIO信号，可以在信号处理函数中调用I/O操作函数处理数据。</p><h3 id="异步I-O"><a href="#异步I-O" class="headerlink" title="异步I/O"></a>异步I/O</h3><p>异步IO不是顺序执行,用户进程进行aio_read系统调用之后，无论内核数据是否准备好，都会直接返回给用户进程，然后用户态进程可以去做别的事情。等到socket数据准备好了，内核直接复制数据给进程，<code>然后从内核向进程发送通知</code>。<code>IO两个阶段，进程都是非阻塞的</code>。</p><p><a href="https://imgtu.com/i/blpGfH" target="_blank" rel="noopener"><img src="https://s4.ax1x.com/2022/03/01/blpGfH.png" alt="blpGfH.png"></a></p><h1 id="Reactor"><a href="#Reactor" class="headerlink" title="Reactor"></a>Reactor</h1><p>Reactor 就是基于NIO中实现多路复用的一种模式</p><h3 id="单线程Reactor模式"><a href="#单线程Reactor模式" class="headerlink" title="单线程Reactor模式"></a>单线程Reactor模式</h3><p><a href="https://imgtu.com/i/bl9d29" target="_blank" rel="noopener"><img src="https://s4.ax1x.com/2022/03/01/bl9d29.jpg" alt="bl9d29.jpg"></a></p><p>如图，即和NIO的描述基本一致。</p><p>只有一个<code>select</code>循环接收请求，客户端（client）注册进来由<code>Reactor</code>接收注册事件，然后再由reactor分发（dispatch）出去，由下面的处理器（Handler）去处理。</p><p>等待数据是阻塞式多路复用，处理输出数据是阻塞式在accepter中。</p><p>单线程的问题实际上是很明显的。只要其中一个Handler方法阻塞了，那就会导致所有的client的Handler都被阻塞了，也会导致注册事件也无法处理，无法接收新的请求。所以这种模式用的比较少，因为不能充分利用到多核的资源。</p><p>这种模式仅仅只能处理Handler比较快速完成的场景。</p><p>实际上5.0及其以前的redis就是这个模式，因为redis的handler的确能快速完成。</p><p>IO多路复用程序接收到用户的请求后，全部推送到一个队列里，交给文件分派器。对于后续的操作，和在 reactor 单线程实现方案里看到的一样，整个过程都在一个线程里完成，因此 Redis 被称为是单线程的操作。</p><p><a href="https://imgtu.com/i/blPn6s" target="_blank" rel="noopener"><img src="https://s4.ax1x.com/2022/03/01/blPn6s.png" alt="blPn6s.png"></a></p><h3 id="Reactor模式-工作者线程池模式"><a href="#Reactor模式-工作者线程池模式" class="headerlink" title="Reactor模式-工作者线程池模式"></a>Reactor模式-工作者线程池模式</h3><p>我们应该将非I/O的业务逻辑操作从Reactor线程上卸载，以此来加速Reactor线程对I/O请求的响应。与单线程模式不同的是，添加了一个<strong>工作者线程池</strong>，并将非I/O操作从Reactor线程中移出转交给工作者线程池（Thread Pool）来执行。这样能够提高Reactor线程的I/O响应，不至于因为一些耗时的业务逻辑而延迟对后面I/O请求的处理。</p><p><a href="https://imgtu.com/i/blCeqx" target="_blank" rel="noopener"><img src="https://s4.ax1x.com/2022/03/01/blCeqx.png" alt="blCeqx.png"></a></p><p>6.0之后的redis即为该模式</p><p>在 Redis 中，单线程的性能瓶颈主要在网络IO操作上。也就是在读写网络 read/write 系统调用执行期间会占用大部分 CPU 时间。如果你要对一些大的键值对进行删除操作的话，在短时间内是删不完的，那么对于单线程来说就会阻塞后边的操作。</p><p>好像其实不是标准的工作者线程池模式</p><p>多线程大部分逻辑和之前的单线程模型是一致的，变动的地方仅仅是把读取客户端请求命令和回写响应数据的逻辑异步化了，交给 I/O 线程去完成，这里需要特别注意的一点是：<strong>I/O 线程仅仅是读取和解析客户端命令而不会真正去执行命令，客户端命令的执行最终还是要在主线程上完成</strong>。</p><p>Redis 把处理逻辑交还给 Master 线程，虽然一定程度上增加了模型复杂度，但也解决了线程并发安全等问题。</p><p><a href="https://imgtu.com/i/blkuXd" target="_blank" rel="noopener"><img src="https://s4.ax1x.com/2022/03/01/blkuXd.png" alt="blkuXd.png"></a></p><h3 id="多Reactor多线程模型"><a href="#多Reactor多线程模型" class="headerlink" title="多Reactor多线程模型"></a>多Reactor多线程模型</h3><p>是将Reactor分成两部分，</p><blockquote><ol><li><p>mainReactor负责监听server socket，用来处理新连接的建立，将建立的socketChannel指定注册给subReactor。</p></li><li><p>subReactor维护自己的selector, 基于mainReactor 注册的socketChannel多路分离IO读写事件，读写网 络数据，对业务处理的功能，另其扔给worker线程池来完成。</p></li></ol></blockquote><p>mainReactor 主要是用来处理网络IO 连接建立操作，通常一个线程就可以处理，而subReactor主要做和建立起来的socket做数据交互和事件业务处理操作，它的个数上一般是和CPU个数等同，每个subReactor一个线程来处理。</p><p>nginx和netty应该是使用这种模式</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;同步和阻塞&quot;&gt;&lt;a href=&quot;#同步和阻塞&quot; class=&quot;headerlink&quot; title=&quot;同步和阻塞&quot;&gt;&lt;/a&gt;同步和阻塞&lt;/h1&gt;&lt;p&gt;很多时候同步和阻塞是同义词，nio这里会分开说，怎么理解&lt;/p&gt;
&lt;p&gt;首先，所有的io分为两步，第一步等待数据，第
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="redis" scheme="https://arvenseyz.github.io/tags/redis/"/>
    
      <category term="计算机网络" scheme="https://arvenseyz.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>12306跨站卖票设计</title>
    <link href="https://arvenseyz.github.io/2022/03/01/3-1%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>https://arvenseyz.github.io/2022/03/01/3-1技术笔记-1/</id>
    <published>2022-03-01T03:14:24.000Z</published>
    <updated>2022-03-01T03:20:58.853Z</updated>
    
    <content type="html"><![CDATA[<p>我们以北京到西安这趟高铁为例，比如我的路线就是从北京到西安，车上如果只剩最后一张票了，那么如果有其他人，在北京到西安这条路线之间买任何一站，那么我都是买不了票的，换句话说，对于单个座位来说，必须是起点到目的地之间的所有站，都没有人买的话，那么才能被算是有票状态。</p><p>所以我们可以尝试用bitmap结合上位操作来实现这种场景，以上述北京到西安为例，我们把问题简化</p><ul><li><p>比如一个火车上只有4个座位</p></li><li><p>北京到西安，一共是4站，其实是三个区间的，分别为北京-&gt;石家庄，石家庄-&gt;郑州，郑州-&gt;西安</p></li></ul><h4 id="首先我们给每个区间构建一个空位图-0为有票，1为无票"><a href="#首先我们给每个区间构建一个空位图-0为有票，1为无票" class="headerlink" title="首先我们给每个区间构建一个空位图(0为有票，1为无票)"></a>首先我们给每个区间构建一个空位图(0为有票，1为无票)</h4><table><thead><tr><th>区间</th><th>1</th><th>2</th><th>3</th><th>4</th></tr></thead><tbody><tr><td>北京-深圳</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>深圳-郑州</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>郑州-西安</td><td>0</td><td>0</td><td>0</td><td>0</td></tr></tbody></table><h4 id="接下来，比如有人买了一张从北京到西安的票"><a href="#接下来，比如有人买了一张从北京到西安的票" class="headerlink" title="接下来，比如有人买了一张从北京到西安的票"></a>接下来，比如有人买了一张从北京到西安的票</h4><p>买票这个动作，比如被分配到的座位是编号为1的座位，那么我们直接把北京到西安的所有站，1号座位全部设置为1</p><table><thead><tr><th>区间</th><th>1</th><th>2</th><th>3</th><th>4</th></tr></thead><tbody><tr><td>北京-石家庄</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>石家庄-郑州</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>郑州-西安</td><td>1</td><td>0</td><td>0</td><td>0</td></tr></tbody></table><h4 id="接下来又有人买了一张从石家庄到西安的票"><a href="#接下来又有人买了一张从石家庄到西安的票" class="headerlink" title="接下来又有人买了一张从石家庄到西安的票"></a>接下来又有人买了一张从石家庄到西安的票</h4><p>比如这次分配的是座位2，那么我们把石家庄到西安的所有票全部设置为1就行了，如下图</p><table><thead><tr><th>区间</th><th>1</th><th>2</th><th>3</th><th>4</th></tr></thead><tbody><tr><td>北京-石家庄</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>石家庄-郑州</td><td>1</td><td>1</td><td>0</td><td>0</td></tr><tr><td>郑州-西安</td><td>1</td><td>1</td><td>0</td><td>0</td></tr></tbody></table><h4 id="如何知道还剩几张票？"><a href="#如何知道还剩几张票？" class="headerlink" title="如何知道还剩几张票？"></a>如何知道还剩几张票？</h4><p>其实解决这个问题很简单，我们直接把上述位图做一个或操作就可以了</p><table><thead><tr><th>区间</th><th>1</th><th>2</th><th>3</th><th>4</th></tr></thead><tbody><tr><td>北京-石家庄</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>石家庄-郑州</td><td>1</td><td>1</td><td>0</td><td>0</td></tr><tr><td>郑州-西安</td><td>1</td><td>1</td><td>0</td><td>0</td></tr><tr><td>或操作结果</td><td>1</td><td>1</td><td>0</td><td>0</td></tr></tbody></table><p>或操作结果有几个0，则说明还剩几张票。</p><p>其实解决这个问题主要在于位图的构建，因为火车票对于某一个座位来说，只要起点到终点中间某一个区间被占用了(置为1)，那么整个座位都是无效的这个特点，很容易想到用或操作的结果来判断买票结果，我们这里只用了4位是为了方便说明问题，实际中应该是火车上有多少座位，位图的长度就应该是多少</p><p>作者：程序员小饭<br>链接：<a href="https://juejin.cn/post/7012507519595577375" target="_blank" rel="noopener">https://juejin.cn/post/7012507519595577375</a><br>来源：稀土掘金<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;我们以北京到西安这趟高铁为例，比如我的路线就是从北京到西安，车上如果只剩最后一张票了，那么如果有其他人，在北京到西安这条路线之间买任何一站，那么我都是买不了票的，换句话说，对于单个座位来说，必须是起点到目的地之间的所有站，都没有人买的话，那么才能被算是有票状态。&lt;/p&gt;
&lt;
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="系统设计" scheme="https://arvenseyz.github.io/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>短链系统设计</title>
    <link href="https://arvenseyz.github.io/2022/02/28/2-28%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>https://arvenseyz.github.io/2022/02/28/2-28技术笔记-1/</id>
    <published>2022-02-28T06:09:59.000Z</published>
    <updated>2022-02-28T07:22:05.656Z</updated>
    
    <content type="html"><![CDATA[<h1 id="编码"><a href="#编码" class="headerlink" title="编码"></a>编码</h1><p>首先是短链怎么生成。</p><p>一个想法是id生成器，但是id生成首先需要考虑的是单点故障问题，优秀的id生成器应该是分布式发号器，每个生成器先从中央协调器（例如ZooKeeper）保留一块id序列，这些id生成器可以单独从他们的id序列中分配id，有必要的时候在自己的id序列中做一些清理。</p><p>另一个想法是哈希，比如md5，但是哈希的问题是冲突，当发生哈希冲突了，意味着两个长链接对应的短链是一样的，解决冲突的办法可以是布隆过滤器（一定不存在，可能存在），如果冲突了，需要重新编码，比如说再拼接一段特殊字符再编码，解码时取消掉即可。另外就是没必要使用加密型的哈希算法， 可以使用<strong>MurmurHash</strong>这种非加密的，好处是速度快。</p><h1 id="存储"><a href="#存储" class="headerlink" title="存储"></a>存储</h1><p>短链很多，存储压力较大，一个简便的分布式系存储比如mongo的确可以满足需要，但是考虑到使用场景，可能可以自动清理过期的。</p><h1 id="跳转"><a href="#跳转" class="headerlink" title="跳转"></a>跳转</h1><blockquote><p>301，代表 永久重定向，也就是说第一次请求拿到长链接后，下次浏览器再去请求短链的话，不会向短网址服务器请求了，而是直接从浏览器的缓存里拿，这样在 server 层面就无法获取到短网址的点击数了，如果这个链接刚好是某个活动的链接，也就无法分析此活动的效果。所以我们一般不采用 301。</p><p> 302，代表 临时重定向，也就是说每次去请求短链都会去请求短网址服务器（除非响应中用 Cache-Control 或 Expired 暗示浏览器缓存）,这样就便于 server 统计点击数，所以虽然用 302 会给 server 增加一点压力，但在数据异常重要的今天，这点代码是值得的，所以推荐使用 302！</p></blockquote><p>实际上可以直接跳过服务端，使用openResty等的HTTP服务器插件，前端直接访问数据库</p><h1 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h1><p>由几个不同部分去做这件事情生成访问流数据，收集整理，每过一段时间写到永久数据库中，用一个延迟较低的信息系统去暂时存储访问数据，然后将数据交给收集整理部分，面试者可能会问访问数据多久需要被更新一次。如果每天更新，一个比较合理的方法是存储在HDFS，用map/reduce去计算数据。 如果是要近乎实时的数据，收集整理的部分就要计算出所需的数据</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;编码&quot;&gt;&lt;a href=&quot;#编码&quot; class=&quot;headerlink&quot; title=&quot;编码&quot;&gt;&lt;/a&gt;编码&lt;/h1&gt;&lt;p&gt;首先是短链怎么生成。&lt;/p&gt;
&lt;p&gt;一个想法是id生成器，但是id生成首先需要考虑的是单点故障问题，优秀的id生成器应该是分布式发号器，每个
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="系统设计" scheme="https://arvenseyz.github.io/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>红包技术设计</title>
    <link href="https://arvenseyz.github.io/2022/02/25/2-25%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-2/"/>
    <id>https://arvenseyz.github.io/2022/02/25/2-25技术笔记-2/</id>
    <published>2022-02-25T07:41:01.000Z</published>
    <updated>2022-02-25T08:26:08.876Z</updated>
    
    <content type="html"><![CDATA[<p>红包是一种秒杀，秒杀的难点就是锁库存，大量用户同时“秒杀”同一商品时，第一个到达 DB 的请求锁住了这行库存记录。在第一个事务完成提交之前这个锁一直被第一个请求占用，后面的所有请求需要排队等待。同时参与“秒杀”的用户越多，并发进 DB 的请求越多，请求排队越严重。因此，并发请求抢锁，是典型的商品“秒杀”系统的设计难点。</p><p>一般有两个思路，第一个是秒杀不锁库存，在内存/redis维护一个库存，这样就不用锁库存，直接在内存/redis原子操作扣减，秒杀结束后再持久化。</p><p>第二个是用乐观锁，乐观锁抢锁失败直接返回用户秒杀失败即可。</p><p>这两个思路都不适合红包</p><p>对红包来说，一个能降低库存的压力的办法是分表，即不同的红包在不同的表。因为红包没有热点商品，这个是可以的。还可以按时间再分，这样红包表也不大。</p><p>第二是串行化时机提前，在服务端维护先进先出的队列串行化，请求量过大直接返回。</p><p>还有个策略是server也切分，这样server和db对应，好处是故障隔离，如果DB error了，直接屏蔽红包号段。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;红包是一种秒杀，秒杀的难点就是锁库存，大量用户同时“秒杀”同一商品时，第一个到达 DB 的请求锁住了这行库存记录。在第一个事务完成提交之前这个锁一直被第一个请求占用，后面的所有请求需要排队等待。同时参与“秒杀”的用户越多，并发进 DB 的请求越多，请求排队越严重。因此，并发
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="系统设计" scheme="https://arvenseyz.github.io/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>feed流设计</title>
    <link href="https://arvenseyz.github.io/2022/02/23/2-22%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>https://arvenseyz.github.io/2022/02/23/2-22技术笔记-1/</id>
    <published>2022-02-23T07:24:58.000Z</published>
    <updated>2022-02-23T08:11:56.558Z</updated>
    
    <content type="html"><![CDATA[<p>feed流有两种，一种是我关注的人/我好友的，比如说朋友圈，另一种是推荐的，比如头条。</p><p>这里看第一种。</p><h2 id="推拉模式"><a href="#推拉模式" class="headerlink" title="推拉模式"></a>推拉模式</h2><p>简单想到的实现方式就是，每一个内容发布者都有一个自己的发件箱，第一步加载用户所有好友，第二步加载这些好友的所有内容。即拉模式，读扩散。</p><p>这个模式有两个问题，第一是性能问题，关注的人数非常多时性能有问题。第二是业务问题，翻页时有问题。</p><p>有拉就有推，即每个用户都有个收件箱，当发布者发表一篇帖子的时候，除了往自己发件箱记录一下之外，还会遍历发布者的所有粉丝，往这些粉丝的收件箱也投放一份相同内容。这样阅读者来读Feed流时，直接从自己的收件箱读取即可。</p><p>比较适合朋友圈这种场景。比如微博，有人一亿粉丝，这种模式肯定用不了。</p><p>其实这种模式可以混合，粉丝量很少的人，可以用推模式。粉丝量多的人，只推给活跃粉丝。</p><p>非活跃粉丝刷feed流时，一方面要读自己的收件箱，另一方面也要拉关注的大v的发件箱。</p><h2 id="分页问题"><a href="#分页问题" class="headerlink" title="分页问题"></a>分页问题</h2><p>即加载第二页时，由于按时间排的，有新的内容导致第一页的内容被挤到第二页，这样又看见第一页的内容。</p><p>比较简单的方法是，加一个last_id</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;feed流有两种，一种是我关注的人/我好友的，比如说朋友圈，另一种是推荐的，比如头条。&lt;/p&gt;
&lt;p&gt;这里看第一种。&lt;/p&gt;
&lt;h2 id=&quot;推拉模式&quot;&gt;&lt;a href=&quot;#推拉模式&quot; class=&quot;headerlink&quot; title=&quot;推拉模式&quot;&gt;&lt;/a&gt;推拉模式&lt;/h2
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="系统设计" scheme="https://arvenseyz.github.io/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>Redis数据倾斜</title>
    <link href="https://arvenseyz.github.io/2022/02/21/2-21%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>https://arvenseyz.github.io/2022/02/21/2-21技术笔记-1/</id>
    <published>2022-02-21T08:46:56.000Z</published>
    <updated>2022-02-21T09:03:44.553Z</updated>
    
    <content type="html"><![CDATA[<p>热点读场景，某个热点帖子内容这样，所有的访问量都打到了redis一个实例。单实例压力过大。（我怀疑这种场景真的存在吗？redis单机读取qps能承受万级别）</p><p>产生原因：redis 根据key进行分片计算，分配到redis实例中的一个，导致大部分流量集中访问到同一个redis实例上，即所谓的“访问量倾斜”，导致redis实例达到性能瓶颈</p><p>解决方案：给hotkey加上后缀，把hotkey数量变成redis实例数N的倍数M，从而由访问一个redis key变成访问N*M个redis key</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//redis 实例数</span></span><br><span class="line"><span class="keyword">const</span> M = <span class="number">16</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//redis 实例数倍数（按需设计，2^n倍，n一般为1到4的整数）</span></span><br><span class="line"><span class="keyword">const</span> N = <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="comment">//获取 redis 实例 </span></span><br><span class="line">    c, err := redis.Dial(<span class="string">"tcp"</span>, <span class="string">"127.0.0.1:6379"</span>)</span><br><span class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">        fmt.Println(<span class="string">"Connect to redis error"</span>, err)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">defer</span> c.Close()</span><br><span class="line"></span><br><span class="line">    hotKey := <span class="string">"hotKey:abc"</span></span><br><span class="line">    <span class="comment">//随机数</span></span><br><span class="line">    randNum := GenerateRangeNum(<span class="number">1</span>, N*M)</span><br><span class="line">    <span class="comment">//得到对 hot key 进行打散的 key</span></span><br><span class="line">    tmpHotKey := hotKey + <span class="string">"_"</span> + strconv.Itoa(randNum)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//hot key 过期时间</span></span><br><span class="line">    expireTime := <span class="number">50</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">//过期时间平缓化的一个时间随机值</span></span><br><span class="line">    randExpireTime := GenerateRangeNum(<span class="number">0</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    data, err := redis.String(c.Do(<span class="string">"GET"</span>, tmpHotKey))</span><br><span class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">        data, err = redis.String(c.Do(<span class="string">"GET"</span>, hotKey))</span><br><span class="line">        <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">            data = GetDataFromDb()</span><br><span class="line">            c.Do(<span class="string">"SET"</span>, <span class="string">"hotKey"</span>, data, expireTime)</span><br><span class="line">            c.Do(<span class="string">"SET"</span>, tmpHotKey, data, expireTime + randExpireTime)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            c.Do(<span class="string">"SET"</span>, tmpHotKey, data, expireTime + randExpireTime)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;热点读场景，某个热点帖子内容这样，所有的访问量都打到了redis一个实例。单实例压力过大。（我怀疑这种场景真的存在吗？redis单机读取qps能承受万级别）&lt;/p&gt;
&lt;p&gt;产生原因：redis 根据key进行分片计算，分配到redis实例中的一个，导致大部分流量集中访问到同
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="redis" scheme="https://arvenseyz.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>RocketMQ 消息存储</title>
    <link href="https://arvenseyz.github.io/2021/12/14/12-14%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>https://arvenseyz.github.io/2021/12/14/12-14技术笔记-1/</id>
    <published>2021-12-14T09:04:05.000Z</published>
    <updated>2021-12-14T09:55:12.164Z</updated>
    
    <content type="html"><![CDATA[<h2 id="先回顾下kafka"><a href="#先回顾下kafka" class="headerlink" title="先回顾下kafka"></a>先回顾下kafka</h2><p><img src="https://cdn.jsdelivr.net/gh/arvenseyz/imageCloud/2a57c077-1ae2-460d-be0b-168329058e70.png" alt></p><p>Kafka 以 Topic 作为文件存储的基本单元，即每个 Topic 有其对应的数据文件和索引文件。消息直接存储在partition中，对单topic为顺序写。</p><p>这样预期结果是，磁盘顺序写+顺序读，性能很好。</p><p>但问题是，是分topic的，如果topic很多，要不停的切topic，顺序读写就被破坏了，降低了性能。</p><h2 id="RocketMQ-消息存储"><a href="#RocketMQ-消息存储" class="headerlink" title="RocketMQ 消息存储"></a>RocketMQ 消息存储</h2><p><img src="https://cdn.jsdelivr.net/gh/arvenseyz/imageCloud/d27e7402-138b-4654-9bed-1da9175417a1.png" alt></p><p>RocketMQ 既然号称能支持万级别topic，肯定不是kafka这么存的。</p><p>首先是存储上不分topic，所以这些topic的内容写在一块的。即CommitLog。</p><p>那既然不同topic，内容在一块，怎么读呢，答案是加一个索引，同时，由于消息仍需要以 Topic 为维度进行消费，因此 RocketMQ 基于 CommitLog 为每个 Topic 异步构建多个逻辑队列（ConsumeQueue），逻辑队列消息是定长的，因为只有表头，存储了这个Queue在CommiLog中的起始offset，log大小和MessageTag的hashCode。</p><p>既然是定长的，根据offset，就能找到消息在ConsumeQueue中的位置，然后再读到在CommiLog中的起始offset，最后从CommiLog读到消息内容。</p><p>消息存储只是把消息主体存储到了物理文件中，但是并没有把消息处理到consumeQueue文件中，那么到底是哪里存入的？答案是起一个线程，不停的轮询，将当前的consumeQueue中的offSet和commitLog中的offSet进行对比，将多出来的offSet进行解析，然后put到consumeQueue中的MapedFile中。</p><p>另外还有个index文件</p><p>index文件是为搜索场景而生的，如果没有搜索业务需求，则这个实现是意义不大的。一般这种搜索，主要用于后台查询验证类使用，或者有其他同的有妙用，不得而知。总之，一切为搜索。它更多的需要借助于时间限定，以key或者id进行查询。</p><p>　那么，如果要查找一个key, 应当如何查找呢？rocketmq会根据时间段找到一个index索引分版，然后再根据key做hash得到一个值，然后定位到 slotValue . 然后再从slotValue去取出索引数据的地址，找到索引数据，然后再回查 commitlog 文件。从而得到具体的消息数据。也就是，相当于搜索经历了四级查询： 索引分片文件查询 -&gt; slotValue 查询 -&gt; 索引数据查询 -&gt; commitlog 查询 。</p><p>看起来比较复杂，但搜索场景毕竟不多。</p><h2 id="RocketMQ-优缺点"><a href="#RocketMQ-优缺点" class="headerlink" title="RocketMQ 优缺点"></a>RocketMQ 优缺点</h2><p>上面的流程，优点是什么呢？</p><p>除了支持多topic外，因为consumequeue数据量小，绝大部分的访问还是Page Cache的访问，而不是磁盘访问。  </p><p>正式部署也可以将CommitLog和consumerQueue放在不同的物理SSD，避免多类文件进行IO竞争。  </p><p>缺点:</p><p>读取消息时，由于不同的topic消息都写在同一个文件，导致读取顺序不连续，造成随机读，降低了读IO。</p><h2 id="怎么降低缺点影响"><a href="#怎么降低缺点影响" class="headerlink" title="怎么降低缺点影响"></a>怎么降低缺点影响</h2><p>（硬件上的原因，缺点似乎不存在了，现在都是ssd，ssd随机读性能很好）</p><h3 id="Mmap"><a href="#Mmap" class="headerlink" title="Mmap"></a>Mmap</h3><p>Mmap内存映射和普通标准IO操作的本质区别在于它并不需要将文件中的数据先拷贝至OS的内核IO缓冲区，而是可以直接将用户进程私有地址空间中的一块区域与文件对象建立映射关系，这样程序就好像可以直接从内存中完成对文件读/写操作一样。只有当缺页中断发生时，直接将文件从磁盘拷贝至用户态的进程空间内，只进行了一次数据拷贝。对于容量较大的文件来说(文件大小一般需要限制在1.5~2G以下)，采用Mmap的方式其读/写的效率和性能都非常高。<br><em>JDK NIO</em>提供的MappedByteBuffer底层就是调用<em>mmap</em>来实现的</p><h3 id="PageCache机制"><a href="#PageCache机制" class="headerlink" title="PageCache机制"></a>PageCache机制</h3><p>PageCache是OS对文件的缓存，用于加速对文件的读写。一般来说，程序对文件进行顺序读写的速度几乎接近于内存的读写访问，这里的主要原因就是在于OS使用PageCache机制对读写访问操作进行了性能优化，将一部分的内存用作PageCache。(1)对于数据文件的读取，如果一次读取文件时出现未命中PageCache的情况，OS从物理磁盘上访问读取文件的同时，会顺序对其他相邻块的数据文件进行预读取(ps：顺序读入紧随其后的少数几个页面)。这样，只要下次访问的文件已经被加载至PageCache时，读取操作的速度基本等于访问内存。(2)对于数据文件的写入，OS会先写入至Cache内，随后通过异步的方式由pdflush内核线程将Cache内的数据刷盘至物理磁盘上。对于文件的顺序读写操作来说，读和写的区域都在OS的PageCache内，此时读写性能接近于内存。RocketMQ的大致做法是，将数据文件映射到OS的虚拟内存中(通过JDK NIO的MappedByteBuffer)，写消息的时候首先写入PageCache，并通过异步刷盘的方式将消息批量的做持久化(同时也支持同步刷盘)；订阅消费消息时(对CommitLog操作是随机读取)，由于PageCache的局部性热点原理且整体情况下还是从旧到新的有序读，因此大部分情况下消息还是可以直接从Page Cache中读取，不会产生太多的缺页(Page Fault)中断而从磁盘读取。</p><h4 id="预先分配MappedFile"><a href="#预先分配MappedFile" class="headerlink" title="预先分配MappedFile"></a>预先分配MappedFile</h4><p>在消息写入过程中(调用CommitLog的putMessage()方法)，CommitLog会先从MappedFileQueue队列中获取一个 MappedFile，如果没有就新建一个。这里，MappedFile的创建过程是将构建好的一个AllocateRequest请求(具体做法是，将下一个文件的路径、下下个文件的路径、文件大小为参数封装为AllocateRequest对象)添加至队列中，后台运行的AllocateMappedFileService服务线程(在Broker启动时，该线程就会创建并运行)，会不停地run，只要请求队列里存在请求，就会去执行MappedFile映射文件的创建和预分配工作，分配的时候有两种策略，一种是使用Mmap的方式来构建MappedFile实例，另外一种是从TransientStorePool堆外内存池中获取相应的DirectByteBuffer来构建MappedFile(ps：具体采用哪种策略，也与刷盘的方式有关)。并且，在创建分配完下个MappedFile后，还会将下下个MappedFile预先创建并保存至请求队列中等待下次获取时直接返回。RocketMQ中预分配MappedFile的设计非常巧妙，下次获取时候直接返回就可以不用等待MappedFile创建分配所产生的时间延迟。</p><h4 id="文件预热-amp-amp-mlock系统调用"><a href="#文件预热-amp-amp-mlock系统调用" class="headerlink" title="文件预热&amp;&amp;mlock系统调用"></a>文件预热&amp;&amp;mlock系统调用</h4><p>(1)mlock系统调用：其可以将进程使用的部分或者全部的地址空间锁定在物理内存中，防止其被交换到swap空间。对于RocketMQ这种的高吞吐量的分布式消息队列来说，追求的是消息读写低延迟，那么肯定希望尽可能地多使用物理内存，提高数据读写访问的操作效率。</p><p>(2)文件预热：预热的目的主要有两点；第一点，由于仅分配内存并进行mlock系统调用后并不会为程序完全锁定这些内存，因为其中的分页可能是写时复制的。因此，就有必要对每个内存页面中写入一个假的值。其中，RocketMQ是在创建并分配MappedFile的过程中，预先写入一些随机值至Mmap映射出的内存空间里。第二，调用Mmap进行内存映射后，OS只是建立虚拟内存地址至物理地址的映射表，而实际并没有加载任何文件至内存中。程序要访问数据时OS会检查该部分的分页是否已经在内存中，如果不在，则发出一次缺页中断。这里，可以想象下1G的CommitLog需要发生多少次缺页中断，才能使得对应的数据才能完全加载至物理内存中(ps：X86的Linux中一个标准页面大小是4KB)？RocketMQ的做法是，在做Mmap内存映射的同时进行madvise系统调用，目的是使OS做一次内存映射后对应的文件数据尽可能多的预加载至内存中，从而达到内存预热的效果。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;先回顾下kafka&quot;&gt;&lt;a href=&quot;#先回顾下kafka&quot; class=&quot;headerlink&quot; title=&quot;先回顾下kafka&quot;&gt;&lt;/a&gt;先回顾下kafka&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/arve
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="消息队列" scheme="https://arvenseyz.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>RocketMQ 推和拉</title>
    <link href="https://arvenseyz.github.io/2021/12/13/12-13%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>https://arvenseyz.github.io/2021/12/13/12-13技术笔记-1/</id>
    <published>2021-12-13T06:48:17.000Z</published>
    <updated>2021-12-15T06:09:12.389Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是推和拉"><a href="#什么是推和拉" class="headerlink" title="什么是推和拉"></a>什么是推和拉</h2><p>说到推拉，其实只针对消费者和broker的行为，生产者只有推（不然生产者岂不是还得把消息持久化等着broker来取数据）。</p><p><strong>推模式</strong>指的是consumer与broker建立好网络长连接，broker有相关数据，直接通过长连接通道推送到consumer。其优点是及时，一旦有数据变更，consumer立马能感知到；另外对consumer来说逻辑简单，不需要关心有无数据这些逻辑处理。缺点是不知道consumer的数据消费能力，可能导致数据积压在consumer，来不及处理。</p><p><strong>拉模式</strong>指的是consumer主动向broker发出请求，拉取相关数据。其优点是此过程由consumer发起请求，故不存在推模式中数据积压的问题。缺点是可能不够及时，对consumer来说需要考虑数据拉取相关逻辑，何时去拉，拉的频率怎么控制等等。</p><h2 id="RocketMq的推拉"><a href="#RocketMq的推拉" class="headerlink" title="RocketMq的推拉"></a>RocketMq的推拉</h2><p>RocketMq其实只有拉。</p><p>推是帮填了些参数的拉。consumer把轮询过程封装了，并注册MessageListener监听器，取到消息后，唤醒MessageListener的consumeMessage()来消费，对用户而言，感觉消息是被推送（push）过来的。主要用的也是这种方式。</p><p>如果是拉的话，客户端代码可能得这么写：</p><ol><li><p>注册消费者实例到nameserver</p></li><li><p>查询对应的topic消息队列以便可以消费其下所有数据</p></li><li><p>获取消息队列，消费消息;</p></li><li><p>自行维护保存消费偏移量，以便为下一次消费提供依据;</p></li><li><p>循环以上操作;</p></li></ol><p>可以看见还是比较麻烦。推的话，只需要注册回调方法即可。</p><h3 id="推是用拉-长轮询实现"><a href="#推是用拉-长轮询实现" class="headerlink" title="推是用拉+长轮询实现"></a>推是用拉+长轮询实现</h3><p>后台会有个 RebalanceService 线程，这个线程会根据 topic 的队列数量和当前消费组的消费者个数做负载均衡，每个队列产生的 pullRequest 放入阻塞队列 pullRequestQueue 中。然后又有个 PullMessageService 线程不断的从阻塞队列 pullRequestQueue 中获取 pullRequest，然后通过网络请求 broker，这样实现的准实时拉取消息。</p><p>上面操作相当于帮做了拉的1、2步</p><p>具体怎么长轮询拉的呢</p><p><img src="https://cdn.jsdelivr.net/gh/arvenseyz/imageCloud/9182641-667ee972d01888f3.webp" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;什么是推和拉&quot;&gt;&lt;a href=&quot;#什么是推和拉&quot; class=&quot;headerlink&quot; title=&quot;什么是推和拉&quot;&gt;&lt;/a&gt;什么是推和拉&lt;/h2&gt;&lt;p&gt;说到推拉，其实只针对消费者和broker的行为，生产者只有推（不然生产者岂不是还得把消息持久化等着broke
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="消息队列" scheme="https://arvenseyz.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>RocketMQ Rebalance机制</title>
    <link href="https://arvenseyz.github.io/2021/12/10/12-10%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>https://arvenseyz.github.io/2021/12/10/12-10技术笔记/</id>
    <published>2021-12-10T06:51:50.000Z</published>
    <updated>2021-12-13T03:30:58.392Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Rebalance是什么"><a href="#Rebalance是什么" class="headerlink" title="Rebalance是什么"></a><strong>Rebalance是什么</strong></h1><p>Rebalance(再均衡)机制指的是：将一个Topic下的<strong>多个队列(或称之为分区)</strong>，在同一个消费者组(consumer group)下的<strong>多个消费者实例</strong>(consumer instance)之间进行重新分配。</p><p><strong>Rebalance机制本意是为了提升消息的并行处理能力。</strong>例如，一个Topic下5个队列，在只有1个消费者的情况下，那么这个消费者将负责处理这5个队列的消息。如果此时我们增加一个消费者，那么可以给其中一个消费者分配2个队列，给另一个分配3个队列，从而提升消息的并行处理能力。</p><p>但是Rebalance机制也存在明显的<strong>限制</strong>与<strong>危害</strong>。</p><p><strong>Rebalance限制：</strong></p><p>由于一个队列最多分配给一个消费者，因此当某个消费者组下的消费者实例数量大于队列的数量时，多余的消费者实例将分配不到任何队列。</p><p><strong>Rebalance危害：</strong></p><p>除了以上限制，更加严重的是，在发生Rebalance时，存在着一些危害，如下所述：</p><ul><li><strong>消费暂停：</strong>考虑在只有Consumer 1的情况下，其负责消费所有5个队列；在新增Consumer 2，触发Rebalance时，需要分配2个队列给其消费。那么Consumer 1就需要停止这2个队列的消费，等到这两个队列分配给Consumer 2后，这两个队列才能继续被消费。</li><li><strong>重复消费：</strong>Consumer 2 在消费分配给自己的2个队列时，必须接着从Consumer 1之前已经消费到的offset继续开始消费。然而默认情况下，offset是异步提交的，如consumer 1当前消费到offset为10，但是异步提交给broker的offset为8；那么如果consumer 2从8的offset开始消费，那么就会有2条消息重复。也就是说，Consumer 2 并不会等待Consumer1提交完offset后，再进行Rebalance，因此提交间隔越长，可能造成的重复消费就越多。</li><li><strong>消费突刺：</strong>由于rebalance可能导致重复消费，如果需要重复消费的消息过多；或者因为rebalance暂停时间过长，导致积压了部分消息。那么都有可能导致在rebalance结束之后瞬间可能需要消费很多消息。</li></ul><h1 id="什么时候Reblance"><a href="#什么时候Reblance" class="headerlink" title="什么时候Reblance"></a>什么时候Reblance</h1><p>从本质上来说，触发Rebalance的根本因素无非是两个：</p><p><strong>1. 订阅Topic的队列数量变化</strong> </p><p><strong>2. 消费者组信息变化。</strong> </p><p><strong>队列信息</strong>和<strong>消费者组信息</strong>称之为Rebalance元数据，Broker负责维护这些元数据，并在二者信息发生变化时，以某种通知机制告诉消费者组下所有实例，需要进行Rebalance。从这个角度来说，Broker在Rebalance过程中，是一个协调者的角色。</p><h1 id="怎么reblance"><a href="#怎么reblance" class="headerlink" title="怎么reblance"></a>怎么reblance</h1><p>Broker是通知每个消费者各自Rebalance，即每个消费者自己给自己重新分配队列，而不是Broker将分配好的结果告知Consumer。从这个角度，RocketMQ与Kafka Rebalance机制类似，二者Rebalance分配都是在客户端进行，不同的是：</p><ul><li><strong>Kafka：</strong>会在消费者组的多个消费者实例中，选出一个作为Group Leader，由这个Group Leader来进行分区分配，分配结果通过Cordinator(特殊角色的broker)同步给其他消费者。相当于Kafka的分区分配只有一个大脑，就是Group Leader。</li><li><strong>RocketMQ：</strong>每个消费者，自己负责给自己分配队列，相当于每个消费者都是一个大脑。</li></ul><p>如果RocketMQ是去中心化的，必然有如下两个问题：</p><ol><li><p>脑裂：因为每个消费者都不知道其他消费者分配的结果，会不会出现一个队列分配给了多个消费者，或者有的队列分配给了多个消费者。</p></li><li><p>如果某个消费者没有收到Rebalance通知怎么办</p></li></ol><p><strong>只要任意一个消费者组需要Rebalance，这台机器上启动的所有其他消费者，也都要进行Rebalance</strong>。</p><h2 id="单个Topic-Rebalance流程"><a href="#单个Topic-Rebalance流程" class="headerlink" title="单个Topic Rebalance流程"></a><strong>单个Topic Rebalance流程</strong></h2><p>单个Topic的Rebalance流程，是在RebalanceImpl类的rebalanceByTopic方法中进行的，整体上可以分为4大步骤：</p><p>1、从namesrv获取messageQueue信息</p><p>2、从broker获取consumer信息</p><p>3、选择Rebalance策略</p><p>4、三者结合实现Rebalance操作</p><p>消费者在Rebalance时需要获得：Topic的队列信息和消费者组实例信息。</p><p><strong>对于队列信息：</strong></p><p>会从之前的缓存的Topic路由信息中获取；Topic路由信息会定时的进行更新。</p><p><strong>对于消费者组实例信息：</strong></p><p>前面我们提到过Broker通过ConsumerManager维护了所有的消费者信息，findConsumerIdList方法内部会会发送<strong>GET_CONSUMER_LIST_BY_GROUP</strong>给请求给任意一个Broker进行获取。</p><p>每个消费者是自己给自己分配，相当于存在多个大脑。那么如何保证分配结果的一致呢？通过以下两个手段来保证：</p><ul><li>对Topic队列，以及消费者各自进行排序</li><li>每个消费者需要使用相同的分配策略。</li></ul><p>尽管每个消费者是各自给自己分配，但是因为使用的相同的分配策略，定位从队列列表中哪个位置开始给自己分配，给自己分配多少个队列，从而保证最终分配结果的一致。</p><h2 id="出发时机"><a href="#出发时机" class="headerlink" title="出发时机"></a>出发时机</h2><p>简单地来说，RocketMQ有三个时机会触发负载均衡：</p><ol><li><p>启动的时候，会立即触发</p></li><li><p>有消费实例数量的变更的时候。broker在接受到消费者的心跳包的时候如果发现这个实例是新的实例的时候，会广播一个消费者数量变更的事件给所有消费者实例；同理，当发现一个消费者实例的连接断了，也会广播这样的一个事件</p></li><li><p>定期触发（默认20秒）。</p></li></ol><p>第一个时机很好理解。启动的时候，消费者需要需要知道自己要分配什么队列，所以要触发Rebalance。</p><p>第二个时机实际也很好理解。因为有实例的数量变更，所以分配的结果肯定也需要调整的，这时候就要广播给各消费者。</p><p>第三点定期触发的原因实际上是一个补偿机制，为了避免第二点广播的时候因为网络异常等原因丢失了重分配的信号，或者还有别的场景实际上也需要重新计算分配结果（例如队列的数量变化、权限变化），所以需要一个定时任务做补偿。</p><p>所以rocketMQ去中心化Reblance的机制，导致，负载均衡的这个实现原理，就会导致RocketMQ消息重复比一般的消息中间件概率要大，而且严重不少（消息是批量重复的）。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Rebalance是什么&quot;&gt;&lt;a href=&quot;#Rebalance是什么&quot; class=&quot;headerlink&quot; title=&quot;Rebalance是什么&quot;&gt;&lt;/a&gt;&lt;strong&gt;Rebalance是什么&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;Rebalance(再均衡
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="消息队列" scheme="https://arvenseyz.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>RocketMQ NameServer机制</title>
    <link href="https://arvenseyz.github.io/2021/12/09/12-9%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>https://arvenseyz.github.io/2021/12/09/12-9技术笔记/</id>
    <published>2021-12-09T06:32:21.000Z</published>
    <updated>2021-12-10T06:51:35.488Z</updated>
    
    <content type="html"><![CDATA[<h1 id="NameServer的作用"><a href="#NameServer的作用" class="headerlink" title="NameServer的作用"></a><strong>NameServer的作用</strong></h1><p><img src="https://raw.githubusercontent.com/arvenseyz/imageCloud/main/862aa9a7-9185-43af-933c-707030d471d6.png" alt></p><p>可以看到，Broker集群、Producer集群、Consumer集群都需要与NameServer集群进行通信：</p><p><strong>Broker集群</strong></p><p>Broker用于接收生产者发送消息，或者消费者消费消息的请求。一个Broker集群由多组Master/Slave组成，Master可写可读，Slave只可以读，Master将写入的数据同步给Slave。每个Broker节点，在启动时，都会遍历NameServer列表，与每个NameServer建立长连接，注册自己的信息，之后定时上报。</p><p><strong>Producer集群</strong></p><p>消息的生产者，通过NameServer集群获得Topic的路由信息，包括Topic下面有哪些Queue，这些Queue分布在哪些Broker上等。Producer只会将消息发送到Master节点上，因此只需要与Master节点建立连接。</p><p><strong>Consumer集群</strong></p><p>消息的消费者，通过NameServer集群获得Topic的路由信息，连接到对应的Broker上消费消息。注意，由于Master和Slave都可以读取消息，因此Consumer会与Master和Slave都建立连接。</p><h1 id="为什么要使用NameServer"><a href="#为什么要使用NameServer" class="headerlink" title="为什么要使用NameServer"></a><strong>为什么要使用NameServer</strong></h1><p>那么为什么rocketmq选择自己开发一个NameServer，而不是使用这些开源组件呢？</p><p>特别的，RocketMQ设计之初时参考的另一款消息中间件Kafka就使用了Zookeeper，Zookeeper其提供了Master选举、分布式锁、数据的发布和订阅等诸多功能。</p><p>事实上，在RocketMQ的早期版本，即MetaQ 1.x和MetaQ 2.x阶段，也是依赖Zookeeper的。但MetaQ 3.x（即RocketMQ）却去掉了ZooKeeper依赖，转而采用自己的NameServer。</p><p>而RocketMQ的架构设计决定了只需要一个轻量级的元数据服务器就足够了，只需要保持最终一致，而不需要Zookeeper这样的强一致性解决方案，不需要再依赖另一个中间件，从而减少整体维护成本。敏锐的同学肯定已经意识到了，根据CAP理论，RocketMQ在名称服务这个模块的设计上选择了AP，而不是CP。</p><p><strong>Zookeeper CP</strong></p><ul><li>分布式选主，主备高可用切换等场景下有不可替代的作用，而这些需求往往多集中在大数据、离线任务等相关的业务领域，因为大数据领域，讲究分割数据集，并且大部分时间分任务多进程 / 线程并行处理这些数据集，但是总是有一些点上需要将这些任务和进程统一协调，这时候就是 ZooKeeper 发挥巨大作用的用武之地。</li><li>但是在交易场景交易链路上，在主业务数据存取，大规模服务发现、大规模健康监测等方面有天然的短板，应该竭力避免在这些场景下引入 ZooKeeper，在生产实践中，应用对 ZooKeeper 申请使用的时候要进行严格的场景、容量、SLA 需求的评估。</li></ul><p><strong>NameServer AP</strong></p><p>NameServer作为一个名称服务，需要提供服务注册、服务剔除、服务发现这些基本功能，但是NameServer节点之间并不通信，容忍在某个时刻各个节点数据可能不一致的情况下</p><p><strong>所以可以使用 CP，也可以使用AP</strong>，但是大数据使用CP，在线服务则AP，分布式协调、选主使用CP，服务发现使用AP</p><h1 id="NameServer如何保证数据的最终一致"><a href="#NameServer如何保证数据的最终一致" class="headerlink" title="NameServer如何保证数据的最终一致"></a><strong>NameServer如何保证数据的最终一致</strong></h1><p>既然是AP系统，就需要保证最终一致。</p><h3 id="路由注册"><a href="#路由注册" class="headerlink" title="路由注册"></a><strong>路由注册</strong></h3><p>对于Zookeeper、Etcd这样强一致性组件，数据只要写到主节点，内部会通过状态机将数据复制到其他节点，Zookeeper使用的是Zab协议，etcd使用的是raft协议。</p><p>但是NameServer节点之间是互不通信的，无法进行数据复制。RocketMQ采取的策略是，在Broker节点在启动的时候，轮训NameServer列表，与每个NameServer节点建立长连接，发起注册请求。NameServer内部会维护一个Broker表，用来动态存储Broker的信息。</p><p>同时，Broker节点为了证明自己是存活的，会将最新的信息上报给NameServer，然后每隔30秒向NameServer发送心跳包，心跳包中包含 BrokerId、Broker地址、Broker名称、Broker所属集群名称等等，然后NameServer接收到心跳包后，会更新时间戳，记录这个Broker的最新存活时间。</p><p>NameServer在处理心跳包的时候，存在多个Broker同时操作一张Broker表，为了防止并发修改Broker表导致不安全，路由注册操作引入了ReadWriteLock读写锁，这个设计亮点允许多个消息生产者并发读，保证了消息发送时的高并发，但是同一时刻NameServer只能处理一个Broker心跳包，多个心跳包串行处理。这也是读写锁的经典使用场景，即读多写少。</p><h3 id="路由剔除"><a href="#路由剔除" class="headerlink" title="路由剔除"></a><strong>路由剔除</strong></h3><p>正常情况下，如果Broker关闭，则会与NameServer断开长连接，Netty的通道关闭监听器会监听到连接断开事件，然后会将这个Broker信息剔除掉。</p><p>异常情况下，NameServer中有一个定时任务，每隔10秒扫描一下Broker表，如果某个Broker的心跳包最新时间戳距离当前时间超多120秒，也会判定Broker失效并将其移除。</p><p>特别的，对于一些日常运维工作，例如：Broker升级，RocketMQ提供了一种优雅剔除路由信息的方式。如在升级一个Master节点之前，可以先通过命令行工具禁止这个Broker的写权限，发送消息到这个Broker的请求，都会收到一个NO_PERMISSION响应，客户端会自动重试其他的Broker。</p><p>当观察到这个broker没有流量后，再将这个broker移除。</p><h3 id="路由发现"><a href="#路由发现" class="headerlink" title="路由发现"></a><strong>路由发现</strong></h3><p>路由发现是客户端的行为，这里的客户端主要说的是生产者和消费者。具体来说：</p><ul><li>对于生产者，可以发送消息到多个Topic，因此一般是在发送第一条消息时，才会根据Topic获取从NameServer获取路由信息。</li><li>对于消费者，订阅的Topic一般是固定的，所在在启动时就会拉取。</li></ul><p>那么生产者/消费者在工作的过程中，如果路由信息发生了变化怎么处理呢？如：Broker集群新增了节点，节点宕机或者Queue的数量发生了变化。细心的读者注意到，前面讲解NameServer在路由注册或者路由剔除过程中，并不会主动推送会客户端的，这意味着，需要由客户端拉取主题的最新路由信息。</p><p>事实上，RocketMQ客户端提供了定时拉取Topic最新路由信息的机制。</p><h2 id="一致性问题"><a href="#一致性问题" class="headerlink" title="一致性问题"></a>一致性问题</h2><p>定时拉取，还不能解决所有的问题。因为客户端默认是每隔30秒会定时请求NameServer并获取最新的路由表，意味着客户端获取路由信息总是会有30秒的延时。这就带来一个严重的问题，客户端无法实时感知Broker服务器的宕机。如果生产者和消费者在这30秒内，依然会向这个宕机的broker发送或消费消息呢？</p><h1 id="生产者重试机制"><a href="#生产者重试机制" class="headerlink" title="生产者重试机制"></a><strong>生产者重试机制</strong></h1><h2 id="普通消息的重试"><a href="#普通消息的重试" class="headerlink" title="普通消息的重试"></a><strong>普通消息的重试</strong></h2><p>对于普通消息，消息发送默认采用round-robin机制来选择发送到哪一个队列，如果发送失败，默认重试2次。由于之前发送失败的Queue必然位于某个Broker上，在重试过程中，这个失败的Broker上的Queue都不会选择，这里主要是考虑，既然发送到这个Broker上某个Queue失败了，那么发送到这个Broker上的Queue失败的可能性依然很大，所以选择其他Broker。</p><p>但是一定会这样吗？例如Broker集群只是由一组Master/Slave组成，发送消息只会选择Master，如果这个Master失败了，没有其他Master可选，此时依然会选择这个Master上的其他Queue。</p><p>在实际生产环境中，通常Broker集群至少由2组Master/Slave组成，甚至更多，例如我司就是3主3从。这样就可以很好的利用RocketMQ对于普通消息发送的重试机制，每次重试到不同的Broker上。</p><p>事情到这里并没有结束，这段代码只是单次发送消息失败重试选择队列的逻辑。实际情况可能是，在Broker宕机期间，可能会发送多条消息，那么每次都可能会选择到失败的Broker上的Queue，然后再重试，尽管重试可能会成功，但是每次发送消息的耗时会增加。因此，MQFaultStrategy实际上还提供了以下两个功能(超出本文范畴，将会后续其他文章中讲解)：</p><ul><li>失败隔离：即发送消息到某个broker失败之后，将其进行隔离，优先从其他正常的broker中进行选择</li><li>延迟隔离：优先发送消息到延迟比较小的broker</li></ul><p>对于无序消息，通过这种异常重试机制，就可以保证消息发送的高可用了。同时由于不需要NameServer通知众多不固定的生产者，也降低了NameServer实现的复杂性。</p><p><strong>既然重试机制有这么明显的好处，那么对于普通有序消息，和严格有序消息，rocketmq为什么默认不进行重试呢？</strong></p><p>答案很简单，这些消息只能发送某个特定的Broker上的某个特定的Queue中，如果发送失败，重试失败的可能依然很大，所以默认不进行重试。如果需要重试，需要业务方自己来做。</p><h2 id="普通有序消息失败情况下的短暂无序"><a href="#普通有序消息失败情况下的短暂无序" class="headerlink" title="普通有序消息失败情况下的短暂无序"></a><strong>普通有序消息失败情况下的短暂无序</strong></h2><p>首先说明，对于普通有序消息，RocketMQ是不会进行重试的。如果需要重试，那么业务RD同学需要自己编写重试代码，例如通过一个for循环，最多重试几次。<strong>但是业务自己的重试是有问题的，即会破坏消息的有序性。</strong></p><p>这里主要说明：对于普通有序消息，在异常情况下，如何经历短暂无序之后再恢复有序。</p><p><strong>异常情况下的短暂无序</strong></p><p>在异常情况下，例如一个Broker宕机，路由信息刷新后，这个Broker上队列就会从List集合中移除。此时按照相同的方式选择队列，就会选择到其他队列上，造成了无序。但是这个无序是很短暂的，因为之后同一个用户的信息，都会发送到同一个新的队列上。</p><p>如果宕机的broker恢复了，那么再次经历一下短暂无序，之后又变得有序了。</p><h2 id="严格有序消息的重试"><a href="#严格有序消息的重试" class="headerlink" title="严格有序消息的重试"></a><strong>严格有序消息的重试</strong></h2><p>对于严格有序消息，由于直接指定了一个MessageQueue。如果这个MessageQueue所在的Broker宕机了，那么之后的重试必然都失败，只有无限重试，直到成功。因此，非必要的情况下，是不建议使用严格有序消息的。</p><h1 id="客户端NameServer选择策略"><a href="#客户端NameServer选择策略" class="headerlink" title="客户端NameServer选择策略"></a><strong>客户端NameServer选择策略</strong></h1><p>前面讲解了客户端在获取路由信息时，每次都会尝试先从缓存的路由表中查找Topic路由信息，如果找不到，那么就去NameServer更新尝试。</p><p>具体选择哪个NameServer，也是使用round-robin的策略。需要注意的是，尽管使用round-robin策略，但是在选择了一个NameServer节点之后，后面总是会优先选择这个NameServer，除非与这个NameServer节点通信出现异常的情况下，才会选择其他节点。</p><p>为什么客户端不与所有NameServer节点建立连接呢，而是只选择其中一个？可能是，通常NameServer节点是固定的几个，但是客户端的数量可能是成百上千，为了减少每个NameServer节点的压力，所以每个客户端节点只随机与其中一个NameServer节点建立连接。</p><p>为了尽可能保证NameServer集群每个节点的负载均衡，在round-robin策略选择时，每个客户端的初始随机位置都不同。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">private final AtomicInteger namesrvIndex = new AtomicInteger(initValueIndex());</span><br></pre></td></tr></table></figure><p>其中initValueIndex()就是计算一个随机值，之后每次选择NameServer时，namesrvIndex+1之后，对namesrvAddrList取模，计算在数据下标的位置，尝试创建连接，一旦创建成功，会将当前选择的NameServer地址记录到namesrvAddrChoosed字段中：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">private final AtomicReference&lt;String&gt; namesrvAddrChoosed = new AtomicReference&lt;String&gt;();</span><br></pre></td></tr></table></figure><p>如果某个NameServer节点创建连接失败是，会自动重试其他节点。具体可参见：getAndCreateNameserverChannel 。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;NameServer的作用&quot;&gt;&lt;a href=&quot;#NameServer的作用&quot; class=&quot;headerlink&quot; title=&quot;NameServer的作用&quot;&gt;&lt;/a&gt;&lt;strong&gt;NameServer的作用&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;&lt;img src=
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="消息队列" scheme="https://arvenseyz.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>ES聚合搜索</title>
    <link href="https://arvenseyz.github.io/2021/12/01/12-1%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>https://arvenseyz.github.io/2021/12/01/12-1技术笔记/</id>
    <published>2021-12-01T07:17:13.000Z</published>
    <updated>2021-12-01T08:09:07.725Z</updated>
    
    <content type="html"><![CDATA[<h2 id="指标和桶"><a href="#指标和桶" class="headerlink" title="指标和桶"></a>指标和桶</h2><p>es的聚合操作是aggs，是aggregations的简写。</p><p>聚合简单分为两部分，指标和桶。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">COUNT</span>(color) </span><br><span class="line"><span class="keyword">FROM</span> <span class="keyword">table</span> </span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> color</span><br></pre></td></tr></table></figure><p>group by color相当于桶。</p><p><em>桶</em>  简单来说就是满足特定条件的文档的集合：</p><ul><li>一个雇员属于  <em>男性</em>  桶或者  <em>女性</em>  桶</li><li>奥尔巴尼属于  <em>纽约</em>  桶</li><li>日期2014-10-28属于  <em>十月</em>  桶</li></ul><p>COUNT(color)相当于指标</p><p>大多数 <em>指标</em> 是简单的数学运算（例如最小值、平均值、最大值，还有汇总）</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">GET /cars/transactions/_search</span><br><span class="line">&#123;</span><br><span class="line">   <span class="attr">"size"</span> : <span class="number">0</span>,</span><br><span class="line">   <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">      <span class="attr">"colors"</span>: &#123;</span><br><span class="line">         <span class="attr">"terms"</span>: &#123;</span><br><span class="line">            <span class="attr">"field"</span>: <span class="string">"color"</span></span><br><span class="line">         &#125;,</span><br><span class="line">         <span class="attr">"aggs"</span>: &#123; </span><br><span class="line">            <span class="attr">"avg_price"</span>: &#123; </span><br><span class="line">               <span class="attr">"avg"</span>: &#123;</span><br><span class="line">                  <span class="attr">"field"</span>: <span class="string">"price"</span> </span><br><span class="line">               &#125;</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">...</span><br><span class="line">   "aggregations": &#123;</span><br><span class="line">      "colors": &#123;</span><br><span class="line">         "buckets": [</span><br><span class="line">            &#123;</span><br><span class="line">               <span class="attr">"key"</span>: <span class="string">"red"</span>,</span><br><span class="line">               <span class="attr">"doc_count"</span>: <span class="number">4</span>,</span><br><span class="line">               <span class="attr">"avg_price"</span>: &#123; </span><br><span class="line">                  <span class="attr">"value"</span>: <span class="number">32500</span></span><br><span class="line">               &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">               <span class="attr">"key"</span>: <span class="string">"blue"</span>,</span><br><span class="line">               <span class="attr">"doc_count"</span>: <span class="number">2</span>,</span><br><span class="line">               <span class="attr">"avg_price"</span>: &#123;</span><br><span class="line">                  <span class="attr">"value"</span>: <span class="number">20000</span></span><br><span class="line">               &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">               <span class="attr">"key"</span>: <span class="string">"green"</span>,</span><br><span class="line">               <span class="attr">"doc_count"</span>: <span class="number">2</span>,</span><br><span class="line">               <span class="attr">"avg_price"</span>: &#123;</span><br><span class="line">                  <span class="attr">"value"</span>: <span class="number">21000</span></span><br><span class="line">               &#125;</span><br><span class="line">            &#125;</span><br><span class="line">         ]</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>第一个aggs里的term，就是指定桶，即按color分桶。</p><p>第二个aggs就是指标了，avg是聚合函数。</p><h2 id="过滤"><a href="#过滤" class="headerlink" title="过滤"></a>过滤</h2><p>过滤有两种，聚合前过滤和聚合后过滤，即对应sql里的where和having</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">GET /cars/transactions/_search</span><br><span class="line">&#123;</span><br><span class="line">   <span class="attr">"size"</span> : <span class="number">0</span>,</span><br><span class="line">   <span class="attr">"query"</span>:&#123;</span><br><span class="line">      <span class="attr">"match"</span>: &#123;</span><br><span class="line">         <span class="attr">"make"</span>: <span class="string">"ford"</span></span><br><span class="line">      &#125;</span><br><span class="line">   &#125;,</span><br><span class="line">   <span class="attr">"aggs"</span>:&#123;</span><br><span class="line">      <span class="attr">"recent_sales"</span>: &#123;</span><br><span class="line">         <span class="attr">"filter"</span>: &#123; </span><br><span class="line">            <span class="attr">"range"</span>: &#123;</span><br><span class="line">               <span class="attr">"sold"</span>: &#123;</span><br><span class="line">                  <span class="attr">"from"</span>: <span class="string">"now-1M"</span></span><br><span class="line">               &#125;</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;,</span><br><span class="line">         <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">            <span class="attr">"average_price"</span>:&#123;</span><br><span class="line">               <span class="attr">"avg"</span>: &#123;</span><br><span class="line">                  <span class="attr">"field"</span>: <span class="string">"price"</span> </span><br><span class="line">               &#125;</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>即只有时间在现在到一个月前的数据会被聚合。</p><p>实际上过滤器可以直接写在query里，似乎性能更好。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">GET /cars/transactions/_search</span><br><span class="line">&#123;</span><br><span class="line">    <span class="attr">"size"</span> : <span class="number">0</span>,</span><br><span class="line">    <span class="attr">"query"</span>: &#123;</span><br><span class="line">        <span class="attr">"match"</span>: &#123;</span><br><span class="line">            <span class="attr">"make"</span>: <span class="string">"ford"</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"post_filter"</span>: &#123;    </span><br><span class="line">        <span class="attr">"term"</span> : &#123;</span><br><span class="line">            <span class="attr">"color"</span> : <span class="string">"green"</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"aggs"</span> : &#123;</span><br><span class="line">        <span class="attr">"all_colors"</span>: &#123;</span><br><span class="line">            <span class="attr">"terms"</span> : &#123; <span class="attr">"field"</span> : <span class="string">"color"</span> &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>即只看green的</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;指标和桶&quot;&gt;&lt;a href=&quot;#指标和桶&quot; class=&quot;headerlink&quot; title=&quot;指标和桶&quot;&gt;&lt;/a&gt;指标和桶&lt;/h2&gt;&lt;p&gt;es的聚合操作是aggs，是aggregations的简写。&lt;/p&gt;
&lt;p&gt;聚合简单分为两部分，指标和桶。&lt;/p&gt;
&lt;fig
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="ES" scheme="https://arvenseyz.github.io/tags/ES/"/>
    
  </entry>
  
  <entry>
    <title>执行计划的extra</title>
    <link href="https://arvenseyz.github.io/2021/11/30/11-30%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>https://arvenseyz.github.io/2021/11/30/11-30技术笔记-1/</id>
    <published>2021-11-30T07:57:33.000Z</published>
    <updated>2021-12-01T07:17:21.217Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Using-fileSort"><a href="#Using-fileSort" class="headerlink" title="Using fileSort"></a>Using fileSort</h2><p>使用文件排序，是指拿到这些行后再排序，具体在哪排，内存还是磁盘，取决于大小，所有列还是排序列+id再回表取决于代价</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> t1 <span class="keyword">order</span> <span class="keyword">by</span> create_time</span><br></pre></td></tr></table></figure><h2 id="Using-temporary"><a href="#Using-temporary" class="headerlink" title="Using temporary"></a>Using temporary</h2><p>需要临时表来储存结构，比如对没有索引的列来group by</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> t1 <span class="keyword">group</span> <span class="keyword">by</span> create_time</span><br></pre></td></tr></table></figure><h2 id="Using-index"><a href="#Using-index" class="headerlink" title="Using index"></a>Using index</h2><p>使用覆盖索引，即索引树上即可拿到字段，无需回表</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> a <span class="keyword">from</span> t1 <span class="keyword">where</span> a =<span class="number">11</span></span><br></pre></td></tr></table></figure><h2 id="Using-where"><a href="#Using-where" class="headerlink" title="Using where"></a>Using where</h2><p>意味着全表扫描或者在查找使用索引的情况下，但是还有查询条件不在索引字段当中.</p><p>Using where: 仅仅表示MySQL服务器在收到存储引擎返回的记录后进行“后过滤”。</p><p><strong>1： 查询条件中的相关列，不是索引字段， 全表扫描后，通过Using where过滤获取所需的数据。</strong></p><p>通俗来说，因为字段D没有索引，所以必须全表扫描，然后在服务器层使用WHERE过滤数据。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">COUNT</span>(*) <span class="keyword">FROM</span> <span class="keyword">TEST</span> <span class="keyword">WHERE</span> D = <span class="string">'2000-01-01'</span>;</span><br></pre></td></tr></table></figure><p>2： <strong>（type=ref)非唯一性索引扫描，但是由于索引未覆盖所有查询条件(字段d并未包含在聚集索引</strong>PRIMARY中**)，在存储引擎返回记录后，仍然需要过滤数据。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">COUNT</span>(i1) <span class="keyword">FROM</span> <span class="keyword">TEST</span> <span class="keyword">WHERE</span> i1 = <span class="number">3</span> <span class="keyword">AND</span> d &gt; <span class="number">321</span></span><br></pre></td></tr></table></figure><h2 id="Using-index-condition"><a href="#Using-index-condition" class="headerlink" title="Using index condition"></a>Using index condition</h2><p>索引下推。存储引擎在访问索引的时候检查筛选字段在索引中的WHERE条件</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> t1 <span class="keyword">where</span> age&gt;<span class="number">9</span> <span class="keyword">and</span> <span class="keyword">name</span> <span class="keyword">like</span> <span class="string">'%张'</span></span><br></pre></td></tr></table></figure><p>即使建立了age和name的联合索引，该查询也只会走age，但是在走age的时候，它可以把name条件带上，顺便就筛了。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Using-fileSort&quot;&gt;&lt;a href=&quot;#Using-fileSort&quot; class=&quot;headerlink&quot; title=&quot;Using fileSort&quot;&gt;&lt;/a&gt;Using fileSort&lt;/h2&gt;&lt;p&gt;使用文件排序，是指拿到这些行后再排序，具体在
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="数据库" scheme="https://arvenseyz.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>图数据库基础语法</title>
    <link href="https://arvenseyz.github.io/2021/10/25/10-25%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-2/"/>
    <id>https://arvenseyz.github.io/2021/10/25/10-25技术笔记-2/</id>
    <published>2021-10-25T10:28:27.000Z</published>
    <updated>2021-10-26T07:20:42.291Z</updated>
    
    <content type="html"><![CDATA[<h2 id="图数据库优势"><a href="#图数据库优势" class="headerlink" title="图数据库优势"></a>图数据库优势</h2><p><a href="https://imgtu.com/i/54fgPS" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/10/25/54fgPS.png" alt="54fgPS.png"></a></p><ul><li><p>关系复杂的模型用图的形式表达容易</p></li><li><p>关系查询性能可控（<strong><em>我的好友所在的公司有多少名员工？</em></strong>）</p></li></ul><h2 id="图数据库基本语法"><a href="#图数据库基本语法" class="headerlink" title="图数据库基本语法"></a>图数据库基本语法</h2><h3 id="基本定义"><a href="#基本定义" class="headerlink" title="基本定义"></a>基本定义</h3><ul><li><p>由点(Vertex)、边(Edge)、属性(Property)构成；</p></li><li><p>点(Vertex)是实体、概念对象</p></li><li><p>&lt;type(uint32_t), ID(uint64_t&gt; 二元组唯一标记一个点</p></li><li><p>type标记了一类点的集合，可以把type理解为table，不同type，是不同table</p></li><li><p>属性：点上可以有多种属性，属性可以是常见基本类型，</p></li><li><p>schema: 同一种type的点，其属性key以及属性类型必须一致</p></li><li><p>边(Edge)是点之间的关系、联系</p></li><li><p>边有起点+终点，边上类型，type（string）；和点一样，同样的type类型的边必须有同样的属性属性：和点上属性一样，支持多种基本类型</p></li></ul><h3 id="germlin语法"><a href="#germlin语法" class="headerlink" title="germlin语法"></a>germlin语法</h3><p>gremlin语言是图遍历（traverse）式语言，简单起见，可以理解为，先在图上定位到一个点，然后从这个点开始做图上的深度/宽度遍历，在图上每一步遍历用step来描述，不同的step有不同的功能，用step的组合来实现图上游走</p><h3 id="创建一个天龙八部人物图"><a href="#创建一个天龙八部人物图" class="headerlink" title="创建一个天龙八部人物图"></a>创建一个天龙八部人物图</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Gremlin: g.addV().property(&apos;id&apos;, 1001).property(&apos;type&apos;, 5).property(&apos;name&apos;, &apos;段正淳&apos;).property(&apos;power&apos;, 60).toList()</span><br><span class="line">Gremlin: g.addV().property(&apos;id&apos;, 1002).property(&apos;type&apos;, 5).property(&apos;name&apos;, &apos;段延庆&apos;).property(&apos;power&apos;, 75).toList()</span><br><span class="line">Gremlin: g.addV().property(&apos;id&apos;, 1003).property(&apos;type&apos;, 5).property(&apos;name&apos;, &apos;王语嫣&apos;).property(&apos;power&apos;, 2).toList()</span><br><span class="line">Gremlin: g.addV().property(&apos;id&apos;, 1004).property(&apos;type&apos;, 5).property(&apos;name&apos;, &apos;阿朱&apos;).property(&apos;power&apos;, 5).toList()</span><br><span class="line">Gremlin: g.addV().property(&apos;id&apos;, 1005).property(&apos;type&apos;, 5).property(&apos;name&apos;, &apos;段誉&apos;).property(&apos;power&apos;, 80).toList()</span><br><span class="line">Gremlin: g.addV().property(&apos;id&apos;, 1006).property(&apos;type&apos;, 5).property(&apos;name&apos;, &apos;叶二娘&apos;).property(&apos;power&apos;, 40).toList()</span><br><span class="line">Gremlin: g.addV().property(&apos;id&apos;, 1007).property(&apos;type&apos;, 5).property(&apos;name&apos;, &apos;乔峰&apos;).property(&apos;power&apos;, 90).toList()</span><br><span class="line">Gremlin: g.addV().property(&apos;id&apos;, 1008).property(&apos;type&apos;, 5).property(&apos;name&apos;, &apos;虚竹&apos;).property(&apos;power&apos;, 85).toList()</span><br><span class="line">Gremlin: g.addE(&apos;relatives&apos;).from(1001, 5).to(1002, 5).property(&apos;relation&apos;, &apos;兄弟&apos;).toList()</span><br><span class="line">Gremlin: g.addE(&apos;relatives&apos;).from(1001, 5).to(1003, 5).property(&apos;relation&apos;, &apos;父女&apos;).toList()</span><br><span class="line">Gremlin: g.addE(&apos;relatives&apos;).from(1001, 5).to(1004, 5).property(&apos;relation&apos;, &apos;父女&apos;).toList()</span><br><span class="line">Gremlin: g.addE(&apos;relatives&apos;).from(1002, 5).to(1005, 5).property(&apos;relation&apos;, &apos;父子&apos;).toList()</span><br><span class="line">Gremlin: g.addE(&apos;relatives&apos;).from(1002, 5).to(1006, 5).property(&apos;relation&apos;, &apos;义妹&apos;).toList()</span><br><span class="line">Gremlin: g.addE(&apos;relatives&apos;).from(1003, 5).to(1005, 5).property(&apos;relation&apos;, &apos;夫妻&apos;).toList()</span><br><span class="line">Gremlin: g.addE(&apos;relatives&apos;).from(1004, 5).to(1007, 5).property(&apos;relation&apos;, &apos;夫妻&apos;).toList()</span><br><span class="line">Gremlin: g.addE(&apos;relatives&apos;).from(1005, 5).to(1008, 5).property(&apos;relation&apos;, &apos;结拜兄弟&apos;).toList()</span><br><span class="line">Gremlin: g.addE(&apos;relatives&apos;).from(1006, 5).to(1008, 5).property(&apos;relation&apos;, &apos;母子&apos;).toList()</span><br><span class="line">Gremlin: g.addE(&apos;relatives&apos;).from(1007, 5).to(1005, 5).property(&apos;relation&apos;, &apos;结拜兄弟&apos;).toList()</span><br><span class="line">Gremlin: g.addE(&apos;relatives&apos;).from(1008, 5).to(1007, 5).property(&apos;relation&apos;, &apos;结拜兄弟&apos;).toList()</span><br></pre></td></tr></table></figure><h3 id="查询语法"><a href="#查询语法" class="headerlink" title="查询语法"></a>查询语法</h3><p>查询点类型是5，id是1005的点，以及它的属性（查询属性时，指定属性名性能更好，原因估计是下文的点切割）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">g.V(vertex(1001,5)).toList()</span><br><span class="line">Result: [Vertex&#123;Id:1001, Type:5&#125;]</span><br><span class="line">g.V(vertex(1001,5)).properties()</span><br><span class="line">Result: [Property&#123;Key:name, Value:&quot;段正淳&quot;&#125;, Property&#123;Key:power, Value:60&#125;]</span><br></pre></td></tr></table></figure><h3 id="遍历"><a href="#遍历" class="headerlink" title="遍历"></a>遍历</h3><p>如上文，操作是定位一个点，然后再图上游走</p><p><a href="https://imgtu.com/i/5If0bR" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/10/26/5If0bR.png" alt="5If0bR.png"></a></p><p>定位一个点后，找到它的出边，即段正淳的关系</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">» g.V(vertex(1001,5)).outE(&quot;relatives&quot;)</span><br><span class="line">Result: [Edge&#123;OutV:Vertex&#123;Id:1001, Type:5&#125;, InV:Vertex&#123;Id:1004, Type:5&#125;, Type:relatives&#125;, Edge&#123;OutV:Vertex&#123;Id:1001, Type:5&#125;, InV:Vertex&#123;Id:1003, Type:5&#125;, Type:relatives&#125;, Edge&#123;OutV:Vertex&#123;Id:1001, Type:5&#125;, InV:Vertex&#123;Id:1002, Type:5&#125;, Type:relatives&#125;]</span><br></pre></td></tr></table></figure><p>找到一个点某种类型过滤属性的边，即段正淳的兄弟关系</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">» g.V(vertex(1001,5)).outE(&quot;relatives&quot;).has(&apos;relation&apos;,&apos;兄弟&apos;).toList()</span><br><span class="line">Result: [Edge&#123;OutV:Vertex&#123;Id:1001, Type:5&#125;, InV:Vertex&#123;Id:1002, Type:5&#125;, Type:relatives&#125;]</span><br></pre></td></tr></table></figure><p>进一步，找到段正淳的兄弟</p><p>遍历法，找到兄弟边，再找到兄弟边链接的点</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">» g.V(vertex(1001,5)).outE(&quot;relatives&quot;).has(&apos;relation&apos;,&apos;兄弟&apos;).inV().toList()</span><br><span class="line">Result: [Vertex&#123;Id:1002, Type:5&#125;]</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;图数据库优势&quot;&gt;&lt;a href=&quot;#图数据库优势&quot; class=&quot;headerlink&quot; title=&quot;图数据库优势&quot;&gt;&lt;/a&gt;图数据库优势&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://imgtu.com/i/54fgPS&quot; target=&quot;_blank&quot; r
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="图数据库" scheme="https://arvenseyz.github.io/tags/%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>redis的redlock锁</title>
    <link href="https://arvenseyz.github.io/2021/10/11/10-11%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>https://arvenseyz.github.io/2021/10/11/10-11技术笔记-1/</id>
    <published>2021-10-11T08:49:43.000Z</published>
    <updated>2021-10-25T10:30:15.259Z</updated>
    
    <content type="html"><![CDATA[<ul><li><h3 id="加锁"><a href="#加锁" class="headerlink" title="加锁"></a>加锁</h3></li></ul><p>官方推荐至少 5 个redis实例，而且都是主库，它们之间没有任何关系，都是一个个孤立的实例，流程如下：</p><ol><li>客户端先获取「当前时间戳T1」。</li><li>客户端依次向这 5 个 Redis 实例发起加锁请求（SET命令），且每个请求会设置超时时间（毫秒级，要远小于锁的有效时间），如果某一个实例加锁失败（包括网络超时、锁被其它人持有等各种异常情况），就立即向下一个 Redis 实例申请加锁。</li><li>如果客户端从 3 个（大多数）以上 Redis 实例加锁成功，则再次获取「当前时间戳T2」，如果 T2 - T1 &lt; 锁的过期时间，此时，认为客户端加锁成功，否则认为加锁失败。</li><li>加锁成功，去操作共享资源（例如修改 MySQL 某一行，或发起一个 API 请求）。</li><li>加锁失败，向全部节点发起释放锁请求。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;&lt;h3 id=&quot;加锁&quot;&gt;&lt;a href=&quot;#加锁&quot; class=&quot;headerlink&quot; title=&quot;加锁&quot;&gt;&lt;/a&gt;加锁&lt;/h3&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;官方推荐至少 5 个redis实例，而且都是主库，它们之间没有任何关系，都是一个个孤立的实例，流程
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="redis" scheme="https://arvenseyz.github.io/tags/redis/"/>
    
      <category term="分布式" scheme="https://arvenseyz.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>redis分布式锁</title>
    <link href="https://arvenseyz.github.io/2021/10/09/10-9%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>https://arvenseyz.github.io/2021/10/09/10-9技术笔记-1/</id>
    <published>2021-10-09T06:52:04.000Z</published>
    <updated>2021-10-11T08:50:16.995Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Redis是AP系统"><a href="#Redis是AP系统" class="headerlink" title="Redis是AP系统"></a>Redis是AP系统</h2><p>先抛个结论：</p><p>“redis多机房同步是最终一致的，如有分布式锁的需求，会有锁不上的情况，业务可根据文档考虑使用强一致的存储组件！” from redis 用户文档</p><p>因此redis锁只能作为弱校验，而不能作为强依赖，必须要其他强一致的系统保证其一致性。</p><h2 id="Redis锁实现原理"><a href="#Redis锁实现原理" class="headerlink" title="Redis锁实现原理"></a>Redis锁实现原理</h2><p>而redis锁锁不住的原因要从redis锁的实现讲起。redis锁主要基于两个命令，<strong>setnx &amp;</strong> <strong>cad</strong>，（注意不是redlock，redlock和这两个命令没有关系，下面最后一个部分会提）</p><p><strong>加锁setnx</strong></p><p>setnx命令会被redis client解析为</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SET key value NX PX 30000</span><br></pre></td></tr></table></figure><ul><li>其中key通常为我们想锁住的<code>key</code>，而<code>value</code>应当为一个随机数，原因在解锁的部分讲</li><li><code>NX</code>代表只有key为空时才会set成功</li><li><code>PX 30000</code> 指过期时间30s</li></ul><p><strong>解锁</strong>  <strong>cad</strong> <strong>（已被公司级别支持）</strong></p><p>cad指<code>compare and delete</code>操作，该操作其实内部执行Redis lua脚本保证cad操作的中不会被其他操作穿插</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">if redis.call(&quot;get&quot;,KEYS[1]) == ARGV[1] then </span><br><span class="line">  return redis.call(&quot;del&quot;,KEYS[1])</span><br><span class="line">else </span><br><span class="line">  return 0 </span><br><span class="line">end</span><br></pre></td></tr></table></figure><ul><li>为什么锁还需要设置随机<code>value</code>去compare？因为虽然redis数据库单线程，但是客户端却可能为多线程，试想以下逻辑：</li></ul><p><a href="https://imgtu.com/i/5FANLj" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/10/09/5FANLj.png" alt="5FANLj.png"></a></p><p>若发生以上时序，client1由于处理请求时被阻塞，导致client2获取的锁会被client1解锁，进而导致锁失效。特别是我们应用代码中通常设置的时长较短（1s - 5s），更增加以上情况出现的几率。</p><ul><li>i/o timeout如何做？</li></ul><p>有些人会觉得奇怪为什么上面的这段代码没有做错误校验，正确的做法是不是应该是这样？</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">err := redis.SetNX(key, value, duration)</span><br><span class="line">if err != nil &#123;</span><br><span class="line">    return </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其实不然，试想<code>SetNX</code> 发生timeout，但其实Redis客户端<strong>收到</strong>该请求，只是respond<strong>回复超时</strong>，该锁会一直被持有直到timeout。</p><p>比较正确的逻辑为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">err := redis.SetNX(key, randomNum, duration)</span><br><span class="line">defer redis.CAD(key, randomNum)</span><br><span class="line">if err != nil &#123;</span><br><span class="line">    return </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>由randomNum来保证key有且仅会被本客户端线程解锁，即使失败，也不会把其他客户端线程的锁unlock（因为randomNum不一致，compare阶段错误）。该逻辑更体现了设置randomNum为value的必要性。这个随机数应当可以保证在一段时间内只被同一client持有，比较偷懒的方法是使用server id + unix microsecond时间戳，在大部分场景下应该足够了。</p><ul><li>Expire time如何定？</li></ul><p>其实这也是个两难问题，若超时时间过短，则锁不住整个流程处理时间，可能被抢锁；若超时时间过长，则解锁操作<code>redis.CAD(key, randomNum)</code>失败时，会导致key被锁住过长时间。因此需根据实际业务场景而定。</p><h2 id="分布式redis情况如何？"><a href="#分布式redis情况如何？" class="headerlink" title="分布式redis情况如何？"></a>分布式redis情况如何？</h2><p>即使我们在实现上都按照完美的路径，以上实现也是基于单机情况，在分布式场景下，由于redis多机房同步是最终一致的，当主节点不可用时，系统自动切换到副节点（即failover的过程），由于主从非同步，在failover的过程中会导致锁被抢。试想以下时序：</p><ol><li>master拿到锁a</li><li>slave1-master同步开启</li><li>master宕机，failover开始</li><li>slave1-master同步未完成</li><li>slave1被选举为master，锁a丢失，可被抢</li></ol><p>虽然很多人觉得failover的情况很少，以上可以忽略，实际上根据我们现在的使用方法，某个历史活动的并发情况而言，已经出现大量的并发锁被抢引起的错误（日均300+，from QPS大概400左右的并发请求）。</p><h2 id="正确姿势如何做？"><a href="#正确姿势如何做？" class="headerlink" title="正确姿势如何做？"></a>正确姿势如何做？</h2><p>redis针对单机redis锁的问题，提出了redlock的解决方案，但是redlock也有些争议，同时其不太适合公司的redis架构，在这里不多做讨论。</p><p>如果要了解正确的锁姿势，首先要分析分布式锁的场景，一般来说，可以分为两种，为了效率加锁，和为了正确性加锁。</p><ul><li>为效率加锁，即为了一些计算的重复；即使失败，也只是把某些操作多做一遍，例如条件多校验一遍</li><li>为了正确性加锁，即不允许分布式锁失败；若失败可能产生不可回滚的脏数据</li></ul><p>若为了效率加锁，使用单机的redis锁已经足够，单重要的是清楚单机redis锁在分布式场景下的限制。</p><p>若为了正确性加锁，一定要使用强一致性保障（bytekv，zookeeper）等，基架推荐尝试bytekv。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Redis是AP系统&quot;&gt;&lt;a href=&quot;#Redis是AP系统&quot; class=&quot;headerlink&quot; title=&quot;Redis是AP系统&quot;&gt;&lt;/a&gt;Redis是AP系统&lt;/h2&gt;&lt;p&gt;先抛个结论：&lt;/p&gt;
&lt;p&gt;“redis多机房同步是最终一致的，如有分布式锁
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="redis" scheme="https://arvenseyz.github.io/tags/redis/"/>
    
      <category term="分布式" scheme="https://arvenseyz.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>es打分方式</title>
    <link href="https://arvenseyz.github.io/2021/09/27/9-27%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-3/"/>
    <id>https://arvenseyz.github.io/2021/09/27/9-27技术笔记-3/</id>
    <published>2021-09-27T09:19:34.000Z</published>
    <updated>2021-09-27T09:28:45.295Z</updated>
    
    <content type="html"><![CDATA[<h2 id="计算公式"><a href="#计算公式" class="headerlink" title="计算公式"></a>计算公式</h2><p><code>Lucene</code>和<code>es</code>的打分机制是一个公式。将查询作为输入，使用不同的手段来确定每一篇文档的得分，将每一个因素最后通过公式综合起来，返回该文档的最终得分。这个综合考量的过程，就是我们希望相关的文档被优先返回的考量过程。在<code>Lucene</code>和<code>es</code>中这种相关性称为得分。<br>在开始计算得分之前，<code>es</code>使用了被搜索词条的频率和它有多常见来影响得分，从两个方面理解：</p><ul><li>一个词条在某篇文档中出现的次数越多，该文档就越相关。</li><li>一个词条如果在不同的文档中出现的次数越多，它就越不相关！</li></ul><p>我们称之为<code>TF-IDF</code>，<code>TF</code>是词频（term frequency），而<code>IDF</code>是逆文档频率（inverse document frequency）。</p><p>此外还有两个因素</p><ul><li><p><strong>Document Frequency(DF)文档频率</strong>：即单词出现的文档数。</p></li><li><p><strong>Field-length Norm</strong>：文档越短，相关性越高，field长度，field越长，相关度越弱</p></li></ul><p>逆文档词频是一个重要的因素，用来平衡词条的词频。比如我们搜索<code>the 996.ICU</code>。单词<code>the</code>几乎出现在所有的文档中（中文中比如<code>的</code>），如果这个鬼东西要不被均衡一下，那么<code>the</code>的频率将完全淹没<code>996.ICU</code>。所以，逆文档词频就有效的均衡了<code>the</code>这个常见词的相关性影响。以达到实际的相关性得分将会对查询的词条有一个更准确地描述。<br>当词频和逆文档词频计算完成。就可以使用<code>TF-IDF</code>公式来计算文档的得分了</p><p>我们通过<code>explain=true</code>，es会返回如何打分的</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">GET py1/doc/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"match"</span>: &#123;</span><br><span class="line">      <span class="attr">"title"</span>: <span class="string">"北京"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"explain"</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="attr">"_source"</span>: <span class="string">"title"</span>, </span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>会返回一个复杂的公式。</p><h2 id="手动控制"><a href="#手动控制" class="headerlink" title="手动控制"></a>手动控制</h2><p>通过boosting可以人为控制某个字段的在评分过程中的比重，有两种类型：</p><ul><li><p>索引期间的boosting</p></li><li><p>查询期间的boosting</p></li></ul><p>通过在mapping中设置boost参数，可以在索引期间改变字段的评分权重：</p><p>一旦映射建立完成，那么所有name字段都会自动拥有一个boost值，并且是以降低精度的数值存储在Lucene内部的索引结构中。只有一个字节用于存储浮点型数值（存不下就损失精度了），计算文档的最终得分时可能会损失精度。</p><p>另外，boost是应用与词条的。因此，再被boost的字段中如果匹配上了多个词条，就意味着计算多次的boost，这将会进一步增加字段的权重，可能会影响最终的文档得分。</p><p>查询期间的boosting可以避免上述问题。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;计算公式&quot;&gt;&lt;a href=&quot;#计算公式&quot; class=&quot;headerlink&quot; title=&quot;计算公式&quot;&gt;&lt;/a&gt;计算公式&lt;/h2&gt;&lt;p&gt;&lt;code&gt;Lucene&lt;/code&gt;和&lt;code&gt;es&lt;/code&gt;的打分机制是一个公式。将查询作为输入，使用不同的手段来
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="ES" scheme="https://arvenseyz.github.io/tags/ES/"/>
    
  </entry>
  
  <entry>
    <title>ES段和段合并</title>
    <link href="https://arvenseyz.github.io/2021/09/24/9-24%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>https://arvenseyz.github.io/2021/09/24/9-24技术笔记-1/</id>
    <published>2021-09-24T06:56:04.000Z</published>
    <updated>2021-09-24T07:11:44.965Z</updated>
    
    <content type="html"><![CDATA[<h1 id="segment"><a href="#segment" class="headerlink" title="segment"></a>segment</h1><p>lucene内部的数据是由⼀个个segment组成的，写⼊lucene的数据并不直接落盘，⽽是先写在内存中，经过了refresh间隔，lucene才将该时间段写⼊的全部数据refresh成⼀个segment，segment多了之后会进⾏merge成更⼤的segment。</p><p>lucene查询时会遍历每个segment完成。由于lucene写⼊的数据是在内存中完成，所以写⼊效率⾮常⾼。但是也存在丢失数据的⻛险，所以Elasticsearch基于此现象实现了translog，只有在segment数据落盘后，Elasticsearch才会删除对应的translog。</p><ul><li><p>每个分片都是一个 Lucene 索引实例，您可以将其视作一个独立的搜索引擎，它能够对 Elasticsearch 集群中的数据子集进行索引并处理相关查询；</p></li><li><p>每个分片包含多个segment（段），每一个segment都是一个倒排索引。</p></li></ul><p>在查询的时，会把所有的segment查询结果汇总归并为最终的分片查询结果返回。</p><p>在 lucene 中，为了实现高索引速度，故使用了segment 分段架构存储。</p><p>一批写入数据保存在一个段中，其中每个段是磁盘中的单个文件。</p><p>由于两次写入之间的文件操作非常繁重，因此将一个段设为不可变的，以便所有后续写入都转到New段。</p><p>由于自动刷新流程每秒会创建一个新的段（由动态配置参数：refresh_interval 决定），这样会导致短时间内的段数量暴增。</p><p>而段数目太多会带来较大的麻烦。</p><ul><li><p>消耗资源：每一个段都会消耗文件句柄、内存和cpu运行周期；</p></li><li><p>搜索变慢：每个搜索请求都必须轮流检查每个段；所以段越多，搜索也就越慢。</p></li></ul><p>Elasticsearch 通过在后台进行段合并来解决这个问题。</p><p>小的段被合并到大的段，然后这些大的段再被合并到更大的段。</p><h1 id="段合并"><a href="#段合并" class="headerlink" title="段合并"></a>段合并</h1><p>段合并的时候会将那些旧的已删除文档从文件系统中清除。</p><p>被删除的文档（或被更新文档的旧版本）不会被拷贝到新的大段中。</p><p>启动段合并不需要你做任何事。进行索引和搜索时会自动进行。</p><p>合并大的段需要消耗大量的I/O和CPU资源，如果任其发展会影响搜索性能。Elasticsearch在默认情况下会对合并流程进行资源限制，所以搜索仍然 有足够的资源很好地执行。</p><ul><li><p>当索引的时候，刷新（refresh）操作会创建新的段并将段打开以供搜索使用。</p></li><li><p>合并进程选择一小部分大小相似的段，并且在后台将它们合并到更大的段中。这并不会中断索引和搜索。</p></li></ul><p>代价呢</p><ul><li><p>磁盘IO操作的代价；</p></li><li><p>速度慢的系统中，段合并会显著影响性能。</p></li></ul><h1 id="手动段合并"><a href="#手动段合并" class="headerlink" title="手动段合并"></a>手动段合并</h1><p><code>optimize</code> API大可看做是 <em>强制合并</em> API。它会将一个分片强制合并到 <code>max_num_segments</code> 参数指定大小的段数目。 这样做的意图是减少段的数量（通常减少到一个），来提升搜索性能。</p><p>在特定情况下，使用  <code>optimize</code>  API 颇有益处。例如在日志这种用例下，每天、每周、每月的日志被存储在一个索引中。 老的索引实质上是只读的；它们也并不太可能会发生变化。</p><p>在这种情况下，使用optimize优化老的索引，将每一个分片合并为一个单独的段就很有用了；这样既可以节省资源，也可以使搜索更加快速</p><h1 id="迁移索引"><a href="#迁移索引" class="headerlink" title="迁移索引"></a>迁移索引</h1><p>使用 <code>optimize</code> API 触发段合并的操作不会受到任何资源上的限制。这可能会消耗掉你节点上全部的I/O资源, 使其没有余裕来处理搜索请求，从而有可能使集群失去响应。 如果你想要对索引执行 <code>optimize</code>，你需要先使用分片分配（查看 <a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/retiring-data.html#migrate-indices" title="迁移旧索引" target="_blank" rel="noopener">迁移旧索引</a>）把索引移到一个安全的节点，再执行。</p><p>随着数据被记录，很有可能存在一个  <em>热点</em>  索引——今日的索引。 所有新文档都会被加到那个索引，几乎所有查询都以它为目标。那个索引应当使用你最好的硬件。</p><p>Elasticsearch 是如何得知哪台是你最好的服务器呢？你可以通过给每台服务器指定任意的标签来告诉它。 例如，你可以像这样启动一个节点：</p><p>./bin/elasticsearch –node.box_type strong</p><p><code>box_type</code>  参数是完全随意的——你可以将它随意命名只要你喜欢——但你可以用这些任意的值来告诉 Elasticsearch 将一个索引分配至何处。</p><p>我们可以通过按以下配置创建今日的索引来确保它被分配到我们最好的服务器上：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PUT /logs_2014-10-01 &#123; &quot;settings&quot;: &#123; &quot;index.routing.allocation.include.box_type&quot; : &quot;strong&quot; &#125; &#125;</span><br></pre></td></tr></table></figure><p>昨日的索引不再需要我们最好的服务器了，我们可以通过更新索引设置将它移动到标记为  <code>medium</code>  的节点上：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">POST /logs_2014-09-30/_settings &#123; &quot;index.routing.allocation.include.box_type&quot; : &quot;medium&quot; &#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;segment&quot;&gt;&lt;a href=&quot;#segment&quot; class=&quot;headerlink&quot; title=&quot;segment&quot;&gt;&lt;/a&gt;segment&lt;/h1&gt;&lt;p&gt;lucene内部的数据是由⼀个个segment组成的，写⼊lucene的数据并不直接落盘，⽽是先写在
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="ES" scheme="https://arvenseyz.github.io/tags/ES/"/>
    
  </entry>
  
  <entry>
    <title>Roaring BitMap</title>
    <link href="https://arvenseyz.github.io/2021/09/23/9-23%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>https://arvenseyz.github.io/2021/09/23/9-23技术笔记/</id>
    <published>2021-09-23T06:20:29.000Z</published>
    <updated>2021-09-23T06:31:56.593Z</updated>
    
    <content type="html"><![CDATA[<p>ES会缓存频率比较高的filter查询，其中的原理也比较简单，即生成<code>(fitler, segment)</code>和id列表的映射，但是和倒排索引不同，我们只把常用的filter缓存下来而倒排索引是保存所有的，并且filter缓存应该足够快，不然直接查询不就可以了。ES直接把缓存的filter放到内存里面，映射的posting list放入磁盘中。</p><p>RBM的主要思路是：将32位无符号整数按照高16位分桶，即最多可能有216=65536个桶，论文内称为container。存储数据时，按照数据的高16位找到container（找不到就会新建一个），再将低16位放入container中。也就是说，一个RBM就是很多container的集合。</p><p>如下所示。</p><p><img src="https://bytedance.feishu.cn/space/api/box/stream/download/asynccode/?code=YmY1YzA1NDRiOTFmZDFiYjZiMWE2NmZiZGI3ZDlmM2VfMW9qbVFITERKZnB4eEFIcU5rSFZpS1RWUktwRW9CUVpfVG9rZW46Ym94Y24zYUswQXJqTEtNUXdYT1FmM2JqVTFlXzE2MzIzNzg2OTQ6MTYzMjM4MjI5NF9WNA" alt></p><p>图中示出了三个container：</p><ul><li><p>高16位为0000H的container，存储有前1000个62的倍数。</p></li><li><p>高16位为0001H的container，存储有[216, 216+100)区间内的100个数。</p></li><li><p>高16位为0002H的container，存储有[2×216, 3×216)区间内的所有偶数，共215个。</p></li></ul><p><strong>ArrayContainer</strong></p><p>当桶内数据的基数不大于4096时，会采用它来存储，其本质上是一个unsigned short类型的有序数组。数组初始长度为4，随着数据的增多会自动扩容（但最大长度就是4096）。另外还维护有一个计数器，用来实时记录基数。</p><p>上图中的前两个container基数都没超过4096，所以均为ArrayContainer。</p><p><strong>BitmapContainer</strong></p><p>当桶内数据的基数大于4096时，会采用它来存储，其本质就是上一节讲过的普通位图，用长度固定为1024的unsigned long型数组表示，亦即位图的大小固定为216位（8KB）。它同样有一个计数器。</p><p>上图中的第三个container基数远远大于4096，所以要用BitmapContainer存储。</p><p><strong>RunContainer</strong></p><p>RunContainer在图中并未示出，初始的RBM实现中也没有它，而是在本节开头的第二篇论文中新加入的。它使用可变长度的unsigned short数组存储用行程长度编码（RLE）压缩后的数据。举个例子，连续的整数序列<code>11, 12, 13, 14, 15, 27, 28, 29</code>会被RLE压缩为两个二元组<code>11, 4, 27, 2</code>，表示11后面紧跟着4个连续递增的值，27后面跟着2个连续递增的值。</p><p>由此可见，RunContainer的压缩效果可好可坏。考虑极端情况：如果所有数据都是连续的，那么最终只需要4字节；如果所有数据都不连续（比如全是奇数或全是偶数），那么不仅不会压缩，还会膨胀成原来的两倍大。所以，RBM引入RunContainer是作为其他两种container的折衷方案。</p><p><strong>shared_container</strong></p><p>这种容器它本身是不存储数据的，只是用它来指向arraycontainer,bitmapcontainer或runcontainer,就好比指针的作用一样，这个指针可以被多个对象拥有，但是指针所指针的实质东西是被这多个对象所共享的。在我们进行roaringbitmap之间的拷贝的时候，有时并不需要将一个container拷贝多份，那么我们就可以使用sharedcontainer来指向实际的container，然后把sharedcontainer赋给多个roaringbitmap对象持有，这个roaringbitmap对象就可以根据sharedcontainer找到真正存储数据的container,这可以省去不必要的空间浪费。</p><p><img src="https://bytedance.feishu.cn/space/api/box/stream/download/asynccode/?code=YTJmYzJlNTUwZTQ3YWY0NDI3YzY0ZTViMmVlOTYxNTRfQm1oMUhOMlJFeGFSSkFxOE9CUG5OV3BybDhKYzk1dnJfVG9rZW46Ym94Y244NWJCNGd2dGpwNWc1ZG9hMk82NlhlXzE2MzIzNzg2OTQ6MTYzMjM4MjI5NF9WNA" alt></p><p>roaringbitmap除了比bitmap占用内存少之外，其并集和交集操作的速度也要比bitmap的快。原因归结为以下几点：</p><ol><li>计算上的优化</li></ol><p>对于roaringbitmap本质上是将大块的bitmap分成各个小块，其中每个小块在需要存储数据的时候才会存在。所以当进行交集或并集运算的时候，roaringbitmap只需要去计算存在的一些块而不需要像bitmap那样对整个大的块进行计算。如果块内非常稀疏，那么只需要对这些小整数列表进行集合的 AND、OR 运算，这样的话计算量还能继续减轻。这里既不是用空间换时间，也没有用时间换空间，而是用逻辑的复杂度同时换取了空间和时间。</p><p>同时在roaringbitmap中32位长的数据，被分割成高 16 位和低 16 位，高 16 位表示块偏移，低16位表示块内位置，单个块可以表达 64k 的位长，也就是 8K 字节。这样可以保证单个块都可以全部放入 L1 Cache，可以显著提升性能。</p><ol start="2"><li>程序逻辑上的优化</li></ol><p>（1）roaringbitmap维护了排好序的一级索引，以及有序的arraycontainer当进行交集操作的时候，只需要根据一级索引中对应的值来获取需要合并的容器，而不需要合并的容器则不需要对其进行操作直接过滤掉。</p><p>（2）当进行合并的arraycontainer中数据个数相差过大的时候采用基于二分查找的方法对arraycontainer求交集,避免不必要的线性合并花费的时间开销。</p><p>（3）roaingbitmap在做并集的时候同样根据一级索引只对相同的索引的容器进行合并操作，而索引不同的直接添加到新的roaringbitmap上即可，不需要遍历容器。</p><p>（4）.roaringbitmap在合并容器的时候会先预测结果，生成对应的容器，避免不必要的容器转换操作。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;ES会缓存频率比较高的filter查询，其中的原理也比较简单，即生成&lt;code&gt;(fitler, segment)&lt;/code&gt;和id列表的映射，但是和倒排索引不同，我们只把常用的filter缓存下来而倒排索引是保存所有的，并且filter缓存应该足够快，不然直接查询不就可
      
    
    </summary>
    
    
      <category term="ES" scheme="https://arvenseyz.github.io/tags/ES/"/>
    
  </entry>
  
  <entry>
    <title>FOR</title>
    <link href="https://arvenseyz.github.io/2021/09/22/9-21%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-2/"/>
    <id>https://arvenseyz.github.io/2021/09/22/9-21技术笔记-2/</id>
    <published>2021-09-22T09:11:15.000Z</published>
    <updated>2021-09-23T06:19:51.450Z</updated>
    
    <content type="html"><![CDATA[<p>在进行查询的时候经常会进行组合查询，比如查询同时包含<code>choice</code>和<code>the</code>的文档，那么就需要分别查出包含这两个单词的文档的id，然后取这两个id列表的<strong>交集</strong>；如果是查包含<code>choice</code><strong>或者</strong><code>the</code>的文档，那么就需要分别查出posting list然后取<strong>并集</strong>。为了能够高效的进行交集和并集的操作，posting list里面的id都是有序的。同时为了减小存储空间，所有的id都会进行<strong>delta编码</strong>（delta-encoding，我觉得可以翻译成<strong>增量编码</strong>）</p><p>比如现在有id列表<code>[73, 300, 302, 332, 343, 372]</code>，转化成每一个id相对于前一个id的增量值（第一个id的前一个id默认是0，增量就是它自己）列表是<code>[73, 227, 2, 30, 11, 29]</code>。在这个新的列表里面，所有的id都是小于255的，所以每个id只需要<strong>一个字节</strong>存储。</p><p>实际上ES会做的更加精细，它会把所有的文档分成很多个block，每个block正好包含256个文档，然后单独对每个文档进行增量编码，计算出存储这个block里面所有文档最多需要多少位来保存每个id，并且把这个位数作为头信息（header）放在每个block 的前面。这个技术叫Frame of Reference，我翻译成索引帧。</p><p>比如对上面的数据进行压缩（假设每个block只有3个文件而不是256），压缩过程如下</p><p><img src="https://s3.bmp.ovh/imgs/2021/09/c8cd99dd7c742a88.png" alt></p><p>在返回结果的时候，其实也并不需要把所有的数据直接解压然后一股脑全部返回，可以直接返回一个迭代器iterator，直接通过迭代器的next方法逐一取出压缩的id，这样也可以极大的节省计算和内存开销。<br>通过以上的方式可以极大的节省posting list的空间消耗，提高查询性能。不过ES为了提高filter过滤器查询的性能，还做了更多的工作，那就是缓存。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在进行查询的时候经常会进行组合查询，比如查询同时包含&lt;code&gt;choice&lt;/code&gt;和&lt;code&gt;the&lt;/code&gt;的文档，那么就需要分别查出包含这两个单词的文档的id，然后取这两个id列表的&lt;strong&gt;交集&lt;/strong&gt;；如果是查包含&lt;code&gt;choic
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="ES" scheme="https://arvenseyz.github.io/tags/ES/"/>
    
  </entry>
  
</feed>
