<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Arvense</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://arvenseyz.github.io/"/>
  <updated>2021-10-26T07:20:42.291Z</updated>
  <id>https://arvenseyz.github.io/</id>
  
  <author>
    <name>Arvense</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>图数据库基础语法</title>
    <link href="https://arvenseyz.github.io/2021/10/25/10-25%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-2/"/>
    <id>https://arvenseyz.github.io/2021/10/25/10-25技术笔记-2/</id>
    <published>2021-10-25T10:28:27.000Z</published>
    <updated>2021-10-26T07:20:42.291Z</updated>
    
    <content type="html"><![CDATA[<h2 id="图数据库优势"><a href="#图数据库优势" class="headerlink" title="图数据库优势"></a>图数据库优势</h2><p><a href="https://imgtu.com/i/54fgPS" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/10/25/54fgPS.png" alt="54fgPS.png"></a></p><ul><li><p>关系复杂的模型用图的形式表达容易</p></li><li><p>关系查询性能可控（<strong><em>我的好友所在的公司有多少名员工？</em></strong>）</p></li></ul><h2 id="图数据库基本语法"><a href="#图数据库基本语法" class="headerlink" title="图数据库基本语法"></a>图数据库基本语法</h2><h3 id="基本定义"><a href="#基本定义" class="headerlink" title="基本定义"></a>基本定义</h3><ul><li><p>由点(Vertex)、边(Edge)、属性(Property)构成；</p></li><li><p>点(Vertex)是实体、概念对象</p></li><li><p>&lt;type(uint32_t), ID(uint64_t&gt; 二元组唯一标记一个点</p></li><li><p>type标记了一类点的集合，可以把type理解为table，不同type，是不同table</p></li><li><p>属性：点上可以有多种属性，属性可以是常见基本类型，</p></li><li><p>schema: 同一种type的点，其属性key以及属性类型必须一致</p></li><li><p>边(Edge)是点之间的关系、联系</p></li><li><p>边有起点+终点，边上类型，type（string）；和点一样，同样的type类型的边必须有同样的属性属性：和点上属性一样，支持多种基本类型</p></li></ul><h3 id="germlin语法"><a href="#germlin语法" class="headerlink" title="germlin语法"></a>germlin语法</h3><p>gremlin语言是图遍历（traverse）式语言，简单起见，可以理解为，先在图上定位到一个点，然后从这个点开始做图上的深度/宽度遍历，在图上每一步遍历用step来描述，不同的step有不同的功能，用step的组合来实现图上游走</p><h3 id="创建一个天龙八部人物图"><a href="#创建一个天龙八部人物图" class="headerlink" title="创建一个天龙八部人物图"></a>创建一个天龙八部人物图</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Gremlin: g.addV().property(&apos;id&apos;, 1001).property(&apos;type&apos;, 5).property(&apos;name&apos;, &apos;段正淳&apos;).property(&apos;power&apos;, 60).toList()</span><br><span class="line">Gremlin: g.addV().property(&apos;id&apos;, 1002).property(&apos;type&apos;, 5).property(&apos;name&apos;, &apos;段延庆&apos;).property(&apos;power&apos;, 75).toList()</span><br><span class="line">Gremlin: g.addV().property(&apos;id&apos;, 1003).property(&apos;type&apos;, 5).property(&apos;name&apos;, &apos;王语嫣&apos;).property(&apos;power&apos;, 2).toList()</span><br><span class="line">Gremlin: g.addV().property(&apos;id&apos;, 1004).property(&apos;type&apos;, 5).property(&apos;name&apos;, &apos;阿朱&apos;).property(&apos;power&apos;, 5).toList()</span><br><span class="line">Gremlin: g.addV().property(&apos;id&apos;, 1005).property(&apos;type&apos;, 5).property(&apos;name&apos;, &apos;段誉&apos;).property(&apos;power&apos;, 80).toList()</span><br><span class="line">Gremlin: g.addV().property(&apos;id&apos;, 1006).property(&apos;type&apos;, 5).property(&apos;name&apos;, &apos;叶二娘&apos;).property(&apos;power&apos;, 40).toList()</span><br><span class="line">Gremlin: g.addV().property(&apos;id&apos;, 1007).property(&apos;type&apos;, 5).property(&apos;name&apos;, &apos;乔峰&apos;).property(&apos;power&apos;, 90).toList()</span><br><span class="line">Gremlin: g.addV().property(&apos;id&apos;, 1008).property(&apos;type&apos;, 5).property(&apos;name&apos;, &apos;虚竹&apos;).property(&apos;power&apos;, 85).toList()</span><br><span class="line">Gremlin: g.addE(&apos;relatives&apos;).from(1001, 5).to(1002, 5).property(&apos;relation&apos;, &apos;兄弟&apos;).toList()</span><br><span class="line">Gremlin: g.addE(&apos;relatives&apos;).from(1001, 5).to(1003, 5).property(&apos;relation&apos;, &apos;父女&apos;).toList()</span><br><span class="line">Gremlin: g.addE(&apos;relatives&apos;).from(1001, 5).to(1004, 5).property(&apos;relation&apos;, &apos;父女&apos;).toList()</span><br><span class="line">Gremlin: g.addE(&apos;relatives&apos;).from(1002, 5).to(1005, 5).property(&apos;relation&apos;, &apos;父子&apos;).toList()</span><br><span class="line">Gremlin: g.addE(&apos;relatives&apos;).from(1002, 5).to(1006, 5).property(&apos;relation&apos;, &apos;义妹&apos;).toList()</span><br><span class="line">Gremlin: g.addE(&apos;relatives&apos;).from(1003, 5).to(1005, 5).property(&apos;relation&apos;, &apos;夫妻&apos;).toList()</span><br><span class="line">Gremlin: g.addE(&apos;relatives&apos;).from(1004, 5).to(1007, 5).property(&apos;relation&apos;, &apos;夫妻&apos;).toList()</span><br><span class="line">Gremlin: g.addE(&apos;relatives&apos;).from(1005, 5).to(1008, 5).property(&apos;relation&apos;, &apos;结拜兄弟&apos;).toList()</span><br><span class="line">Gremlin: g.addE(&apos;relatives&apos;).from(1006, 5).to(1008, 5).property(&apos;relation&apos;, &apos;母子&apos;).toList()</span><br><span class="line">Gremlin: g.addE(&apos;relatives&apos;).from(1007, 5).to(1005, 5).property(&apos;relation&apos;, &apos;结拜兄弟&apos;).toList()</span><br><span class="line">Gremlin: g.addE(&apos;relatives&apos;).from(1008, 5).to(1007, 5).property(&apos;relation&apos;, &apos;结拜兄弟&apos;).toList()</span><br></pre></td></tr></table></figure><h3 id="查询语法"><a href="#查询语法" class="headerlink" title="查询语法"></a>查询语法</h3><p>查询点类型是5，id是1005的点，以及它的属性（查询属性时，指定属性名性能更好，原因估计是下文的点切割）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">g.V(vertex(1001,5)).toList()</span><br><span class="line">Result: [Vertex&#123;Id:1001, Type:5&#125;]</span><br><span class="line">g.V(vertex(1001,5)).properties()</span><br><span class="line">Result: [Property&#123;Key:name, Value:&quot;段正淳&quot;&#125;, Property&#123;Key:power, Value:60&#125;]</span><br></pre></td></tr></table></figure><h3 id="遍历"><a href="#遍历" class="headerlink" title="遍历"></a>遍历</h3><p>如上文，操作是定位一个点，然后再图上游走</p><p><a href="https://imgtu.com/i/5If0bR" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/10/26/5If0bR.png" alt="5If0bR.png"></a></p><p>定位一个点后，找到它的出边，即段正淳的关系</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">» g.V(vertex(1001,5)).outE(&quot;relatives&quot;)</span><br><span class="line">Result: [Edge&#123;OutV:Vertex&#123;Id:1001, Type:5&#125;, InV:Vertex&#123;Id:1004, Type:5&#125;, Type:relatives&#125;, Edge&#123;OutV:Vertex&#123;Id:1001, Type:5&#125;, InV:Vertex&#123;Id:1003, Type:5&#125;, Type:relatives&#125;, Edge&#123;OutV:Vertex&#123;Id:1001, Type:5&#125;, InV:Vertex&#123;Id:1002, Type:5&#125;, Type:relatives&#125;]</span><br></pre></td></tr></table></figure><p>找到一个点某种类型过滤属性的边，即段正淳的兄弟关系</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">» g.V(vertex(1001,5)).outE(&quot;relatives&quot;).has(&apos;relation&apos;,&apos;兄弟&apos;).toList()</span><br><span class="line">Result: [Edge&#123;OutV:Vertex&#123;Id:1001, Type:5&#125;, InV:Vertex&#123;Id:1002, Type:5&#125;, Type:relatives&#125;]</span><br></pre></td></tr></table></figure><p>进一步，找到段正淳的兄弟</p><p>遍历法，找到兄弟边，再找到兄弟边链接的点</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">» g.V(vertex(1001,5)).outE(&quot;relatives&quot;).has(&apos;relation&apos;,&apos;兄弟&apos;).inV().toList()</span><br><span class="line">Result: [Vertex&#123;Id:1002, Type:5&#125;]</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;图数据库优势&quot;&gt;&lt;a href=&quot;#图数据库优势&quot; class=&quot;headerlink&quot; title=&quot;图数据库优势&quot;&gt;&lt;/a&gt;图数据库优势&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://imgtu.com/i/54fgPS&quot; target=&quot;_blank&quot; r
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="图数据库" scheme="https://arvenseyz.github.io/tags/%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>redis的redlock锁</title>
    <link href="https://arvenseyz.github.io/2021/10/11/10-11%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>https://arvenseyz.github.io/2021/10/11/10-11技术笔记-1/</id>
    <published>2021-10-11T08:49:43.000Z</published>
    <updated>2021-10-25T10:30:15.259Z</updated>
    
    <content type="html"><![CDATA[<ul><li><h3 id="加锁"><a href="#加锁" class="headerlink" title="加锁"></a>加锁</h3></li></ul><p>官方推荐至少 5 个redis实例，而且都是主库，它们之间没有任何关系，都是一个个孤立的实例，流程如下：</p><ol><li>客户端先获取「当前时间戳T1」。</li><li>客户端依次向这 5 个 Redis 实例发起加锁请求（SET命令），且每个请求会设置超时时间（毫秒级，要远小于锁的有效时间），如果某一个实例加锁失败（包括网络超时、锁被其它人持有等各种异常情况），就立即向下一个 Redis 实例申请加锁。</li><li>如果客户端从 3 个（大多数）以上 Redis 实例加锁成功，则再次获取「当前时间戳T2」，如果 T2 - T1 &lt; 锁的过期时间，此时，认为客户端加锁成功，否则认为加锁失败。</li><li>加锁成功，去操作共享资源（例如修改 MySQL 某一行，或发起一个 API 请求）。</li><li>加锁失败，向全部节点发起释放锁请求。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;&lt;h3 id=&quot;加锁&quot;&gt;&lt;a href=&quot;#加锁&quot; class=&quot;headerlink&quot; title=&quot;加锁&quot;&gt;&lt;/a&gt;加锁&lt;/h3&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;官方推荐至少 5 个redis实例，而且都是主库，它们之间没有任何关系，都是一个个孤立的实例，流程
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="redis" scheme="https://arvenseyz.github.io/tags/redis/"/>
    
      <category term="分布式" scheme="https://arvenseyz.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>redis分布式锁</title>
    <link href="https://arvenseyz.github.io/2021/10/09/10-9%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>https://arvenseyz.github.io/2021/10/09/10-9技术笔记-1/</id>
    <published>2021-10-09T06:52:04.000Z</published>
    <updated>2021-10-11T08:50:16.995Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Redis是AP系统"><a href="#Redis是AP系统" class="headerlink" title="Redis是AP系统"></a>Redis是AP系统</h2><p>先抛个结论：</p><p>“redis多机房同步是最终一致的，如有分布式锁的需求，会有锁不上的情况，业务可根据文档考虑使用强一致的存储组件！” from redis 用户文档</p><p>因此redis锁只能作为弱校验，而不能作为强依赖，必须要其他强一致的系统保证其一致性。</p><h2 id="Redis锁实现原理"><a href="#Redis锁实现原理" class="headerlink" title="Redis锁实现原理"></a>Redis锁实现原理</h2><p>而redis锁锁不住的原因要从redis锁的实现讲起。redis锁主要基于两个命令，<strong>setnx &amp;</strong> <strong>cad</strong>，（注意不是redlock，redlock和这两个命令没有关系，下面最后一个部分会提）</p><p><strong>加锁setnx</strong></p><p>setnx命令会被redis client解析为</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SET key value NX PX 30000</span><br></pre></td></tr></table></figure><ul><li>其中key通常为我们想锁住的<code>key</code>，而<code>value</code>应当为一个随机数，原因在解锁的部分讲</li><li><code>NX</code>代表只有key为空时才会set成功</li><li><code>PX 30000</code> 指过期时间30s</li></ul><p><strong>解锁</strong>  <strong>cad</strong> <strong>（已被公司级别支持）</strong></p><p>cad指<code>compare and delete</code>操作，该操作其实内部执行Redis lua脚本保证cad操作的中不会被其他操作穿插</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">if redis.call(&quot;get&quot;,KEYS[1]) == ARGV[1] then </span><br><span class="line">  return redis.call(&quot;del&quot;,KEYS[1])</span><br><span class="line">else </span><br><span class="line">  return 0 </span><br><span class="line">end</span><br></pre></td></tr></table></figure><ul><li>为什么锁还需要设置随机<code>value</code>去compare？因为虽然redis数据库单线程，但是客户端却可能为多线程，试想以下逻辑：</li></ul><p><a href="https://imgtu.com/i/5FANLj" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/10/09/5FANLj.png" alt="5FANLj.png"></a></p><p>若发生以上时序，client1由于处理请求时被阻塞，导致client2获取的锁会被client1解锁，进而导致锁失效。特别是我们应用代码中通常设置的时长较短（1s - 5s），更增加以上情况出现的几率。</p><ul><li>i/o timeout如何做？</li></ul><p>有些人会觉得奇怪为什么上面的这段代码没有做错误校验，正确的做法是不是应该是这样？</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">err := redis.SetNX(key, value, duration)</span><br><span class="line">if err != nil &#123;</span><br><span class="line">    return </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其实不然，试想<code>SetNX</code> 发生timeout，但其实Redis客户端<strong>收到</strong>该请求，只是respond<strong>回复超时</strong>，该锁会一直被持有直到timeout。</p><p>比较正确的逻辑为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">err := redis.SetNX(key, randomNum, duration)</span><br><span class="line">defer redis.CAD(key, randomNum)</span><br><span class="line">if err != nil &#123;</span><br><span class="line">    return </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>由randomNum来保证key有且仅会被本客户端线程解锁，即使失败，也不会把其他客户端线程的锁unlock（因为randomNum不一致，compare阶段错误）。该逻辑更体现了设置randomNum为value的必要性。这个随机数应当可以保证在一段时间内只被同一client持有，比较偷懒的方法是使用server id + unix microsecond时间戳，在大部分场景下应该足够了。</p><ul><li>Expire time如何定？</li></ul><p>其实这也是个两难问题，若超时时间过短，则锁不住整个流程处理时间，可能被抢锁；若超时时间过长，则解锁操作<code>redis.CAD(key, randomNum)</code>失败时，会导致key被锁住过长时间。因此需根据实际业务场景而定。</p><h2 id="分布式redis情况如何？"><a href="#分布式redis情况如何？" class="headerlink" title="分布式redis情况如何？"></a>分布式redis情况如何？</h2><p>即使我们在实现上都按照完美的路径，以上实现也是基于单机情况，在分布式场景下，由于redis多机房同步是最终一致的，当主节点不可用时，系统自动切换到副节点（即failover的过程），由于主从非同步，在failover的过程中会导致锁被抢。试想以下时序：</p><ol><li>master拿到锁a</li><li>slave1-master同步开启</li><li>master宕机，failover开始</li><li>slave1-master同步未完成</li><li>slave1被选举为master，锁a丢失，可被抢</li></ol><p>虽然很多人觉得failover的情况很少，以上可以忽略，实际上根据我们现在的使用方法，某个历史活动的并发情况而言，已经出现大量的并发锁被抢引起的错误（日均300+，from QPS大概400左右的并发请求）。</p><h2 id="正确姿势如何做？"><a href="#正确姿势如何做？" class="headerlink" title="正确姿势如何做？"></a>正确姿势如何做？</h2><p>redis针对单机redis锁的问题，提出了redlock的解决方案，但是redlock也有些争议，同时其不太适合公司的redis架构，在这里不多做讨论。</p><p>如果要了解正确的锁姿势，首先要分析分布式锁的场景，一般来说，可以分为两种，为了效率加锁，和为了正确性加锁。</p><ul><li>为效率加锁，即为了一些计算的重复；即使失败，也只是把某些操作多做一遍，例如条件多校验一遍</li><li>为了正确性加锁，即不允许分布式锁失败；若失败可能产生不可回滚的脏数据</li></ul><p>若为了效率加锁，使用单机的redis锁已经足够，单重要的是清楚单机redis锁在分布式场景下的限制。</p><p>若为了正确性加锁，一定要使用强一致性保障（bytekv，zookeeper）等，基架推荐尝试bytekv。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Redis是AP系统&quot;&gt;&lt;a href=&quot;#Redis是AP系统&quot; class=&quot;headerlink&quot; title=&quot;Redis是AP系统&quot;&gt;&lt;/a&gt;Redis是AP系统&lt;/h2&gt;&lt;p&gt;先抛个结论：&lt;/p&gt;
&lt;p&gt;“redis多机房同步是最终一致的，如有分布式锁
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="redis" scheme="https://arvenseyz.github.io/tags/redis/"/>
    
      <category term="分布式" scheme="https://arvenseyz.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>es打分方式</title>
    <link href="https://arvenseyz.github.io/2021/09/27/9-27%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-3/"/>
    <id>https://arvenseyz.github.io/2021/09/27/9-27技术笔记-3/</id>
    <published>2021-09-27T09:19:34.000Z</published>
    <updated>2021-09-27T09:28:45.295Z</updated>
    
    <content type="html"><![CDATA[<h2 id="计算公式"><a href="#计算公式" class="headerlink" title="计算公式"></a>计算公式</h2><p><code>Lucene</code>和<code>es</code>的打分机制是一个公式。将查询作为输入，使用不同的手段来确定每一篇文档的得分，将每一个因素最后通过公式综合起来，返回该文档的最终得分。这个综合考量的过程，就是我们希望相关的文档被优先返回的考量过程。在<code>Lucene</code>和<code>es</code>中这种相关性称为得分。<br>在开始计算得分之前，<code>es</code>使用了被搜索词条的频率和它有多常见来影响得分，从两个方面理解：</p><ul><li>一个词条在某篇文档中出现的次数越多，该文档就越相关。</li><li>一个词条如果在不同的文档中出现的次数越多，它就越不相关！</li></ul><p>我们称之为<code>TF-IDF</code>，<code>TF</code>是词频（term frequency），而<code>IDF</code>是逆文档频率（inverse document frequency）。</p><p>此外还有两个因素</p><ul><li><p><strong>Document Frequency(DF)文档频率</strong>：即单词出现的文档数。</p></li><li><p><strong>Field-length Norm</strong>：文档越短，相关性越高，field长度，field越长，相关度越弱</p></li></ul><p>逆文档词频是一个重要的因素，用来平衡词条的词频。比如我们搜索<code>the 996.ICU</code>。单词<code>the</code>几乎出现在所有的文档中（中文中比如<code>的</code>），如果这个鬼东西要不被均衡一下，那么<code>the</code>的频率将完全淹没<code>996.ICU</code>。所以，逆文档词频就有效的均衡了<code>the</code>这个常见词的相关性影响。以达到实际的相关性得分将会对查询的词条有一个更准确地描述。<br>当词频和逆文档词频计算完成。就可以使用<code>TF-IDF</code>公式来计算文档的得分了</p><p>我们通过<code>explain=true</code>，es会返回如何打分的</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">GET py1/doc/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"match"</span>: &#123;</span><br><span class="line">      <span class="attr">"title"</span>: <span class="string">"北京"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"explain"</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="attr">"_source"</span>: <span class="string">"title"</span>, </span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>会返回一个复杂的公式。</p><h2 id="手动控制"><a href="#手动控制" class="headerlink" title="手动控制"></a>手动控制</h2><p>通过boosting可以人为控制某个字段的在评分过程中的比重，有两种类型：</p><ul><li><p>索引期间的boosting</p></li><li><p>查询期间的boosting</p></li></ul><p>通过在mapping中设置boost参数，可以在索引期间改变字段的评分权重：</p><p>一旦映射建立完成，那么所有name字段都会自动拥有一个boost值，并且是以降低精度的数值存储在Lucene内部的索引结构中。只有一个字节用于存储浮点型数值（存不下就损失精度了），计算文档的最终得分时可能会损失精度。</p><p>另外，boost是应用与词条的。因此，再被boost的字段中如果匹配上了多个词条，就意味着计算多次的boost，这将会进一步增加字段的权重，可能会影响最终的文档得分。</p><p>查询期间的boosting可以避免上述问题。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;计算公式&quot;&gt;&lt;a href=&quot;#计算公式&quot; class=&quot;headerlink&quot; title=&quot;计算公式&quot;&gt;&lt;/a&gt;计算公式&lt;/h2&gt;&lt;p&gt;&lt;code&gt;Lucene&lt;/code&gt;和&lt;code&gt;es&lt;/code&gt;的打分机制是一个公式。将查询作为输入，使用不同的手段来
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="ES" scheme="https://arvenseyz.github.io/tags/ES/"/>
    
  </entry>
  
  <entry>
    <title>ES段和段合并</title>
    <link href="https://arvenseyz.github.io/2021/09/24/9-24%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>https://arvenseyz.github.io/2021/09/24/9-24技术笔记-1/</id>
    <published>2021-09-24T06:56:04.000Z</published>
    <updated>2021-09-24T07:11:44.965Z</updated>
    
    <content type="html"><![CDATA[<h1 id="segment"><a href="#segment" class="headerlink" title="segment"></a>segment</h1><p>lucene内部的数据是由⼀个个segment组成的，写⼊lucene的数据并不直接落盘，⽽是先写在内存中，经过了refresh间隔，lucene才将该时间段写⼊的全部数据refresh成⼀个segment，segment多了之后会进⾏merge成更⼤的segment。</p><p>lucene查询时会遍历每个segment完成。由于lucene写⼊的数据是在内存中完成，所以写⼊效率⾮常⾼。但是也存在丢失数据的⻛险，所以Elasticsearch基于此现象实现了translog，只有在segment数据落盘后，Elasticsearch才会删除对应的translog。</p><ul><li><p>每个分片都是一个 Lucene 索引实例，您可以将其视作一个独立的搜索引擎，它能够对 Elasticsearch 集群中的数据子集进行索引并处理相关查询；</p></li><li><p>每个分片包含多个segment（段），每一个segment都是一个倒排索引。</p></li></ul><p>在查询的时，会把所有的segment查询结果汇总归并为最终的分片查询结果返回。</p><p>在 lucene 中，为了实现高索引速度，故使用了segment 分段架构存储。</p><p>一批写入数据保存在一个段中，其中每个段是磁盘中的单个文件。</p><p>由于两次写入之间的文件操作非常繁重，因此将一个段设为不可变的，以便所有后续写入都转到New段。</p><p>由于自动刷新流程每秒会创建一个新的段（由动态配置参数：refresh_interval 决定），这样会导致短时间内的段数量暴增。</p><p>而段数目太多会带来较大的麻烦。</p><ul><li><p>消耗资源：每一个段都会消耗文件句柄、内存和cpu运行周期；</p></li><li><p>搜索变慢：每个搜索请求都必须轮流检查每个段；所以段越多，搜索也就越慢。</p></li></ul><p>Elasticsearch 通过在后台进行段合并来解决这个问题。</p><p>小的段被合并到大的段，然后这些大的段再被合并到更大的段。</p><h1 id="段合并"><a href="#段合并" class="headerlink" title="段合并"></a>段合并</h1><p>段合并的时候会将那些旧的已删除文档从文件系统中清除。</p><p>被删除的文档（或被更新文档的旧版本）不会被拷贝到新的大段中。</p><p>启动段合并不需要你做任何事。进行索引和搜索时会自动进行。</p><p>合并大的段需要消耗大量的I/O和CPU资源，如果任其发展会影响搜索性能。Elasticsearch在默认情况下会对合并流程进行资源限制，所以搜索仍然 有足够的资源很好地执行。</p><ul><li><p>当索引的时候，刷新（refresh）操作会创建新的段并将段打开以供搜索使用。</p></li><li><p>合并进程选择一小部分大小相似的段，并且在后台将它们合并到更大的段中。这并不会中断索引和搜索。</p></li></ul><p>代价呢</p><ul><li><p>磁盘IO操作的代价；</p></li><li><p>速度慢的系统中，段合并会显著影响性能。</p></li></ul><h1 id="手动段合并"><a href="#手动段合并" class="headerlink" title="手动段合并"></a>手动段合并</h1><p><code>optimize</code> API大可看做是 <em>强制合并</em> API。它会将一个分片强制合并到 <code>max_num_segments</code> 参数指定大小的段数目。 这样做的意图是减少段的数量（通常减少到一个），来提升搜索性能。</p><p>在特定情况下，使用  <code>optimize</code>  API 颇有益处。例如在日志这种用例下，每天、每周、每月的日志被存储在一个索引中。 老的索引实质上是只读的；它们也并不太可能会发生变化。</p><p>在这种情况下，使用optimize优化老的索引，将每一个分片合并为一个单独的段就很有用了；这样既可以节省资源，也可以使搜索更加快速</p><h1 id="迁移索引"><a href="#迁移索引" class="headerlink" title="迁移索引"></a>迁移索引</h1><p>使用 <code>optimize</code> API 触发段合并的操作不会受到任何资源上的限制。这可能会消耗掉你节点上全部的I/O资源, 使其没有余裕来处理搜索请求，从而有可能使集群失去响应。 如果你想要对索引执行 <code>optimize</code>，你需要先使用分片分配（查看 <a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/retiring-data.html#migrate-indices" title="迁移旧索引" target="_blank" rel="noopener">迁移旧索引</a>）把索引移到一个安全的节点，再执行。</p><p>随着数据被记录，很有可能存在一个  <em>热点</em>  索引——今日的索引。 所有新文档都会被加到那个索引，几乎所有查询都以它为目标。那个索引应当使用你最好的硬件。</p><p>Elasticsearch 是如何得知哪台是你最好的服务器呢？你可以通过给每台服务器指定任意的标签来告诉它。 例如，你可以像这样启动一个节点：</p><p>./bin/elasticsearch –node.box_type strong</p><p><code>box_type</code>  参数是完全随意的——你可以将它随意命名只要你喜欢——但你可以用这些任意的值来告诉 Elasticsearch 将一个索引分配至何处。</p><p>我们可以通过按以下配置创建今日的索引来确保它被分配到我们最好的服务器上：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PUT /logs_2014-10-01 &#123; &quot;settings&quot;: &#123; &quot;index.routing.allocation.include.box_type&quot; : &quot;strong&quot; &#125; &#125;</span><br></pre></td></tr></table></figure><p>昨日的索引不再需要我们最好的服务器了，我们可以通过更新索引设置将它移动到标记为  <code>medium</code>  的节点上：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">POST /logs_2014-09-30/_settings &#123; &quot;index.routing.allocation.include.box_type&quot; : &quot;medium&quot; &#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;segment&quot;&gt;&lt;a href=&quot;#segment&quot; class=&quot;headerlink&quot; title=&quot;segment&quot;&gt;&lt;/a&gt;segment&lt;/h1&gt;&lt;p&gt;lucene内部的数据是由⼀个个segment组成的，写⼊lucene的数据并不直接落盘，⽽是先写在
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="ES" scheme="https://arvenseyz.github.io/tags/ES/"/>
    
  </entry>
  
  <entry>
    <title>Roaring BitMap</title>
    <link href="https://arvenseyz.github.io/2021/09/23/9-23%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>https://arvenseyz.github.io/2021/09/23/9-23技术笔记/</id>
    <published>2021-09-23T06:20:29.000Z</published>
    <updated>2021-09-23T06:31:56.593Z</updated>
    
    <content type="html"><![CDATA[<p>ES会缓存频率比较高的filter查询，其中的原理也比较简单，即生成<code>(fitler, segment)</code>和id列表的映射，但是和倒排索引不同，我们只把常用的filter缓存下来而倒排索引是保存所有的，并且filter缓存应该足够快，不然直接查询不就可以了。ES直接把缓存的filter放到内存里面，映射的posting list放入磁盘中。</p><p>RBM的主要思路是：将32位无符号整数按照高16位分桶，即最多可能有216=65536个桶，论文内称为container。存储数据时，按照数据的高16位找到container（找不到就会新建一个），再将低16位放入container中。也就是说，一个RBM就是很多container的集合。</p><p>如下所示。</p><p><img src="https://bytedance.feishu.cn/space/api/box/stream/download/asynccode/?code=YmY1YzA1NDRiOTFmZDFiYjZiMWE2NmZiZGI3ZDlmM2VfMW9qbVFITERKZnB4eEFIcU5rSFZpS1RWUktwRW9CUVpfVG9rZW46Ym94Y24zYUswQXJqTEtNUXdYT1FmM2JqVTFlXzE2MzIzNzg2OTQ6MTYzMjM4MjI5NF9WNA" alt></p><p>图中示出了三个container：</p><ul><li><p>高16位为0000H的container，存储有前1000个62的倍数。</p></li><li><p>高16位为0001H的container，存储有[216, 216+100)区间内的100个数。</p></li><li><p>高16位为0002H的container，存储有[2×216, 3×216)区间内的所有偶数，共215个。</p></li></ul><p><strong>ArrayContainer</strong></p><p>当桶内数据的基数不大于4096时，会采用它来存储，其本质上是一个unsigned short类型的有序数组。数组初始长度为4，随着数据的增多会自动扩容（但最大长度就是4096）。另外还维护有一个计数器，用来实时记录基数。</p><p>上图中的前两个container基数都没超过4096，所以均为ArrayContainer。</p><p><strong>BitmapContainer</strong></p><p>当桶内数据的基数大于4096时，会采用它来存储，其本质就是上一节讲过的普通位图，用长度固定为1024的unsigned long型数组表示，亦即位图的大小固定为216位（8KB）。它同样有一个计数器。</p><p>上图中的第三个container基数远远大于4096，所以要用BitmapContainer存储。</p><p><strong>RunContainer</strong></p><p>RunContainer在图中并未示出，初始的RBM实现中也没有它，而是在本节开头的第二篇论文中新加入的。它使用可变长度的unsigned short数组存储用行程长度编码（RLE）压缩后的数据。举个例子，连续的整数序列<code>11, 12, 13, 14, 15, 27, 28, 29</code>会被RLE压缩为两个二元组<code>11, 4, 27, 2</code>，表示11后面紧跟着4个连续递增的值，27后面跟着2个连续递增的值。</p><p>由此可见，RunContainer的压缩效果可好可坏。考虑极端情况：如果所有数据都是连续的，那么最终只需要4字节；如果所有数据都不连续（比如全是奇数或全是偶数），那么不仅不会压缩，还会膨胀成原来的两倍大。所以，RBM引入RunContainer是作为其他两种container的折衷方案。</p><p><strong>shared_container</strong></p><p>这种容器它本身是不存储数据的，只是用它来指向arraycontainer,bitmapcontainer或runcontainer,就好比指针的作用一样，这个指针可以被多个对象拥有，但是指针所指针的实质东西是被这多个对象所共享的。在我们进行roaringbitmap之间的拷贝的时候，有时并不需要将一个container拷贝多份，那么我们就可以使用sharedcontainer来指向实际的container，然后把sharedcontainer赋给多个roaringbitmap对象持有，这个roaringbitmap对象就可以根据sharedcontainer找到真正存储数据的container,这可以省去不必要的空间浪费。</p><p><img src="https://bytedance.feishu.cn/space/api/box/stream/download/asynccode/?code=YTJmYzJlNTUwZTQ3YWY0NDI3YzY0ZTViMmVlOTYxNTRfQm1oMUhOMlJFeGFSSkFxOE9CUG5OV3BybDhKYzk1dnJfVG9rZW46Ym94Y244NWJCNGd2dGpwNWc1ZG9hMk82NlhlXzE2MzIzNzg2OTQ6MTYzMjM4MjI5NF9WNA" alt></p><p>roaringbitmap除了比bitmap占用内存少之外，其并集和交集操作的速度也要比bitmap的快。原因归结为以下几点：</p><ol><li>计算上的优化</li></ol><p>对于roaringbitmap本质上是将大块的bitmap分成各个小块，其中每个小块在需要存储数据的时候才会存在。所以当进行交集或并集运算的时候，roaringbitmap只需要去计算存在的一些块而不需要像bitmap那样对整个大的块进行计算。如果块内非常稀疏，那么只需要对这些小整数列表进行集合的 AND、OR 运算，这样的话计算量还能继续减轻。这里既不是用空间换时间，也没有用时间换空间，而是用逻辑的复杂度同时换取了空间和时间。</p><p>同时在roaringbitmap中32位长的数据，被分割成高 16 位和低 16 位，高 16 位表示块偏移，低16位表示块内位置，单个块可以表达 64k 的位长，也就是 8K 字节。这样可以保证单个块都可以全部放入 L1 Cache，可以显著提升性能。</p><ol start="2"><li>程序逻辑上的优化</li></ol><p>（1）roaringbitmap维护了排好序的一级索引，以及有序的arraycontainer当进行交集操作的时候，只需要根据一级索引中对应的值来获取需要合并的容器，而不需要合并的容器则不需要对其进行操作直接过滤掉。</p><p>（2）当进行合并的arraycontainer中数据个数相差过大的时候采用基于二分查找的方法对arraycontainer求交集,避免不必要的线性合并花费的时间开销。</p><p>（3）roaingbitmap在做并集的时候同样根据一级索引只对相同的索引的容器进行合并操作，而索引不同的直接添加到新的roaringbitmap上即可，不需要遍历容器。</p><p>（4）.roaringbitmap在合并容器的时候会先预测结果，生成对应的容器，避免不必要的容器转换操作。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;ES会缓存频率比较高的filter查询，其中的原理也比较简单，即生成&lt;code&gt;(fitler, segment)&lt;/code&gt;和id列表的映射，但是和倒排索引不同，我们只把常用的filter缓存下来而倒排索引是保存所有的，并且filter缓存应该足够快，不然直接查询不就可
      
    
    </summary>
    
    
      <category term="ES" scheme="https://arvenseyz.github.io/tags/ES/"/>
    
  </entry>
  
  <entry>
    <title>FOR</title>
    <link href="https://arvenseyz.github.io/2021/09/22/9-21%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-2/"/>
    <id>https://arvenseyz.github.io/2021/09/22/9-21技术笔记-2/</id>
    <published>2021-09-22T09:11:15.000Z</published>
    <updated>2021-09-23T06:19:51.450Z</updated>
    
    <content type="html"><![CDATA[<p>在进行查询的时候经常会进行组合查询，比如查询同时包含<code>choice</code>和<code>the</code>的文档，那么就需要分别查出包含这两个单词的文档的id，然后取这两个id列表的<strong>交集</strong>；如果是查包含<code>choice</code><strong>或者</strong><code>the</code>的文档，那么就需要分别查出posting list然后取<strong>并集</strong>。为了能够高效的进行交集和并集的操作，posting list里面的id都是有序的。同时为了减小存储空间，所有的id都会进行<strong>delta编码</strong>（delta-encoding，我觉得可以翻译成<strong>增量编码</strong>）</p><p>比如现在有id列表<code>[73, 300, 302, 332, 343, 372]</code>，转化成每一个id相对于前一个id的增量值（第一个id的前一个id默认是0，增量就是它自己）列表是<code>[73, 227, 2, 30, 11, 29]</code>。在这个新的列表里面，所有的id都是小于255的，所以每个id只需要<strong>一个字节</strong>存储。</p><p>实际上ES会做的更加精细，它会把所有的文档分成很多个block，每个block正好包含256个文档，然后单独对每个文档进行增量编码，计算出存储这个block里面所有文档最多需要多少位来保存每个id，并且把这个位数作为头信息（header）放在每个block 的前面。这个技术叫Frame of Reference，我翻译成索引帧。</p><p>比如对上面的数据进行压缩（假设每个block只有3个文件而不是256），压缩过程如下</p><p><img src="https://s3.bmp.ovh/imgs/2021/09/c8cd99dd7c742a88.png" alt></p><p>在返回结果的时候，其实也并不需要把所有的数据直接解压然后一股脑全部返回，可以直接返回一个迭代器iterator，直接通过迭代器的next方法逐一取出压缩的id，这样也可以极大的节省计算和内存开销。<br>通过以上的方式可以极大的节省posting list的空间消耗，提高查询性能。不过ES为了提高filter过滤器查询的性能，还做了更多的工作，那就是缓存。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在进行查询的时候经常会进行组合查询，比如查询同时包含&lt;code&gt;choice&lt;/code&gt;和&lt;code&gt;the&lt;/code&gt;的文档，那么就需要分别查出包含这两个单词的文档的id，然后取这两个id列表的&lt;strong&gt;交集&lt;/strong&gt;；如果是查包含&lt;code&gt;choic
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="ES" scheme="https://arvenseyz.github.io/tags/ES/"/>
    
  </entry>
  
  <entry>
    <title>FST</title>
    <link href="https://arvenseyz.github.io/2021/09/22/9-22%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-2/"/>
    <id>https://arvenseyz.github.io/2021/09/22/9-22技术笔记-2/</id>
    <published>2021-09-22T03:20:52.000Z</published>
    <updated>2021-09-22T07:23:18.318Z</updated>
    
    <content type="html"><![CDATA[<h2 id="FST（Finite-State-Transducer）"><a href="#FST（Finite-State-Transducer）" class="headerlink" title="FST（Finite State Transducer）"></a>FST（Finite State Transducer）</h2><p>FST类似一种TRIE树。</p><p><a href="https://imgtu.com/i/4N3OO0" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/22/4N3OO0.png" alt="4N3OO0.png"></a></p><p><a href="https://imgtu.com/i/4N8Em6" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/22/4N8Em6.png" alt="4N8Em6.png"></a></p><p>可见FST和字典树类似，区别在于，它不但共享了前缀，还共享了后缀。</p><h2 id="怎么构建"><a href="#怎么构建" class="headerlink" title="怎么构建"></a>怎么构建</h2><p>FST树的构建比较简单，但其依赖于前提<strong><em>输入有序</em></strong></p><p>只需要每次和上一个输入进行最大前缀匹配即可。</p><p><img src="https://s3.bmp.ovh/imgs/2021/09/a813ad0d38865fba.png" alt></p><p>插入“do”与，前一个单词“deep”进行最大前缀匹配，发现是d，则在d边后增加新边o，o边指向终点。</p><h1 id="怎么用"><a href="#怎么用" class="headerlink" title="怎么用"></a>怎么用</h1><p>Lucene在存储倒排索引时，分为2个文件: 词典文件(.tim), 词典索引文件(.tip)。其中.tip中存储的就是多个FST，<br>FST中存储的是&lt;单词前缀，以该前缀开头的所有Term的压缩块在磁盘中的位置&gt;。</p><p>ES的词典，实际上分了两级，Terms Dictionary 通过 .tim 后缀文件存储，其内部采用 NodeBlock 对 Term 进行压缩前缀存储，处理过程会将相同前缀的的 Term 压缩为一个 NodeBlock，NodeBlock 会存储公共前缀，然后将每个 Term 的后缀以及对应 Term 的 Posting 关联信息处理为一个 Entry 保存到 Block。</p><p><img src="https://s3.bmp.ovh/imgs/2021/09/13ba20217a706cd5.png" alt></p><p>在上图中可以看到 Block 中还包含了 Block，这里是为了处理包含相同前缀的 Term 集合内部部分 Term 又包含了相同前缀。</p><p>举个例子，在下图中为公共前缀为 a 的 Term 集合，内部部分 Term 的又包含了相同前缀 ab，这时这部分 Term 就会处理为一个嵌套的 Block。</p><p>Terms Dictionary 是按 NodeBlock 存储在.tim 文件上。当文档数量越来越多的时，Dictionary 中的 Term 也会越来越多，那查询效率必然也会逐渐变低。</p><p>因此需要一个很好的数据结构为 Dictionary 建构一个索引，这就是 Terms Index(.tip文件存储)，Lucene 采用了 FST 这个数据结构来实现这个索引。</p><p>实际上，<strong>FST的结构非常复杂，我们可以简单的将其理解为一个高效的K-V结构，而且空间占用率更高</strong>。这里想简单强调一下：<strong>Lucene到底在FST里存了什么数据？</strong> 如果你已经了解FST在Lucene中充当的角色和作用的话，我想你可能会误认为FST中存了Dictionary中所有的Terms数据，这样可以通过FST是找到具体的Term的位置，或者通过FST可以切实获知一个Term是否存在。</p><p><strong>然而，事实并非如此。</strong> FST即不能知道某个Term在Dictionary(.tim)文件上具体的位置，也不能仅通过FST就能确切的知道Term是否真实存在。它只能告诉你，查询的Term可能在这些Blocks上，到底存不存在FST并不能给出确切的答案，<strong>因为FST是通过Dictionary的每个Block的前缀构成，所以通过FST只可以直接找到这个Block在.tim文件上具体的File Pointer</strong>，并无法直接找到Terms。</p><h3 id="倒排索引的实现"><a href="#倒排索引的实现" class="headerlink" title="倒排索引的实现"></a>倒排索引的实现</h3><ul><li>通过 Term Index 数据（.tip文件）中的 StartFP 获取指定字段的 FST</li><li>通过 FST 找到指定 Term 在 Term Dictionary（.tim 文件）可能存在的 Block</li><li>将对应 Block 加载内存，遍历 Block 中的 Entry，通过后缀（Suffix）判断是否存在指定 Term</li><li>存在则通过 Entry 的 TermStat 数据中各个文件的 FP 获取 Posting 数据</li><li>如果需要获取 Term 对应的所有 DocId 则直接遍历 TermFreqs，如果获取指定 DocId 数据则通过 SkipData快速跳转</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;FST（Finite-State-Transducer）&quot;&gt;&lt;a href=&quot;#FST（Finite-State-Transducer）&quot; class=&quot;headerlink&quot; title=&quot;FST（Finite State Transducer）&quot;&gt;&lt;/a&gt;FS
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="ES" scheme="https://arvenseyz.github.io/tags/ES/"/>
    
  </entry>
  
  <entry>
    <title>ES的搜索阶段</title>
    <link href="https://arvenseyz.github.io/2021/09/18/9-16%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>https://arvenseyz.github.io/2021/09/18/9-16技术笔记/</id>
    <published>2021-09-18T08:54:44.000Z</published>
    <updated>2021-09-18T09:48:31.610Z</updated>
    
    <content type="html"><![CDATA[<h1 id="查询阶段"><a href="#查询阶段" class="headerlink" title="查询阶段"></a>查询阶段</h1><p>在初始 <em>查询阶段</em> 时， 查询会广播到索引中每一个分片拷贝（主分片或者副本分片）。 每个分片在本地执行搜索并构建一个匹配文档的 <em>优先队列</em>。</p><p>查询阶段包含以下三个步骤:</p><ol><li>客户端发送一个  search  请求到   一个节点 ， 该节点 会创建一个大小为  <code>from + size</code>  的空优先队列。</li><li>节点将查询请求转发到索引的每个主分片或副本分片中。每个分片在本地执行查询并添加结果到大小为  <code>from + size</code>  的本地有序优先队列中。</li><li>每个分片返回各自优先队列中所有文档的 ID 和排序值给协调节点  ，它合并这些值到自己的优先队列中来产生一个全局排序后的结果列表。</li></ol><p>当一个搜索请求被发送到某个节点时，这个节点就变成了协调节点。 这个节点的任务是广播查询请求到所有相关分片并将它们的响应整合成全局排序后的结果集合，这个结果集合会返回给客户端。</p><h1 id="取回阶段"><a href="#取回阶段" class="headerlink" title="取回阶段"></a>取回阶段</h1><p>分布式阶段由以下步骤构成：</p><ol><li>协调节点辨别出哪些文档需要被取回并向相关的分片提交多个  <code>GET</code>  请求。</li><li>每个分片加载并  <em>丰富</em>  文档，如果有需要的话，接着返回文档给协调节点。</li><li>一旦所有的文档都被取回了，协调节点返回结果给客户端。</li></ol><p>协调节点首先决定哪些文档  <em>确实</em>  需要被取回。例如，如果我们的查询指定了  <code>{ &quot;from&quot;: 90, &quot;size&quot;: 10 }</code>  ，最初的90个结果会被丢弃，只有从第91个开始的10个结果需要被取回。这些文档可能来自和最初搜索请求有关的一个、多个甚至全部分片。</p><p>协调节点给持有相关文档的每个分片创建一个  <a href="https://www.elastic.co/guide/cn/elasticsearch/guide/2.x/distrib-multi-doc.html" title="多文档模式" target="_blank" rel="noopener">multi-get request</a>  ，并发送请求给同样处理查询阶段的分片副本。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;查询阶段&quot;&gt;&lt;a href=&quot;#查询阶段&quot; class=&quot;headerlink&quot; title=&quot;查询阶段&quot;&gt;&lt;/a&gt;查询阶段&lt;/h1&gt;&lt;p&gt;在初始 &lt;em&gt;查询阶段&lt;/em&gt; 时， 查询会广播到索引中每一个分片拷贝（主分片或者副本分片）。 每个分片在本地执行搜索并
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="ES" scheme="https://arvenseyz.github.io/tags/ES/"/>
    
  </entry>
  
  <entry>
    <title>ES的Scroll查询</title>
    <link href="https://arvenseyz.github.io/2021/09/15/9-15%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>https://arvenseyz.github.io/2021/09/15/9-15技术笔记-1/</id>
    <published>2021-09-15T08:27:28.000Z</published>
    <updated>2021-09-18T10:04:43.513Z</updated>
    
    <content type="html"><![CDATA[<p>如scroll=1m则把查询结果在下一次请求上来时暂存1分钟，response比传统的返回多了一个scroll_id，下次带上这个scroll_id即可找回这个缓存的结果。这里就scroll完成的逻辑。</p><p>Scroll方式通过一次查询请求后维护一个临时的索引快照的search context，此后的增删查改操作并不会影响这个快照数据信息，后续的查询只需要根据游标去取数据，直到结果集中返回的 hits 字段为空，就表示遍历结束。效率比较高。在5.x之后，还可以通过slice分片来实现并行导出。</p><p>想象下，srcoll没有from，只能从头开始，比如size10，某种sort，分片接到请求后，构建优先队列，拿到top10返回，然后保存该优先队列。第二次请求，协调者可以告诉该分片，这次需要大于多少的10个。节点接着操作该树即可。</p><p>它的缺点就是维护一个search context需要占用很多资源，而且在快照建立之后数据变化如删除和更新操作是不能被感知到的，所以不能够用于实时和高并发的场景。</p><p>scroll先从各个分片根据搜索结果获取文档ID排序后返回到协调节点，协调节点再进行排序，第一次和from+size流程一样，区别在于通过scroll会把这次搜索的文档ID都汇总到协调节点并缓存起来，下次根据分页获取的时候不再重新构造，而是直接从缓存里获取</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">GET yz_alias/_search?scroll=2m</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">10</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"_scroll_id"</span> : <span class="string">"DnF1ZXJ5VGhlbkZldGNoAwAAAAAAsiN1FkpGQ2dUa1BNUVUyeUpVSzY1bUduVEEAAAAAAMAg5RZNaWx1TmFSUVRYUzBmV3dpOGRYUUpnAAAAAADAIOQWTWlsdU5hUlFUWFMwZld3aThkWFFKZw=="</span>,</span><br><span class="line">  <span class="attr">"took"</span> : <span class="number">10</span>,</span><br><span class="line">  ....</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>第二次搜索的时候，只需要用srcollid搜即可</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">GET /_search/scroll</span><br><span class="line">&#123;</span><br><span class="line">    <span class="attr">"scroll"</span>: <span class="string">"2m"</span>, </span><br><span class="line">    <span class="attr">"scroll_id"</span> : <span class="string">"DnF1ZXJ5VGhlbkZldGNoAwAAAAAAwDyLFk1pbHVOYVJRVFhTMGZXd2k4ZFhRSmcAAAAAALI-KhZKRkNnVGtQTVFVMnlKVUs2NW1HblRBAAAAAACyPisWSkZDZ1RrUE1RVTJ5SlVLNjVtR25UQQ=="</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;如scroll=1m则把查询结果在下一次请求上来时暂存1分钟，response比传统的返回多了一个scroll_id，下次带上这个scroll_id即可找回这个缓存的结果。这里就scroll完成的逻辑。&lt;/p&gt;
&lt;p&gt;Scroll方式通过一次查询请求后维护一个临时的索引快照
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="ES" scheme="https://arvenseyz.github.io/tags/ES/"/>
    
  </entry>
  
  <entry>
    <title>ES的search after</title>
    <link href="https://arvenseyz.github.io/2021/09/14/9-14%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>https://arvenseyz.github.io/2021/09/14/9-14技术笔记/</id>
    <published>2021-09-14T06:29:27.000Z</published>
    <updated>2021-09-15T08:27:14.906Z</updated>
    
    <content type="html"><![CDATA[<h1 id="search-after"><a href="#search-after" class="headerlink" title="search after"></a>search after</h1><p>es搜索带sort字段时，也会返回，sort对应的值</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">GET yz_alias/_search?pretty</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">10</span>,</span><br><span class="line">  <span class="attr">"sort"</span>: &#123;</span><br><span class="line">    <span class="attr">"date"</span>: <span class="string">"asc"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">"hits" : [</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="attr">"_index"</span> : <span class="string">"yz_test"</span>,</span><br><span class="line">    <span class="attr">"_type"</span> : <span class="string">"_doc"</span>,</span><br><span class="line">    <span class="attr">"_id"</span> : <span class="string">"1"</span>,</span><br><span class="line">    <span class="attr">"_score"</span> : <span class="literal">null</span>,</span><br><span class="line">    <span class="attr">"_source"</span> : &#123;</span><br><span class="line">      <span class="attr">"title"</span> : <span class="string">"Some short title"</span>,</span><br><span class="line">      <span class="attr">"date"</span> : <span class="string">"2015-01-01"</span>,</span><br><span class="line">      <span class="attr">"content"</span> : <span class="string">"A very long content field..."</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"sort"</span> : [</span><br><span class="line">      <span class="number">1420070400000</span></span><br><span class="line">    ]</span><br><span class="line">  &#125;,</span><br></pre></td></tr></table></figure><p>这时把sort的值，放到search after里，可以继续往下搜</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">GET yz_alias/_search?pretty</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">10</span>,</span><br><span class="line">  <span class="attr">"sort"</span>: &#123;</span><br><span class="line">    <span class="attr">"date"</span>: <span class="string">"asc"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"search_after"</span>: [</span><br><span class="line">    <span class="number">1420070400000</span></span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">"hits" : [</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="attr">"_index"</span> : <span class="string">"yz_test2"</span>,</span><br><span class="line">    <span class="attr">"_type"</span> : <span class="string">"_doc"</span>,</span><br><span class="line">    <span class="attr">"_id"</span> : <span class="string">"3"</span>,</span><br><span class="line">    <span class="attr">"_score"</span> : <span class="literal">null</span>,</span><br><span class="line">    <span class="attr">"_source"</span> : &#123;</span><br><span class="line">      <span class="attr">"title"</span> : <span class="string">"Some short title2"</span>,</span><br><span class="line">      <span class="attr">"date"</span> : <span class="string">"2016-01-01"</span>,</span><br><span class="line">      <span class="attr">"content"</span> : <span class="string">"A very long content field..."</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"sort"</span> : [</span><br><span class="line">      <span class="number">1451606400000</span></span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>search after的好处是，不用把前n页的数据全部拿到，但是searchAfter也是全部搜索了一遍，只不过在collect过程中添加了一个上一页最后doc和当前返回的doc对比，这个过程时间复杂度为o(n)，也就是说，相比于search，并不能优化速度，时间复杂度还是o(n)，但是至少不会oom，可以搜出来。</p><p>举个例子。</p><p>一共10个分片，每个分片10条数据。现在需要第91到100条。</p><p>from+size的方式，必须的每个分片都吐出所有数据，然后协调者把这100条排序。</p><p>因为每个分片不知道其他分片数据的情况。</p><p>而search after的数据，只需要每个分片给出大于第90数据的数据即可。但是这个分片依然要扫描所有数据，才知道哪些数据大于90的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;search-after&quot;&gt;&lt;a href=&quot;#search-after&quot; class=&quot;headerlink&quot; title=&quot;search after&quot;&gt;&lt;/a&gt;search after&lt;/h1&gt;&lt;p&gt;es搜索带sort字段时，也会返回，sort对应的值&lt;/p&gt;
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="ES" scheme="https://arvenseyz.github.io/tags/ES/"/>
    
  </entry>
  
  <entry>
    <title>ES分布式</title>
    <link href="https://arvenseyz.github.io/2021/08/17/8-17%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>https://arvenseyz.github.io/2021/08/17/8-17技术笔记/</id>
    <published>2021-08-17T06:58:31.000Z</published>
    <updated>2021-08-17T08:19:38.824Z</updated>
    
    <content type="html"><![CDATA[<h2 id="并发控制"><a href="#并发控制" class="headerlink" title="并发控制"></a>并发控制</h2><p>Elasticsearch 是分布式的。当文档创建、更新或删除时， 新版本的文档必须复制到集群中的其他节点。Elasticsearch 也是异步和并发的，这意味着这些复制请求被并行发送，并且到达目的地时也许  <em>顺序是乱的</em>  。 Elasticsearch 需要一种方法确保文档的旧版本不会覆盖新的版本。</p><p>当我们之前讨论  <code>index</code>  ，  <code>GET</code>  和  <code>delete</code>  请求时，我们指出每个文档都有一个  <code>_version</code>  （版本）号，当文档被修改时版本号递增。 Elasticsearch 使用这个  <code>_version</code>  号来确保变更以正确顺序得到执行。如果旧版本的文档在新版本之后到达，它可以被简单的忽略。</p><p>操作数据时，可以指定版本，这样如果我们指定的版本号，小于当前版本号，会返回失败。</p><h2 id="选主"><a href="#选主" class="headerlink" title="选主"></a>选主</h2><p>ES集群中也会选举一个节点成为<strong>主节点</strong>，主节点它的职责是维护全局集群状态，在节点加入或离开集群的时候重新分配分片。</p><ul><li>集群层面的配置</li><li>集群内有哪些节点</li><li>各索引的设置，映射，分析器和别名等</li><li>索引内各分片所在的节点位置</li></ul><p>所有主要的文档级别API（索引，删除，搜索）都不与主节点通信，主节点并不需要涉及到文档级别的变更和搜索等操作，所以当集群只拥有一个主节点的情况下，即使流量的增加它也不会成为瓶颈。 任何节点都可以成为主节点。如果集群中就只有一个节点，那么它同时也就是主节点。</p><h5 id="Bully算法"><a href="#Bully算法" class="headerlink" title="Bully算法"></a>Bully算法</h5><p>每个节点有一个唯一ID，然后对集群中所有的节点ID进行排序，选取其中最小的ID所属的节点作为Master。<br>Bully算法的问题： 假设当前Master因为负载过重而假死，然后ID第二大的被选举为新的Master，这时旧的Master恢复然后又被选举为Master然后又会因为负载过重而假死……</p><h3 id="Zen-Discovery"><a href="#Zen-Discovery" class="headerlink" title="Zen Discovery"></a>Zen Discovery</h3><p>例如，Master负载过重而假死，集群拥有第二大ID的节点被选为新主，这时原来的Master恢复，再次被选为新主，然后又假死<br>ES 通过推迟选举，直到当前的 Master 失效来解决上述问题，只要当前主节点不挂掉，就不重新选主。但是容易产生脑裂（双主），为此，再通过“法定得票人数过半”解决脑裂问题</p><p>只有一个 Leader将当前版本的全局集群状态推送到每个节点。 ZenDiscovery（默认）过程就是这样的:</p><p>每个节点计算最高的已知节点ID，并向该节点发送领导投票<br>如果一个节点收到足够多的票数，并且该节点也为自己投票，那么它将扮演领导者的角色，开始发布集群状态。<br>所有节点都会参数选举,并参与投票,但是,只有有资格成为 master 的节点的投票才有效.<br>————————————————</p><ol><li><p>过滤出具有Master资格的节点（filterPingResponses）</p></li><li><p>选出临时Master。根据PingResponse结果构建两个列表：activeMasters和masterCandidates。</p><p>– 如果activeMasters非空，则从activeMasters中选择最合适的作为Master；</p><p>– 如果activeMasters为空，则从masterCandidates中选举，结果可能选举成功，也可能选举失败。</p></li><li><p>判断临时Master是否是本节点。</p><p>– 如果临时Master是本节点：则等待其他节点选我，默认30秒超时，成功的话就发布新的clusterState。（当选总统候选人，只等选票过半了）</p><p>– 如果临时Master是其他节点：则不再接受其他节点的join请求，并向Master节点发送加入请求。（没资格选举，就只能送人头了）</p></li></ol><h3 id="Raft"><a href="#Raft" class="headerlink" title="Raft"></a>Raft</h3><p>7版本后已改用Raft</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;并发控制&quot;&gt;&lt;a href=&quot;#并发控制&quot; class=&quot;headerlink&quot; title=&quot;并发控制&quot;&gt;&lt;/a&gt;并发控制&lt;/h2&gt;&lt;p&gt;Elasticsearch 是分布式的。当文档创建、更新或删除时， 新版本的文档必须复制到集群中的其他节点。Elastics
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="ES" scheme="https://arvenseyz.github.io/tags/ES/"/>
    
  </entry>
  
  <entry>
    <title>ES索引别名</title>
    <link href="https://arvenseyz.github.io/2021/08/16/8-16%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>https://arvenseyz.github.io/2021/08/16/8-16技术笔记-1/</id>
    <published>2021-08-16T07:01:50.000Z</published>
    <updated>2021-08-16T09:52:15.398Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ES别名"><a href="#ES别名" class="headerlink" title="ES别名"></a>ES别名</h1><p>索引别名可以指向一个或多个索引，并且可以在任何需要索引名称的API中使用。</p><h3 id="创建别名"><a href="#创建别名" class="headerlink" title="创建别名"></a>创建别名</h3><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">POST /_aliases?pretty</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"actions"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"add"</span>: &#123;</span><br><span class="line">        <span class="attr">"index"</span>: <span class="string">"yz_test"</span>,</span><br><span class="line">        <span class="attr">"alias"</span>: <span class="string">"yz_alias"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"add"</span>: &#123;</span><br><span class="line">        <span class="attr">"index"</span>: <span class="string">"yz_test1"</span>,</span><br><span class="line">        <span class="attr">"alias"</span>: <span class="string">"yz_alias"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="通过别名搜索"><a href="#通过别名搜索" class="headerlink" title="通过别名搜索"></a>通过别名搜索</h3><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">GET yz_alias/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"stored_fields"</span>: [ <span class="string">"title"</span>, <span class="string">"date"</span> ] ,</span><br><span class="line">    <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"bool"</span>: &#123;</span><br><span class="line">      <span class="attr">"must"</span>: &#123;</span><br><span class="line">        <span class="attr">"term"</span>: &#123;</span><br><span class="line">          <span class="attr">"content"</span>:<span class="string">"long"</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"took"</span> : <span class="number">7</span>,</span><br><span class="line">  <span class="attr">"timed_out"</span> : <span class="literal">false</span>,</span><br><span class="line">  <span class="attr">"_shards"</span> : &#123;</span><br><span class="line">    <span class="attr">"total"</span> : <span class="number">2</span>,</span><br><span class="line">    <span class="attr">"successful"</span> : <span class="number">2</span>,</span><br><span class="line">    <span class="attr">"skipped"</span> : <span class="number">0</span>,</span><br><span class="line">    <span class="attr">"failed"</span> : <span class="number">0</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"hits"</span> : &#123;</span><br><span class="line">    <span class="attr">"total"</span> : &#123;</span><br><span class="line">      <span class="attr">"value"</span> : <span class="number">2</span>,</span><br><span class="line">      <span class="attr">"relation"</span> : <span class="string">"eq"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"max_score"</span> : <span class="number">0.2876821</span>,</span><br><span class="line">    <span class="attr">"hits"</span> : [</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">"_index"</span> : <span class="string">"yz_test1"</span>,</span><br><span class="line">        <span class="attr">"_type"</span> : <span class="string">"_doc"</span>,</span><br><span class="line">        <span class="attr">"_id"</span> : <span class="string">"1"</span>,</span><br><span class="line">        <span class="attr">"_score"</span> : <span class="number">0.2876821</span>,</span><br><span class="line">        <span class="attr">"fields"</span> : &#123;</span><br><span class="line">          <span class="attr">"date"</span> : [</span><br><span class="line">            <span class="string">"2015-01-01T00:00:00.000Z"</span></span><br><span class="line">          ],</span><br><span class="line">          <span class="attr">"title"</span> : [</span><br><span class="line">            <span class="string">"Some short title"</span></span><br><span class="line">          ]</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">"_index"</span> : <span class="string">"yz_test"</span>,</span><br><span class="line">        <span class="attr">"_type"</span> : <span class="string">"_doc"</span>,</span><br><span class="line">        <span class="attr">"_id"</span> : <span class="string">"1"</span>,</span><br><span class="line">        <span class="attr">"_score"</span> : <span class="number">0.18232156</span>,</span><br><span class="line">        <span class="attr">"fields"</span> : &#123;</span><br><span class="line">          <span class="attr">"date"</span> : [</span><br><span class="line">            <span class="string">"2015-01-01T00:00:00.000Z"</span></span><br><span class="line">          ],</span><br><span class="line">          <span class="attr">"title"</span> : [</span><br><span class="line">            <span class="string">"Some short title"</span></span><br><span class="line">          ]</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可见，会把相同别名下索引的数据全部搜出来。</p><h3 id="索引模版"><a href="#索引模版" class="headerlink" title="索引模版"></a>索引模版</h3><p>Elasticsearch 不要求你在使用一个索引前创建它。 对于日志记录类应用，依赖于自动创建索引比手动创建要更加方便。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">PUT /_template/yz_template</span><br><span class="line"> &#123;</span><br><span class="line"> <span class="attr">"index_patterns"</span>: <span class="string">"yz_test*"</span>,</span><br><span class="line"> <span class="attr">"order"</span>: <span class="number">1</span>,</span><br><span class="line"> <span class="attr">"settings"</span>: &#123;</span><br><span class="line"> <span class="attr">"number_of_shards"</span>: <span class="number">1</span></span><br><span class="line"> &#125;,</span><br><span class="line">   <span class="attr">"mappings"</span>: &#123;</span><br><span class="line">    <span class="attr">"properties"</span>: &#123;</span><br><span class="line">      <span class="attr">"title"</span>: &#123;</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"text"</span>,</span><br><span class="line">        <span class="attr">"store"</span>: <span class="literal">true</span> </span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"date"</span>: &#123;</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"date"</span>,</span><br><span class="line">        <span class="attr">"store"</span>: <span class="literal">true</span> </span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"content"</span>: &#123;</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"text"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> &#125;,</span><br><span class="line"> <span class="attr">"aliases"</span>: &#123;</span><br><span class="line"> <span class="attr">"yz_alias"</span>: &#123;&#125;</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个模板指定了所有名字以 <code>yz_test</code> 为起始的索引的默认设置，不论它是手动还是自动创建的。 </p><p>这样我们写入数据时，会自动创建索引：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">PUT yz_test2/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"title"</span>:   <span class="string">"Some short title2"</span>,</span><br><span class="line">  <span class="attr">"date"</span>:    <span class="string">"2015-01-01"</span>,</span><br><span class="line">  <span class="attr">"content"</span>: <span class="string">"A very long content field..."</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这时，我们再使用别名搜索，可以搜出三个索引的数据。</p><h2 id="利用别名重建索引"><a href="#利用别名重建索引" class="headerlink" title="利用别名重建索引"></a>利用别名重建索引</h2><p>我们有一个索引my_index_v1，使用别名my_index</p><p>我们决定修改索引中一个字段的映射。当然，我们不能修改现存的映射，所以我们必须重新索引数据。 首先, 我们用新映射创建索引 <code>my_index_v2</code> </p><p>然后我们将数据从 <code>my_index_v1</code> 重新索引到 <code>my_index_v2</code>。方法如<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.6/docs-reindex.html" target="_blank" rel="noopener">Reindex API</a></p><p>数据迁移完成后切换别名</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">POST /_aliases</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"actions"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"add"</span>: &#123;</span><br><span class="line">        <span class="attr">"index"</span>: <span class="string">"my_index_v2"</span>,</span><br><span class="line">        <span class="attr">"alias"</span>: <span class="string">"my_index"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"remove"</span>: &#123;</span><br><span class="line">        <span class="attr">"index"</span>: <span class="string">"my_index_v1"</span>,</span><br><span class="line">        <span class="attr">"alias"</span>: <span class="string">"my_index"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="filter别名"><a href="#filter别名" class="headerlink" title="filter别名"></a>filter别名</h3><p>别名时设置filter，通过这个别名就只能看到符合过滤器过滤后的结果了</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">POST /_aliases</span><br><span class="line">&#123;</span><br><span class="line">    <span class="attr">"actions"</span> : [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"add"</span> : &#123;</span><br><span class="line">                 <span class="attr">"index"</span> : <span class="string">"test1"</span>,</span><br><span class="line">                 <span class="attr">"alias"</span> : <span class="string">"alias2"</span>,</span><br><span class="line">                 <span class="attr">"filter"</span> : &#123; <span class="attr">"term"</span> : &#123; <span class="attr">"user"</span> : <span class="string">"kimchy"</span> &#125; &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="路由别名"><a href="#路由别名" class="headerlink" title="路由别名"></a>路由别名</h3><p>所有具有此别名的操作将自动修改为使用进行路由:</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">POST /_aliases</span><br><span class="line">&#123;</span><br><span class="line">    <span class="attr">"actions"</span> : [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"add"</span> : &#123;</span><br><span class="line">                 <span class="attr">"index"</span> : <span class="string">"test"</span>,</span><br><span class="line">                 <span class="attr">"alias"</span> : <span class="string">"alias1"</span>,</span><br><span class="line">                 <span class="attr">"routing"</span> : <span class="string">"1"</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>还可以为搜索和索引操作指定不同的路由值</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">POST /_aliases</span><br><span class="line">&#123;</span><br><span class="line">    <span class="attr">"actions"</span> : [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"add"</span> : &#123;</span><br><span class="line">                 <span class="attr">"index"</span> : <span class="string">"test"</span>,</span><br><span class="line">                 <span class="attr">"alias"</span> : <span class="string">"alias2"</span>,</span><br><span class="line">                 <span class="attr">"search_routing"</span> : <span class="string">"1,2"</span>,</span><br><span class="line">                 <span class="attr">"index_routing"</span> : <span class="string">"2"</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;ES别名&quot;&gt;&lt;a href=&quot;#ES别名&quot; class=&quot;headerlink&quot; title=&quot;ES别名&quot;&gt;&lt;/a&gt;ES别名&lt;/h1&gt;&lt;p&gt;索引别名可以指向一个或多个索引，并且可以在任何需要索引名称的API中使用。&lt;/p&gt;
&lt;h3 id=&quot;创建别名&quot;&gt;&lt;a hre
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="ES" scheme="https://arvenseyz.github.io/tags/ES/"/>
    
  </entry>
  
  <entry>
    <title>BDK树</title>
    <link href="https://arvenseyz.github.io/2021/08/12/8-12%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>https://arvenseyz.github.io/2021/08/12/8-12技术笔记-1/</id>
    <published>2021-08-12T08:27:52.000Z</published>
    <updated>2021-08-13T07:42:01.647Z</updated>
    
    <content type="html"><![CDATA[<p>说到ES，就想到倒排索引，但是有个问题，我们在数字比大小的场景，倒排索引怎么实现呢？</p><p>即range怎么实现的？</p><p>早期的ES，只能把范围转化成in，最多再多一些小优化，自动产生一些区间的term，构建一个基于数字的字典树，但在大范围时依然没用，并且不太好支持多范围查询。</p><p>现在版本，ES对于数字类型，用的不是倒排索引，而是 Block k-d tree</p><h1 id="Block-k-d-tree"><a href="#Block-k-d-tree" class="headerlink" title="Block k-d tree"></a>Block k-d tree</h1><h2 id="k-d-tree"><a href="#k-d-tree" class="headerlink" title="k-d tree"></a>k-d tree</h2><p>k-d树（k-dimensional树的简称），是一种分割k维数据空间的数据结构。主要应用于多维空间关键数据的搜索（如：范围搜索和最近邻搜索）。</p><p>我们想象下二分搜索树：</p><p><strong>二叉搜索树则是在二叉树的基础上加了一些规则</strong>：</p><ul><li>左子树的值都小于父节点</li><li>右子树的值都大于父节点</li></ul><p>如果把BST中的所有元素看成一维线段上的所有点，从树的根节点开始每个节点都会把线段分成两段。</p><p><img src="https://s3.bmp.ovh/imgs/2021/08/365f9e0e6ca0052c.jpeg" alt></p><p>所以BST本质上就是一维K-D树(或者叫做1-D树)</p><p>现在将树中的元素推广到二维平面上的点，树的每一层按照维度轮流划分。比如，奇数层按x轴划分，偶数层按y轴划分，这样就得到一棵二维K-D树(2-d树)</p><p><img src="https://s3.bmp.ovh/imgs/2021/08/345c1f9a74431519.jpeg" alt></p><p>很明显，K-D树和BST一样不仅可以精确查找，也更适合做范围查询，但K-D树比BST更强，它能对多个维度进行范围查询。</p><p>比如：</p><p>Person1(age:18,hight:176)，Person2(age:19,height:181) … Person10(age:23,height:171)</p><p>想要查找年龄在20岁以上并且身高在170到180之间的所有人，用K-D树就能很好的解决。</p><h2 id="K-D-B树"><a href="#K-D-B树" class="headerlink" title="K-D-B树"></a>K-D-B树</h2><p>既然KD树是高维的二叉搜索树，那么它自然也会继承二叉搜索树的缺点：会退化成链表。</p><p>二叉搜索树解决这个问题的办法是：AVL树，红黑树。那么这个办法能否推广到高维空间呢，答案是不能。</p><p>还有个解决方法是B树。有没有高维B树呢，有的：</p><p><img src="https://s3.bmp.ovh/imgs/2021/08/5871bb9a6111b295.jpeg" alt></p><p>但是B树也有问题：B树如果节点中的子节点树超过规定的阶数，就会发生节点分裂（数据库中经常称之为“页”分裂）。</p><p><img src="https://s3.bmp.ovh/imgs/2021/08/15b47785e81116d8.gif" alt></p><p>高维B树当然也继承了这个问题，并且更加严重页分裂的时候不能以B树“一刀切”的方式解决。</p><p>以二维K-D-B树为例，一个节点数据过多，需要分裂时，就需要拆分区域。拆分区域的过程中大概率会出现拆分该区域的子区域。</p><p>所以写入性能很差</p><h2 id="B-K-D树"><a href="#B-K-D树" class="headerlink" title="B-K-D树"></a>B-K-D树</h2><p>再次优化。</p><p>BKD树是二叉树和B+树的组合。比较特殊的是，内部node必须是一个完全二叉树，而叶子node存储的则和K-D-B树一模一样。</p><p><img src="https://s3.bmp.ovh/imgs/2021/08/f6f737dc48a79824.png" alt></p><p><img src="https://s3.bmp.ovh/imgs/2021/08/fdf434231d85f737.jpeg" alt></p><p>B-K-D树结合了二叉树和B+树的特性。比较特殊的是，内部节点必须形成一个完全二叉树，而叶子节点存储方式和K-D-B树叶子相同。</p><p>和堆类似，B-K-D树的内部节点组成了一个完全二叉树。这样的好处是节点不需要存储指向子节点的指针，根据父节点索引即可算出子节点索引。假如一个节点的位置在i ，那这个节点的左节点在位置2 i，右节点在2 i + 1 。</p><p>内部节点本身不包含数据，所有数据存储在叶子节点。较小的节点也意味着内存中可以缓存更多的节点。这一点和B+树类似。</p><p>另外B-K-D树的内部树永远不会被修改，而是使用一种策略来添加新数据。</p><p>首先，有一个大小为M的Buffer。在那片论文里，它是被保存在内存的。这个Buffer, 可能仅仅是一个数组或者性能更好的一些数据结构，毕竟是有查询需求的。论文并没有指明这个Buffer的最优大小，但是直觉上来说，至少应该和K-D树节点一样大。</p><p><img src="https://s3.bmp.ovh/imgs/2021/08/fdf434231d85f737.jpeg" alt></p><p>这里用了类似LSM树的技术。</p><p>如果BKD树由N个数据，那么它有 log2(N/M)个可修改的K-D树。每一个树都是前一个树的2倍。数据首先被插入到内存里的Buffer里，一旦Buffer满了，先定位到第1个为空的树。这个Buffer的数据，以及空树之前所有节点的数据一起生成一个满的平衡树。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;说到ES，就想到倒排索引，但是有个问题，我们在数字比大小的场景，倒排索引怎么实现呢？&lt;/p&gt;
&lt;p&gt;即range怎么实现的？&lt;/p&gt;
&lt;p&gt;早期的ES，只能把范围转化成in，最多再多一些小优化，自动产生一些区间的term，构建一个基于数字的字典树，但在大范围时依然没用，并且
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="ES" scheme="https://arvenseyz.github.io/tags/ES/"/>
    
  </entry>
  
  <entry>
    <title>ES的store、source、index属性</title>
    <link href="https://arvenseyz.github.io/2021/08/10/8-10%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>https://arvenseyz.github.io/2021/08/10/8-10技术笔记-1/</id>
    <published>2021-08-10T06:59:40.000Z</published>
    <updated>2021-08-10T07:49:48.496Z</updated>
    
    <content type="html"><![CDATA[<h1 id="index"><a href="#index" class="headerlink" title="index"></a>index</h1><p>index的含义还比较容易简单，一共3个值，no,analyzied，not_analyzied，分别对应’不对该字段进行索引（无法搜索）’，’分词后索引’，’以单个关键词进行索引’。</p><h1 id="source"><a href="#source" class="headerlink" title="source"></a>source</h1><p>es里除了倒排索引，当然还会把文档原文存储一遍，存储的这一遍就是source。</p><p>官方文档解释如下：</p><blockquote><p>默认地，Elasticsearch 在  <code>_source</code>  字段存储代表文档体的JSON字符串。和所有被存储的字段一样，  <code>_source</code>  字段在被写入磁盘之前先会被压缩。</p><p>这个字段的存储几乎总是我们想要的，因为它意味着下面的这些：</p><ul><li>搜索结果包括了整个可用的文档——不需要额外的从另一个的数据仓库来取文档。</li><li>如果没有  <code>_source</code>  字段，部分  <code>update</code>  请求不会生效。</li><li>当你的映射改变时，你需要重新索引你的数据，有了_source字段你可以直接从Elasticsearch这样做，而不必从另一个（通常是速度更慢的）数据仓库取回你的所有文档。</li><li>当你不需要看到整个文档时，单个字段可以从  <code>_source</code>  字段提取和通过  <code>get</code>  或者  <code>search</code>  请求返回。</li><li>调试查询语句更加简单，因为你可以直接看到每个文档包括什么，而不是从一列id猜测它们的内容。</li></ul><p>然而，存储  <code>_source</code>  字段的确要使用磁盘空间。如果上面的原因对你来说没有一个是重要的，你可以用下面的映射禁用  <code>_source</code>  字段。</p></blockquote><p><a href="https://imgtu.com/i/fY9nJ0" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/08/10/fY9nJ0.png" alt="fY9nJ0.png"></a></p><p>当然可以关闭该属性。</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"mappings"</span>:&#123;</span><br><span class="line">        <span class="attr">"_source"</span>:&#123;</span><br><span class="line">            <span class="attr">"enabled"</span>:<span class="literal">false</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"properties"</span>: &#123;</span><br><span class="line">            ... </span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>或者选择性开启某些字段</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"mappings"</span>:&#123;</span><br><span class="line">        <span class="attr">"_source"</span>: &#123;</span><br><span class="line">          <span class="attr">"includes"</span>: [</span><br><span class="line">            <span class="string">"*.count"</span>,</span><br><span class="line">            <span class="string">"meta.*"</span></span><br><span class="line">          ],</span><br><span class="line">          <span class="attr">"excludes"</span>: [</span><br><span class="line">            <span class="string">"meta.description"</span>,</span><br><span class="line">            <span class="string">"meta.other.*"</span></span><br><span class="line">          ]</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="string">"properties"</span>: &#123;</span><br><span class="line">            ... </span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>于是问题来了，既然搜不出，我干嘛要用。</p><p> 答案是，虽然搜不出来，但是可以搜到，比如我们只用es搜索，用这些字段可以搜出id，然后内容存在某个kv数据库中，再用该id去这个kv数据库搜。</p><h1 id="store"><a href="#store" class="headerlink" title="store"></a>store</h1><p>store和source的include似乎结果上是相同的，即某些字段可以被搜出来。</p><p>官方解释</p><blockquote><p>默认情况下，字段值被<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-index.html" title="index" target="_blank" rel="noopener">index</a>以使其可搜索，但它们不会被<em>存储</em>。这意味着可以查询该字段，但无法检索原始字段值。</p><p>通常这无关紧要。字段值已经是<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-source-field.html" title="_source 字段" target="_blank" rel="noopener"><code>_source</code>字段的</a>一部分， 默认情况下存储。如果您只想检索单个字段或几个字段的值，而不是整个<code>_source</code>，那么这可以通过<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-fields.html#source-filtering" title="_source 选项" target="_blank" rel="noopener">源过滤</a>来实现 。</p><p>在某些情况下，它可能对<code>store</code>某个领域有意义。例如，如果您有一个包含 a <code>title</code>、 a<code>date</code>和一个非常大的<code>content</code> 字段的文档，您可能只想检索 the<code>title</code>和 the<code>date</code>而不必从大<code>_source</code>字段中提取这些字段：</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;index&quot;&gt;&lt;a href=&quot;#index&quot; class=&quot;headerlink&quot; title=&quot;index&quot;&gt;&lt;/a&gt;index&lt;/h1&gt;&lt;p&gt;index的含义还比较容易简单，一共3个值，no,analyzied，not_analyzied，分别对应’不对该字
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="ES" scheme="https://arvenseyz.github.io/tags/ES/"/>
    
  </entry>
  
  <entry>
    <title>缓存的数据一致性问题</title>
    <link href="https://arvenseyz.github.io/2021/01/14/1-14%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>https://arvenseyz.github.io/2021/01/14/1-14技术笔记/</id>
    <published>2021-01-14T07:13:03.000Z</published>
    <updated>2021-01-14T07:59:24.965Z</updated>
    
    <content type="html"><![CDATA[<p> 一般来说，缓存有以下三种模式：</p><ul><li><p>Cache Aside 更新模式</p></li><li><p>Read/Write Through 更新模式</p></li><li><p>Write Behind Caching 更新模式</p></li></ul><p>通俗一点来讲就是，同时更新缓存和数据库（Cache Aside 更新模式）；先更新缓存，缓存负责同步更新数据库（Read/Write Through 更新模式）；先更新缓存，缓存定时异步更新数据库（Write Behind Caching 更新模式）</p><h1 id="Cache-Aside-旁路缓存-策略"><a href="#Cache-Aside-旁路缓存-策略" class="headerlink" title="Cache Aside(旁路缓存)策略"></a>Cache Aside(旁路缓存)策略</h1><h2 id="更新缓存的问题"><a href="#更新缓存的问题" class="headerlink" title="更新缓存的问题"></a>更新缓存的问题</h2><p>首先是缓存更新还是删除，采用删除，原因有两点：</p><ol><li><p>对于对象类型，或者文本类型，修改缓存value的成本较高。</p></li><li><p>有并发问题。</p></li></ol><p>即同时有请求A和请求B进行更新操作，那么会出现<br>（1）线程A更新了数据库<br>（2）线程B更新了数据库<br>（3）线程B更新了缓存<br>（4）线程A更新了缓存<br>这就出现请求A更新缓存应该比请求B更新缓存早才对，但是因为网络等原因，B却比A更早更新了缓存。这就导致了脏数据，因此不考虑。</p><h2 id="先删缓存的问题"><a href="#先删缓存的问题" class="headerlink" title="先删缓存的问题"></a>先删缓存的问题</h2><p>其次是先删缓存还是先改数据库。</p><p>都有问题。</p><p>先删缓存问题如下：</p><h3 id="并发问题"><a href="#并发问题" class="headerlink" title="并发问题"></a>并发问题</h3><p>同时有一个请求A进行更新操作，另一个请求B进行查询操作。那么会出现如下情形:<br>（1）请求A进行写操作，删除缓存<br>（2）请求B查询发现缓存不存在<br>（3）请求B去数据库查询得到旧值<br>（4）请求B将旧值写入缓存<br>（5）请求A将新值写入数据库<br>上述情况就会导致不一致的情形出现。而且，如果不采用给缓存设置过期时间策略，该数据永远都是脏数据。</p><h3 id="主从同步问题"><a href="#主从同步问题" class="headerlink" title="主从同步问题"></a>主从同步问题</h3><p>两个请求，一个请求A进行更新操作，另一个请求B进行查询操作。  </p><p>（1）请求A进行写操作，删除缓存<br>（2）请求A将数据写入数据库了，<br>（3）请求B查询缓存发现，缓存没有值<br>（4）请求B去从库查询，这时，还没有完成主从同步，因此查询到的是旧值<br>（5）请求B将旧值写入缓存<br>（6）数据库完成主从同步，从库变为新值</p><h3 id="异步双删"><a href="#异步双删" class="headerlink" title="异步双删"></a>异步双删</h3><p>等一定时间（主从同步时间）后，再次删除</p><h2 id="先更新数据库的问题"><a href="#先更新数据库的问题" class="headerlink" title="先更新数据库的问题"></a>先更新数据库的问题</h2><h3 id="原子性问题"><a href="#原子性问题" class="headerlink" title="原子性问题"></a>原子性问题</h3><p>更新数据库成功，删除缓存失败，不好处理。</p><h3 id="并发问题-1"><a href="#并发问题-1" class="headerlink" title="并发问题"></a>并发问题</h3><p>假设这会有两个请求，一个请求A做查询操作，一个请求B做更新操作，那么会有如下情形产生<br>（1）缓存刚好失效<br>（2）请求A查询数据库，得一个旧值<br>（3）请求B将新值写入数据库<br>（4）请求B删除缓存<br>（5）请求A将查到的旧值写入缓存<br>ok，如果发生上述情况，确实是会发生脏数据。</p><p>但是这种问题，出现在写操作比读操作慢，一般不会发生。</p><h3 id="异步双删-1"><a href="#异步双删-1" class="headerlink" title="异步双删"></a>异步双删</h3><p>也可以解决这个问题。</p><p>异步第二次删除失败怎么处理，搞个失败队列啥的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt; 一般来说，缓存有以下三种模式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Cache Aside 更新模式&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Read/Write Through 更新模式&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Write Behind Caching 更新模式&lt;/p&gt;
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="redis" scheme="https://arvenseyz.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>mongo分布式一致性</title>
    <link href="https://arvenseyz.github.io/2020/12/30/12-30%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>https://arvenseyz.github.io/2020/12/30/12-30技术笔记/</id>
    <published>2020-12-30T03:07:26.000Z</published>
    <updated>2020-12-30T07:05:33.879Z</updated>
    
    <content type="html"><![CDATA[<h1 id="CAP与BASE"><a href="#CAP与BASE" class="headerlink" title="CAP与BASE"></a>CAP与BASE</h1><p>CAP原理为基础，实际上现在大部分系统都是BASE的，其实BASE很好理解，即基本可用，最终一致。是一种可用性与一致性平衡的状态。</p><p>具体在实践中，指：一主多从，主写从读，主挂了切从，选举的时候只能读不能写（基本可用），从库不保证能读到刚写入的数据。</p><p>这里个角度看，mongo的分布式一致性与mysql主从架构是一致的。</p><p>mongo现在使用的是副本集形式。</p><p>集群拥有一个主节点和多个从节点，这一点与主从复制模式类似，且主从节点所负责的工作也类似，但是副本集与主从复制的区别在于：当集群中主节点发生故障时，副本集可以自动投票，选举出新的主节点，并引导其余的从节点连接新的主节点，而且这个过程对应用是透明的。  </p><h1 id="Replica-Set"><a href="#Replica-Set" class="headerlink" title="Replica Set"></a>Replica Set</h1><p>可以说，MongoDB 的副本集是自带故障转移功能的主从复制。  </p><p>MongoDB 副本集使用的是 N 个 mongod 节点构建的具备自动容错功能、自动恢复功能的高可用方案。在副本集中，任何节点都可作为主节点，但为了维持数据一致性，只能有一个主节点。  </p><p>主节点负责数据的写入和更新，并在更新数据的同时，将操作信息写入名为 oplog 的日志文件当中。主节点还负责指定其他节点为从节点，并设置从节点数据的可读性，从而让从节点来分担集群读取数据的压力。  </p><p>另外，从节点会定时轮询读取 oplog 日志，根据日志内容同步更新自身的数据，保持与主节点一致。  </p><p>在一些场景中，用户还可以使用副本集来扩展读性能，客户端有能力发送读写操作给不同的服务器，也可以在不同的数据中心获取不同的副本来扩展分布式应用的能力。  </p><p>在副本集中还有一个额外的仲裁节点（不需要使用专用的硬件设备），负责在主节点发生故障时，参与选举新节点作为主节点。  选举使用的是raft算法。</p><p>副本集中的各节点会通过心跳信息来检测各自的健康状况，当主节点出现故障时，多个从节点会触发一次新的选举操作，并选举其中一个作为新的主节点。为了保证选举票数不同，副本集的节点数保持为奇数。</p><h1 id="读写一致性"><a href="#读写一致性" class="headerlink" title="读写一致性"></a>读写一致性</h1><h2 id="swrite-concern"><a href="#swrite-concern" class="headerlink" title="swrite-concern"></a>swrite-concern</h2><p><a href="https://imgchr.com/i/rLib0f" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2020/12/30/rLib0f.png" alt="rLib0f.png"></a></p><p>　write concern表示对于写操作，MongoDB在什么情况下给予客户端响应。包括下面三个字段：</p><blockquote><p>　　{ w: <value>, j: <boolean>, wtimeout: <number> }</number></boolean></value></p></blockquote><p>先看journal，默认开启，即写入了日志文件再返回，不然就是写入了内存就返回了。</p><p>指定超时等待写入咨询Write concern的写操作仅表示所需数量的副本集成员未在wtimeout时间段内确认写操作。它不一定表示主节点Primary未能应用写入。</p><p>w: 表示当写请求在value个MongoDB实例处理之后才向客户端返回。取值范围：</p><p>0表示直接返回，显然性能高，容易丢数据。</p><p>1是默认值，即写入主节点返回。</p><p>majority是指写入从的大部分节点才返回。</p><p>一般默认配置是，write concern为1，journal为true，这样宕机也能通过journal找回数据，但是依然会丢数据。即主库刚写入就挂了，新选的从库没有这条数据了。</p><h2 id="Read-preference"><a href="#Read-preference" class="headerlink" title="Read preference"></a>Read preference</h2><p>读跟写不一样，为了保持一致性，写只能通过主节点，但读可以选择主节点，也可以选择副本节点，区别是主节点数据最新，副本节点因为同步问题可能会有延迟，但从副本节点读取数据可以分散对主节点的压力。</p><p>读偏好指的是读主还是读从，可以想象到有这么四种，强制读主，优先读主，强制读从，优先读从。还有第五种，主从一致，基于延迟选择。</p><h2 id="read-concern"><a href="#read-concern" class="headerlink" title="read concern"></a>read concern</h2><p>有三个级别，local和majority以及linearizable。</p><p>majority  的初衷在于解决『脏读』的问题，比如用户从 MongoDB 的 primary 上读取了某一条数据，但这条数据并没有同步到大多数节点，然后 primary 就故障了，重新恢复后 这个primary 节点会将未同步到大多数节点的数据回滚掉，导致用户读到了『脏数据』。</p><p>当指定 readConcern 级别为 majority 时，能保证用户读到的数据『已经写入到大多数节点』，而这样的数据肯定不会发生回滚，避免了脏读的问题。</p><p>需要注意的是，<code>majority</code> 能保证读到的数据『不会发生回滚』，但并不能保证读到的数据是最新的，无论何种级别的 <code>majority</code>，客户端都只会从『某一个确定的节点』（具体是哪个节点由 readPreference 决定）读取数据，该节点根据自己看到的同步状态视图，只会返回已经同步到大多数节点的数据。</p><p>（因为他还不知道大多数节点已经更新了）</p><p><a href="https://www.docs4dev.com/docs/en/mongodb/v3.6/reference/reference-read-concern-majority.html" target="_blank" rel="noopener">https://www.docs4dev.com/docs/en/mongodb/v3.6/reference/reference-read-concern-majority.html</a></p><p>其实majority是有bug的，就是无法面对网络分区的所带来的多主问题，出现了解决方案，即“<strong>线性化</strong>”读取问题。使用此属性，mongo会在发出读取操作的结果之前检查其主节点并查看大多数节点。但是，对于“多数”使用此“读取关注点”会有性能成本的损失，因此这不能替代“多数”读取关注点。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;CAP与BASE&quot;&gt;&lt;a href=&quot;#CAP与BASE&quot; class=&quot;headerlink&quot; title=&quot;CAP与BASE&quot;&gt;&lt;/a&gt;CAP与BASE&lt;/h1&gt;&lt;p&gt;CAP原理为基础，实际上现在大部分系统都是BASE的，其实BASE很好理解，即基本可用，最终
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="分布式" scheme="https://arvenseyz.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="mongo" scheme="https://arvenseyz.github.io/tags/mongo/"/>
    
  </entry>
  
  <entry>
    <title>mongo索引</title>
    <link href="https://arvenseyz.github.io/2020/12/29/12-29%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>https://arvenseyz.github.io/2020/12/29/12-29技术笔记-1/</id>
    <published>2020-12-29T03:57:43.000Z</published>
    <updated>2020-12-29T07:06:28.979Z</updated>
    
    <content type="html"><![CDATA[<p>在现在的引擎即wiredTiger下，mongo索引也用的是B+树。</p><h1 id="为什么要用B-树"><a href="#为什么要用B-树" class="headerlink" title="为什么要用B+树"></a>为什么要用B+树</h1><p>原因和mysql一样，B+树很宽，这样树很扁，减少了磁盘io。</p><h1 id="B-树什么样子的"><a href="#B-树什么样子的" class="headerlink" title="B+树什么样子的"></a>B+树什么样子的</h1><p><a href="https://imgchr.com/i/rHRpfx" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2020/12/29/rHRpfx.png" alt="rHRpfx.png"></a></p><p>在整个B-Tree中，从上往下依次为Root结点、内部结点和叶子结点，每个结点就是一个Page，数据以Page为单位在内存和磁盘间进行调度，每个Page的大小决定了相应结点的分支数量，每条索引记录会包含一个数据指针，指向一条数据记录所在文件的偏移量。</p><p>如上图，假设每个结点100个分支，那么所有叶子结点合起来可以包含100万个键值（等于100<em>100</em>100）。通常情况下Root结点和内部结点的Page会驻留在内存中，所以查找一条数据可能只需2次磁盘I/O。但随着数据不断的插入、删除，会涉及到B-Tree结点的分裂、位置提升及合并等操作，因此维护一个B-Tree的平衡也是比较耗时的。</p><p>B<strong>+</strong> Tree中的leaf page包含一个页头（page header）、块头（block header）和真正的数据（key/value），其中页头定义了页的类型、页中实际载荷数据的大小、页中记录条数等信息；块头定义了此页的checksum、块在磁盘上的寻址位置等信息。</p><p>WiredTiger有一个块设备管理的模块，用来为page分配block。如果要定位某一行数据（key/value）的位置，可以先通过block的位置找到此page（相对于文件起始位置的偏移量），再通过page找到行数据的相对位置，最后可以得到行数据相对于文件起始位置的偏移量offsets。由于offsets是一个8字节大小的变量，所以WiredTiger磁盘文件的大小，其最大值可以非常大(2^64bit)。</p><h1 id="叶子节点里有什么"><a href="#叶子节点里有什么" class="headerlink" title="叶子节点里有什么"></a>叶子节点里有什么</h1><p><a href="https://imgchr.com/i/rH4CUH" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2020/12/29/rH4CUH.png" alt="rH4CUH.png"></a></p><p>对数据的查询，修改，新增，都是先到内存，后到磁盘。</p><ul><li><p>内存上的leaf page会维护一个WT_ROW结构的数组变量，将保存从磁盘leaf page读取的keys/values值，每一条记录还有一个cell_offset变量，表示这条记录在page上的偏移量；</p></li><li><p>内存上的leaf page会维护一个WT_UPDATE结构的数组变量，每条被修改的记录都会有一个数组元素与之对应，如果某条记录被多次修改，则会将所有修改值以链表形式保存。</p></li><li><p>内存上的leaf page会维护一个WT_INSERT_HEAD结构的数组变量，具体插入的data会保存在WT_INSERT_HEAD结构中的WT_UPDATE属性上，且通过key属性的offset和size可以计算出此条记录待插入的位置；同时，为了提高寻找待插入位置的效率，每个WT_INSERT_HEAD变量以跳转链表的形式构成。</p></li></ul><h1 id="索引分类"><a href="#索引分类" class="headerlink" title="索引分类"></a>索引分类</h1><h2 id="id-字段索引"><a href="#id-字段索引" class="headerlink" title="_id 字段索引"></a>_id 字段索引</h2><p>默认情况下，MongoDB 在创建一个 collection 的时候，会创建一个 _id 字段，该字段是一个唯一索引，保证不会重复插入两份相同的 documents；同时，该字段是不允许被删除的；</p><h2 id="单字段和复合索引"><a href="#单字段和复合索引" class="headerlink" title="单字段和复合索引"></a>单字段和复合索引</h2><p>类似与mysql。还能指定顺序，sort时也走索引。</p><h2 id="数组索引"><a href="#数组索引" class="headerlink" title="数组索引"></a>数组索引</h2><p>如果为一个数组类型的key建立了索引，实际上是给数组中的每一个元素建立了一条索引。</p><p>可以为某个数组字段的每一个元素建立索引，但有限制</p><ol><li><p>不能同时在两个数组字段上建立一个复合索引</p></li><li><p>不能使用数组索引( Multikey Indexes )来做为分片主键( Sharded Key )</p></li><li><p>不能用作 Hashed Indexes</p></li><li><p>如果查询条件是需要完整匹配整个数组的元素，包含顺序；那么这个时候，数组索引只能作用到第一个查询元素上，它会查询所有的数组中包含该元素的数组，然后再从这些数组中依次匹配，找到完全匹配的数组项</p></li></ol><h1 id="索引变种"><a href="#索引变种" class="headerlink" title="索引变种"></a>索引变种</h1><h2 id="唯一索引"><a href="#唯一索引" class="headerlink" title="唯一索引"></a>唯一索引</h2><p>同mysql，也支持联合unique。</p><h2 id="部分索引"><a href="#部分索引" class="headerlink" title="部分索引"></a>部分索引</h2><p>有时候，如果对所有的数据都创建索引，非常浪费资源而且可能会导致性能问题；所以，通过 Partial Indexes 可以通过对需要被索引的字段设置过滤条件，进而只在该字段的部分数据集上创建索引，有针对性的提升查询性能。</p><h2 id="稀疏索引"><a href="#稀疏索引" class="headerlink" title="稀疏索引"></a>稀疏索引</h2><p>MongoDB 中同一个 collection M 中的不同 document 的结构是随性的，是可以不相同的，document A 可以包含 Field X 但是 document B 可以不包含 Field X，包含的却是另外一个字段 Field X；所以，假设，我们按照常规索引的方式对 Field X 创建索引，这个时候，MongoDB 会对整个 collection M 中的记录创建索引，当 document B 不存在该字段 Field X 的时候，会使用 X = <code>null</code> 的方式为其同样的创建索引；这样的话，就造成了不必要的空间浪费，所以，稀疏索引既是 Sparse Indexes 诞生了，它诞生的目的就是为了解决上述的情况，当 document B 不存在 Field X 的时候，直接将该记录跳过，不为该记录其创建任何索引；</p><h2 id="生死索引-Time-To-Alive-Indexes-TTL-Indexes"><a href="#生死索引-Time-To-Alive-Indexes-TTL-Indexes" class="headerlink" title="生死索引( Time To Alive Indexes, TTL Indexes )"></a>生死索引( Time To Alive Indexes, TTL Indexes )</h2><p>TTL index 是在某个<code>日期字段</code>上所创建的一种索引，其作用是，为其设置声明时间，如果超过了声明时间，那么 MongoDB 将会自动的去删除该记录( document )；</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在现在的引擎即wiredTiger下，mongo索引也用的是B+树。&lt;/p&gt;
&lt;h1 id=&quot;为什么要用B-树&quot;&gt;&lt;a href=&quot;#为什么要用B-树&quot; class=&quot;headerlink&quot; title=&quot;为什么要用B+树&quot;&gt;&lt;/a&gt;为什么要用B+树&lt;/h1&gt;&lt;p&gt;原因和m
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="mongo" scheme="https://arvenseyz.github.io/tags/mongo/"/>
    
  </entry>
  
  <entry>
    <title>mongo的数据类型和bson</title>
    <link href="https://arvenseyz.github.io/2020/12/28/12-28%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>https://arvenseyz.github.io/2020/12/28/12-28技术笔记/</id>
    <published>2020-12-28T02:32:52.000Z</published>
    <updated>2020-12-28T06:51:56.750Z</updated>
    
    <content type="html"><![CDATA[<h1 id="bosn"><a href="#bosn" class="headerlink" title="bosn"></a>bosn</h1><p>mongo的数据格式很像json，但是有所不同，因为json有所缺陷，</p><p>例如,JSON没有日期类型,只有一种数字类型,无法区分浮点数和整数,更别说区分32为和64位数字了。再者,JSON无法表示其他一些通用类型,如正则表达式或函数。所以mongo使用的bson，相当于是json在类型上进行了扩展。</p><h1 id="数字类型"><a href="#数字类型" class="headerlink" title="数字类型"></a>数字类型</h1><p>值得说明的是其数字类型，mongoDb默认将数字认为double类型，如果想使用其他的类型，需要使用转化函数。</p><p>值得注意的是，mongodb shell实际上是一个js引擎，使用数字时，是先转化成double，继续转，所以可能先失真了一次。例如大整数时失真。</p><h1 id="type-运算符"><a href="#type-运算符" class="headerlink" title="$type 运算符"></a>$type 运算符</h1><p>如果想获取 “col” 集合中 title 为 String 的数据，可以使用以下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">db.col.find(&#123;&quot;title&quot; : &#123;$type : 2&#125;&#125;)</span><br><span class="line">或</span><br><span class="line">db.col.find(&#123;&quot;title&quot; : &#123;$type : &apos;string&apos;&#125;&#125;)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;bosn&quot;&gt;&lt;a href=&quot;#bosn&quot; class=&quot;headerlink&quot; title=&quot;bosn&quot;&gt;&lt;/a&gt;bosn&lt;/h1&gt;&lt;p&gt;mongo的数据格式很像json，但是有所不同，因为json有所缺陷，&lt;/p&gt;
&lt;p&gt;例如,JSON没有日期类型,只有一种数
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="mongo" scheme="https://arvenseyz.github.io/tags/mongo/"/>
    
  </entry>
  
  <entry>
    <title>mongo简单查询</title>
    <link href="https://arvenseyz.github.io/2020/12/24/12-24%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>https://arvenseyz.github.io/2020/12/24/12-24技术笔记/</id>
    <published>2020-12-24T10:17:44.000Z</published>
    <updated>2020-12-28T06:51:53.705Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://imgchr.com/i/r2lMgf" target="_blank" rel="noopener"><img src="https://s3.ax1x.com/2020/12/24/r2lMgf.jpg" alt="r2lMgf.jpg"></a></p><p>compass各参数解释如下：</p><p>filter：即筛选条件，相当于sql的where，kv写法即等于，其他需要：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123; field: &#123; $lt: value&#125; &#125;</span><br><span class="line">&#123; field: &#123; $gt: value&#125; &#125;</span><br><span class="line">&#123; field: &#123; $lte: value&#125; &#125;</span><br><span class="line">&#123; field: &#123; $gte: value&#125; &#125;</span><br></pre></td></tr></table></figure><p>project：相当于sql中的select，即需要哪些字段，kv写法，1是0否。</p><p>sort：排序方法。1升序，-1降序，可以多字段。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123; username: -1, date: -1 &#125;</span><br></pre></td></tr></table></figure><p>skip，limit。即offset和limit。</p><p>collation。排序方法.归类允许用户为字符串比较指定特定于语言的规则，例如字母大写和重音符号的规则。比如汉字默认按二进制比较，相当于没有比。内置了按拼音比较的方式。   即图中的所在地。</p><p>and和or。and连着写就好，or需要用$or运算符</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db.col.find(&#123;&quot;date&quot;: &#123;$gt:50&#125;, $or: [&#123;&quot;username&quot;: &quot;阿萨萨&quot;&#125;,&#123;&quot;title&quot;: &quot;StudentFile&quot;&#125;]&#125;).pretty()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://imgchr.com/i/r2lMgf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;img src=&quot;https://s3.ax1x.com/2020/12/24/r2lMgf.jpg&quot; alt=&quot;r2lMgf.jpg
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="mongo" scheme="https://arvenseyz.github.io/tags/mongo/"/>
    
  </entry>
  
</feed>
