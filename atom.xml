<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Arvense</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://arvenseyz.github.io/"/>
  <updated>2021-12-14T09:55:12.164Z</updated>
  <id>https://arvenseyz.github.io/</id>
  
  <author>
    <name>Arvense</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>RocketMQ 消息存储</title>
    <link href="https://arvenseyz.github.io/2021/12/14/12-14%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>https://arvenseyz.github.io/2021/12/14/12-14技术笔记-1/</id>
    <published>2021-12-14T09:04:05.000Z</published>
    <updated>2021-12-14T09:55:12.164Z</updated>
    
    <content type="html"><![CDATA[<h2 id="先回顾下kafka"><a href="#先回顾下kafka" class="headerlink" title="先回顾下kafka"></a>先回顾下kafka</h2><p><img src="https://cdn.jsdelivr.net/gh/arvenseyz/imageCloud/2a57c077-1ae2-460d-be0b-168329058e70.png" alt></p><p>Kafka 以 Topic 作为文件存储的基本单元，即每个 Topic 有其对应的数据文件和索引文件。消息直接存储在partition中，对单topic为顺序写。</p><p>这样预期结果是，磁盘顺序写+顺序读，性能很好。</p><p>但问题是，是分topic的，如果topic很多，要不停的切topic，顺序读写就被破坏了，降低了性能。</p><h2 id="RocketMQ-消息存储"><a href="#RocketMQ-消息存储" class="headerlink" title="RocketMQ 消息存储"></a>RocketMQ 消息存储</h2><p><img src="https://cdn.jsdelivr.net/gh/arvenseyz/imageCloud/d27e7402-138b-4654-9bed-1da9175417a1.png" alt></p><p>RocketMQ 既然号称能支持万级别topic，肯定不是kafka这么存的。</p><p>首先是存储上不分topic，所以这些topic的内容写在一块的。即CommitLog。</p><p>那既然不同topic，内容在一块，怎么读呢，答案是加一个索引，同时，由于消息仍需要以 Topic 为维度进行消费，因此 RocketMQ 基于 CommitLog 为每个 Topic 异步构建多个逻辑队列（ConsumeQueue），逻辑队列消息是定长的，因为只有表头，存储了这个Queue在CommiLog中的起始offset，log大小和MessageTag的hashCode。</p><p>既然是定长的，根据offset，就能找到消息在ConsumeQueue中的位置，然后再读到在CommiLog中的起始offset，最后从CommiLog读到消息内容。</p><p>消息存储只是把消息主体存储到了物理文件中，但是并没有把消息处理到consumeQueue文件中，那么到底是哪里存入的？答案是起一个线程，不停的轮询，将当前的consumeQueue中的offSet和commitLog中的offSet进行对比，将多出来的offSet进行解析，然后put到consumeQueue中的MapedFile中。</p><p>另外还有个index文件</p><p>index文件是为搜索场景而生的，如果没有搜索业务需求，则这个实现是意义不大的。一般这种搜索，主要用于后台查询验证类使用，或者有其他同的有妙用，不得而知。总之，一切为搜索。它更多的需要借助于时间限定，以key或者id进行查询。</p><p>　那么，如果要查找一个key, 应当如何查找呢？rocketmq会根据时间段找到一个index索引分版，然后再根据key做hash得到一个值，然后定位到 slotValue . 然后再从slotValue去取出索引数据的地址，找到索引数据，然后再回查 commitlog 文件。从而得到具体的消息数据。也就是，相当于搜索经历了四级查询： 索引分片文件查询 -&gt; slotValue 查询 -&gt; 索引数据查询 -&gt; commitlog 查询 。</p><p>看起来比较复杂，但搜索场景毕竟不多。</p><h2 id="RocketMQ-优缺点"><a href="#RocketMQ-优缺点" class="headerlink" title="RocketMQ 优缺点"></a>RocketMQ 优缺点</h2><p>上面的流程，优点是什么呢？</p><p>除了支持多topic外，因为consumequeue数据量小，绝大部分的访问还是Page Cache的访问，而不是磁盘访问。  </p><p>正式部署也可以将CommitLog和consumerQueue放在不同的物理SSD，避免多类文件进行IO竞争。  </p><p>缺点:</p><p>读取消息时，由于不同的topic消息都写在同一个文件，导致读取顺序不连续，造成随机读，降低了读IO。</p><h2 id="怎么降低缺点影响"><a href="#怎么降低缺点影响" class="headerlink" title="怎么降低缺点影响"></a>怎么降低缺点影响</h2><p>（硬件上的原因，缺点似乎不存在了，现在都是ssd，ssd随机读性能很好）</p><h3 id="Mmap"><a href="#Mmap" class="headerlink" title="Mmap"></a>Mmap</h3><p>Mmap内存映射和普通标准IO操作的本质区别在于它并不需要将文件中的数据先拷贝至OS的内核IO缓冲区，而是可以直接将用户进程私有地址空间中的一块区域与文件对象建立映射关系，这样程序就好像可以直接从内存中完成对文件读/写操作一样。只有当缺页中断发生时，直接将文件从磁盘拷贝至用户态的进程空间内，只进行了一次数据拷贝。对于容量较大的文件来说(文件大小一般需要限制在1.5~2G以下)，采用Mmap的方式其读/写的效率和性能都非常高。<br><em>JDK NIO</em>提供的MappedByteBuffer底层就是调用<em>mmap</em>来实现的</p><h3 id="PageCache机制"><a href="#PageCache机制" class="headerlink" title="PageCache机制"></a>PageCache机制</h3><p>PageCache是OS对文件的缓存，用于加速对文件的读写。一般来说，程序对文件进行顺序读写的速度几乎接近于内存的读写访问，这里的主要原因就是在于OS使用PageCache机制对读写访问操作进行了性能优化，将一部分的内存用作PageCache。(1)对于数据文件的读取，如果一次读取文件时出现未命中PageCache的情况，OS从物理磁盘上访问读取文件的同时，会顺序对其他相邻块的数据文件进行预读取(ps：顺序读入紧随其后的少数几个页面)。这样，只要下次访问的文件已经被加载至PageCache时，读取操作的速度基本等于访问内存。(2)对于数据文件的写入，OS会先写入至Cache内，随后通过异步的方式由pdflush内核线程将Cache内的数据刷盘至物理磁盘上。对于文件的顺序读写操作来说，读和写的区域都在OS的PageCache内，此时读写性能接近于内存。RocketMQ的大致做法是，将数据文件映射到OS的虚拟内存中(通过JDK NIO的MappedByteBuffer)，写消息的时候首先写入PageCache，并通过异步刷盘的方式将消息批量的做持久化(同时也支持同步刷盘)；订阅消费消息时(对CommitLog操作是随机读取)，由于PageCache的局部性热点原理且整体情况下还是从旧到新的有序读，因此大部分情况下消息还是可以直接从Page Cache中读取，不会产生太多的缺页(Page Fault)中断而从磁盘读取。</p><h4 id="预先分配MappedFile"><a href="#预先分配MappedFile" class="headerlink" title="预先分配MappedFile"></a>预先分配MappedFile</h4><p>在消息写入过程中(调用CommitLog的putMessage()方法)，CommitLog会先从MappedFileQueue队列中获取一个 MappedFile，如果没有就新建一个。这里，MappedFile的创建过程是将构建好的一个AllocateRequest请求(具体做法是，将下一个文件的路径、下下个文件的路径、文件大小为参数封装为AllocateRequest对象)添加至队列中，后台运行的AllocateMappedFileService服务线程(在Broker启动时，该线程就会创建并运行)，会不停地run，只要请求队列里存在请求，就会去执行MappedFile映射文件的创建和预分配工作，分配的时候有两种策略，一种是使用Mmap的方式来构建MappedFile实例，另外一种是从TransientStorePool堆外内存池中获取相应的DirectByteBuffer来构建MappedFile(ps：具体采用哪种策略，也与刷盘的方式有关)。并且，在创建分配完下个MappedFile后，还会将下下个MappedFile预先创建并保存至请求队列中等待下次获取时直接返回。RocketMQ中预分配MappedFile的设计非常巧妙，下次获取时候直接返回就可以不用等待MappedFile创建分配所产生的时间延迟。</p><h4 id="文件预热-amp-amp-mlock系统调用"><a href="#文件预热-amp-amp-mlock系统调用" class="headerlink" title="文件预热&amp;&amp;mlock系统调用"></a>文件预热&amp;&amp;mlock系统调用</h4><p>(1)mlock系统调用：其可以将进程使用的部分或者全部的地址空间锁定在物理内存中，防止其被交换到swap空间。对于RocketMQ这种的高吞吐量的分布式消息队列来说，追求的是消息读写低延迟，那么肯定希望尽可能地多使用物理内存，提高数据读写访问的操作效率。</p><p>(2)文件预热：预热的目的主要有两点；第一点，由于仅分配内存并进行mlock系统调用后并不会为程序完全锁定这些内存，因为其中的分页可能是写时复制的。因此，就有必要对每个内存页面中写入一个假的值。其中，RocketMQ是在创建并分配MappedFile的过程中，预先写入一些随机值至Mmap映射出的内存空间里。第二，调用Mmap进行内存映射后，OS只是建立虚拟内存地址至物理地址的映射表，而实际并没有加载任何文件至内存中。程序要访问数据时OS会检查该部分的分页是否已经在内存中，如果不在，则发出一次缺页中断。这里，可以想象下1G的CommitLog需要发生多少次缺页中断，才能使得对应的数据才能完全加载至物理内存中(ps：X86的Linux中一个标准页面大小是4KB)？RocketMQ的做法是，在做Mmap内存映射的同时进行madvise系统调用，目的是使OS做一次内存映射后对应的文件数据尽可能多的预加载至内存中，从而达到内存预热的效果。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;先回顾下kafka&quot;&gt;&lt;a href=&quot;#先回顾下kafka&quot; class=&quot;headerlink&quot; title=&quot;先回顾下kafka&quot;&gt;&lt;/a&gt;先回顾下kafka&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/arve
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="消息队列" scheme="https://arvenseyz.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>rocketMq推和拉</title>
    <link href="https://arvenseyz.github.io/2021/12/13/12-13%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>https://arvenseyz.github.io/2021/12/13/12-13技术笔记-1/</id>
    <published>2021-12-13T06:48:17.000Z</published>
    <updated>2021-12-13T07:42:26.964Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是推和拉"><a href="#什么是推和拉" class="headerlink" title="什么是推和拉"></a>什么是推和拉</h2><p>说到推拉，其实只针对消费者和broker的行为，生产者只有推（不然生产者岂不是还得把消息持久化等着broker来取数据）。</p><p><strong>推模式</strong>指的是consumer与broker建立好网络长连接，broker有相关数据，直接通过长连接通道推送到consumer。其优点是及时，一旦有数据变更，consumer立马能感知到；另外对consumer来说逻辑简单，不需要关心有无数据这些逻辑处理。缺点是不知道consumer的数据消费能力，可能导致数据积压在consumer，来不及处理。</p><p><strong>拉模式</strong>指的是consumer主动向broker发出请求，拉取相关数据。其优点是此过程由consumer发起请求，故不存在推模式中数据积压的问题。缺点是可能不够及时，对consumer来说需要考虑数据拉取相关逻辑，何时去拉，拉的频率怎么控制等等。</p><h2 id="RocketMq的推拉"><a href="#RocketMq的推拉" class="headerlink" title="RocketMq的推拉"></a>RocketMq的推拉</h2><p>RocketMq其实只有拉。</p><p>推是帮填了些参数的拉。consumer把轮询过程封装了，并注册MessageListener监听器，取到消息后，唤醒MessageListener的consumeMessage()来消费，对用户而言，感觉消息是被推送（push）过来的。主要用的也是这种方式。</p><p>如果是拉的话，客户端代码可能得这么写：</p><ol><li><p>注册消费者实例到nameserver</p></li><li><p>查询对应的topic消息队列以便可以消费其下所有数据</p></li><li><p>获取消息队列，消费消息;</p></li><li><p>自行维护保存消费偏移量，以便为下一次消费提供依据;</p></li><li><p>循环以上操作;</p></li></ol><p>可以看见还是比较麻烦。推的话，只需要注册回调方法即可。</p><h3 id="推是用拉-长轮询实现"><a href="#推是用拉-长轮询实现" class="headerlink" title="推是用拉+长轮询实现"></a>推是用拉+长轮询实现</h3><p>后台会有个 RebalanceService 线程，这个线程会根据 topic 的队列数量和当前消费组的消费者个数做负载均衡，每个队列产生的 pullRequest 放入阻塞队列 pullRequestQueue 中。然后又有个 PullMessageService 线程不断的从阻塞队列 pullRequestQueue 中获取 pullRequest，然后通过网络请求 broker，这样实现的准实时拉取消息。</p><p>上面操作相当于帮做了拉的1、2步</p><p>具体怎么长轮询拉的呢</p><p><img src="https://cdn.jsdelivr.net/gh/arvenseyz/imageCloud/9182641-667ee972d01888f3.webp" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;什么是推和拉&quot;&gt;&lt;a href=&quot;#什么是推和拉&quot; class=&quot;headerlink&quot; title=&quot;什么是推和拉&quot;&gt;&lt;/a&gt;什么是推和拉&lt;/h2&gt;&lt;p&gt;说到推拉，其实只针对消费者和broker的行为，生产者只有推（不然生产者岂不是还得把消息持久化等着broke
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="消息队列" scheme="https://arvenseyz.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>RocketMQ Rebalance机制</title>
    <link href="https://arvenseyz.github.io/2021/12/10/12-10%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>https://arvenseyz.github.io/2021/12/10/12-10技术笔记/</id>
    <published>2021-12-10T06:51:50.000Z</published>
    <updated>2021-12-13T03:30:58.392Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Rebalance是什么"><a href="#Rebalance是什么" class="headerlink" title="Rebalance是什么"></a><strong>Rebalance是什么</strong></h1><p>Rebalance(再均衡)机制指的是：将一个Topic下的<strong>多个队列(或称之为分区)</strong>，在同一个消费者组(consumer group)下的<strong>多个消费者实例</strong>(consumer instance)之间进行重新分配。</p><p><strong>Rebalance机制本意是为了提升消息的并行处理能力。</strong>例如，一个Topic下5个队列，在只有1个消费者的情况下，那么这个消费者将负责处理这5个队列的消息。如果此时我们增加一个消费者，那么可以给其中一个消费者分配2个队列，给另一个分配3个队列，从而提升消息的并行处理能力。</p><p>但是Rebalance机制也存在明显的<strong>限制</strong>与<strong>危害</strong>。</p><p><strong>Rebalance限制：</strong></p><p>由于一个队列最多分配给一个消费者，因此当某个消费者组下的消费者实例数量大于队列的数量时，多余的消费者实例将分配不到任何队列。</p><p><strong>Rebalance危害：</strong></p><p>除了以上限制，更加严重的是，在发生Rebalance时，存在着一些危害，如下所述：</p><ul><li><strong>消费暂停：</strong>考虑在只有Consumer 1的情况下，其负责消费所有5个队列；在新增Consumer 2，触发Rebalance时，需要分配2个队列给其消费。那么Consumer 1就需要停止这2个队列的消费，等到这两个队列分配给Consumer 2后，这两个队列才能继续被消费。</li><li><strong>重复消费：</strong>Consumer 2 在消费分配给自己的2个队列时，必须接着从Consumer 1之前已经消费到的offset继续开始消费。然而默认情况下，offset是异步提交的，如consumer 1当前消费到offset为10，但是异步提交给broker的offset为8；那么如果consumer 2从8的offset开始消费，那么就会有2条消息重复。也就是说，Consumer 2 并不会等待Consumer1提交完offset后，再进行Rebalance，因此提交间隔越长，可能造成的重复消费就越多。</li><li><strong>消费突刺：</strong>由于rebalance可能导致重复消费，如果需要重复消费的消息过多；或者因为rebalance暂停时间过长，导致积压了部分消息。那么都有可能导致在rebalance结束之后瞬间可能需要消费很多消息。</li></ul><h1 id="什么时候Reblance"><a href="#什么时候Reblance" class="headerlink" title="什么时候Reblance"></a>什么时候Reblance</h1><p>从本质上来说，触发Rebalance的根本因素无非是两个：</p><p><strong>1. 订阅Topic的队列数量变化</strong> </p><p><strong>2. 消费者组信息变化。</strong> </p><p><strong>队列信息</strong>和<strong>消费者组信息</strong>称之为Rebalance元数据，Broker负责维护这些元数据，并在二者信息发生变化时，以某种通知机制告诉消费者组下所有实例，需要进行Rebalance。从这个角度来说，Broker在Rebalance过程中，是一个协调者的角色。</p><h1 id="怎么reblance"><a href="#怎么reblance" class="headerlink" title="怎么reblance"></a>怎么reblance</h1><p>Broker是通知每个消费者各自Rebalance，即每个消费者自己给自己重新分配队列，而不是Broker将分配好的结果告知Consumer。从这个角度，RocketMQ与Kafka Rebalance机制类似，二者Rebalance分配都是在客户端进行，不同的是：</p><ul><li><strong>Kafka：</strong>会在消费者组的多个消费者实例中，选出一个作为Group Leader，由这个Group Leader来进行分区分配，分配结果通过Cordinator(特殊角色的broker)同步给其他消费者。相当于Kafka的分区分配只有一个大脑，就是Group Leader。</li><li><strong>RocketMQ：</strong>每个消费者，自己负责给自己分配队列，相当于每个消费者都是一个大脑。</li></ul><p>如果RocketMQ是去中心化的，必然有如下两个问题：</p><ol><li><p>脑裂：因为每个消费者都不知道其他消费者分配的结果，会不会出现一个队列分配给了多个消费者，或者有的队列分配给了多个消费者。</p></li><li><p>如果某个消费者没有收到Rebalance通知怎么办</p></li></ol><p><strong>只要任意一个消费者组需要Rebalance，这台机器上启动的所有其他消费者，也都要进行Rebalance</strong>。</p><h2 id="单个Topic-Rebalance流程"><a href="#单个Topic-Rebalance流程" class="headerlink" title="单个Topic Rebalance流程"></a><strong>单个Topic Rebalance流程</strong></h2><p>单个Topic的Rebalance流程，是在RebalanceImpl类的rebalanceByTopic方法中进行的，整体上可以分为4大步骤：</p><p>1、从namesrv获取messageQueue信息</p><p>2、从broker获取consumer信息</p><p>3、选择Rebalance策略</p><p>4、三者结合实现Rebalance操作</p><p>消费者在Rebalance时需要获得：Topic的队列信息和消费者组实例信息。</p><p><strong>对于队列信息：</strong></p><p>会从之前的缓存的Topic路由信息中获取；Topic路由信息会定时的进行更新。</p><p><strong>对于消费者组实例信息：</strong></p><p>前面我们提到过Broker通过ConsumerManager维护了所有的消费者信息，findConsumerIdList方法内部会会发送<strong>GET_CONSUMER_LIST_BY_GROUP</strong>给请求给任意一个Broker进行获取。</p><p>每个消费者是自己给自己分配，相当于存在多个大脑。那么如何保证分配结果的一致呢？通过以下两个手段来保证：</p><ul><li>对Topic队列，以及消费者各自进行排序</li><li>每个消费者需要使用相同的分配策略。</li></ul><p>尽管每个消费者是各自给自己分配，但是因为使用的相同的分配策略，定位从队列列表中哪个位置开始给自己分配，给自己分配多少个队列，从而保证最终分配结果的一致。</p><h2 id="出发时机"><a href="#出发时机" class="headerlink" title="出发时机"></a>出发时机</h2><p>简单地来说，RocketMQ有三个时机会触发负载均衡：</p><ol><li><p>启动的时候，会立即触发</p></li><li><p>有消费实例数量的变更的时候。broker在接受到消费者的心跳包的时候如果发现这个实例是新的实例的时候，会广播一个消费者数量变更的事件给所有消费者实例；同理，当发现一个消费者实例的连接断了，也会广播这样的一个事件</p></li><li><p>定期触发（默认20秒）。</p></li></ol><p>第一个时机很好理解。启动的时候，消费者需要需要知道自己要分配什么队列，所以要触发Rebalance。</p><p>第二个时机实际也很好理解。因为有实例的数量变更，所以分配的结果肯定也需要调整的，这时候就要广播给各消费者。</p><p>第三点定期触发的原因实际上是一个补偿机制，为了避免第二点广播的时候因为网络异常等原因丢失了重分配的信号，或者还有别的场景实际上也需要重新计算分配结果（例如队列的数量变化、权限变化），所以需要一个定时任务做补偿。</p><p>所以rocketMQ去中心化Reblance的机制，导致，负载均衡的这个实现原理，就会导致RocketMQ消息重复比一般的消息中间件概率要大，而且严重不少（消息是批量重复的）。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Rebalance是什么&quot;&gt;&lt;a href=&quot;#Rebalance是什么&quot; class=&quot;headerlink&quot; title=&quot;Rebalance是什么&quot;&gt;&lt;/a&gt;&lt;strong&gt;Rebalance是什么&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;Rebalance(再均衡
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="消息队列" scheme="https://arvenseyz.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>RocketMQ NameServer机制</title>
    <link href="https://arvenseyz.github.io/2021/12/09/12-9%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>https://arvenseyz.github.io/2021/12/09/12-9技术笔记/</id>
    <published>2021-12-09T06:32:21.000Z</published>
    <updated>2021-12-10T06:51:35.488Z</updated>
    
    <content type="html"><![CDATA[<h1 id="NameServer的作用"><a href="#NameServer的作用" class="headerlink" title="NameServer的作用"></a><strong>NameServer的作用</strong></h1><p><img src="https://raw.githubusercontent.com/arvenseyz/imageCloud/main/862aa9a7-9185-43af-933c-707030d471d6.png" alt></p><p>可以看到，Broker集群、Producer集群、Consumer集群都需要与NameServer集群进行通信：</p><p><strong>Broker集群</strong></p><p>Broker用于接收生产者发送消息，或者消费者消费消息的请求。一个Broker集群由多组Master/Slave组成，Master可写可读，Slave只可以读，Master将写入的数据同步给Slave。每个Broker节点，在启动时，都会遍历NameServer列表，与每个NameServer建立长连接，注册自己的信息，之后定时上报。</p><p><strong>Producer集群</strong></p><p>消息的生产者，通过NameServer集群获得Topic的路由信息，包括Topic下面有哪些Queue，这些Queue分布在哪些Broker上等。Producer只会将消息发送到Master节点上，因此只需要与Master节点建立连接。</p><p><strong>Consumer集群</strong></p><p>消息的消费者，通过NameServer集群获得Topic的路由信息，连接到对应的Broker上消费消息。注意，由于Master和Slave都可以读取消息，因此Consumer会与Master和Slave都建立连接。</p><h1 id="为什么要使用NameServer"><a href="#为什么要使用NameServer" class="headerlink" title="为什么要使用NameServer"></a><strong>为什么要使用NameServer</strong></h1><p>那么为什么rocketmq选择自己开发一个NameServer，而不是使用这些开源组件呢？</p><p>特别的，RocketMQ设计之初时参考的另一款消息中间件Kafka就使用了Zookeeper，Zookeeper其提供了Master选举、分布式锁、数据的发布和订阅等诸多功能。</p><p>事实上，在RocketMQ的早期版本，即MetaQ 1.x和MetaQ 2.x阶段，也是依赖Zookeeper的。但MetaQ 3.x（即RocketMQ）却去掉了ZooKeeper依赖，转而采用自己的NameServer。</p><p>而RocketMQ的架构设计决定了只需要一个轻量级的元数据服务器就足够了，只需要保持最终一致，而不需要Zookeeper这样的强一致性解决方案，不需要再依赖另一个中间件，从而减少整体维护成本。敏锐的同学肯定已经意识到了，根据CAP理论，RocketMQ在名称服务这个模块的设计上选择了AP，而不是CP。</p><p><strong>Zookeeper CP</strong></p><ul><li>分布式选主，主备高可用切换等场景下有不可替代的作用，而这些需求往往多集中在大数据、离线任务等相关的业务领域，因为大数据领域，讲究分割数据集，并且大部分时间分任务多进程 / 线程并行处理这些数据集，但是总是有一些点上需要将这些任务和进程统一协调，这时候就是 ZooKeeper 发挥巨大作用的用武之地。</li><li>但是在交易场景交易链路上，在主业务数据存取，大规模服务发现、大规模健康监测等方面有天然的短板，应该竭力避免在这些场景下引入 ZooKeeper，在生产实践中，应用对 ZooKeeper 申请使用的时候要进行严格的场景、容量、SLA 需求的评估。</li></ul><p><strong>NameServer AP</strong></p><p>NameServer作为一个名称服务，需要提供服务注册、服务剔除、服务发现这些基本功能，但是NameServer节点之间并不通信，容忍在某个时刻各个节点数据可能不一致的情况下</p><p><strong>所以可以使用 CP，也可以使用AP</strong>，但是大数据使用CP，在线服务则AP，分布式协调、选主使用CP，服务发现使用AP</p><h1 id="NameServer如何保证数据的最终一致"><a href="#NameServer如何保证数据的最终一致" class="headerlink" title="NameServer如何保证数据的最终一致"></a><strong>NameServer如何保证数据的最终一致</strong></h1><p>既然是AP系统，就需要保证最终一致。</p><h3 id="路由注册"><a href="#路由注册" class="headerlink" title="路由注册"></a><strong>路由注册</strong></h3><p>对于Zookeeper、Etcd这样强一致性组件，数据只要写到主节点，内部会通过状态机将数据复制到其他节点，Zookeeper使用的是Zab协议，etcd使用的是raft协议。</p><p>但是NameServer节点之间是互不通信的，无法进行数据复制。RocketMQ采取的策略是，在Broker节点在启动的时候，轮训NameServer列表，与每个NameServer节点建立长连接，发起注册请求。NameServer内部会维护一个Broker表，用来动态存储Broker的信息。</p><p>同时，Broker节点为了证明自己是存活的，会将最新的信息上报给NameServer，然后每隔30秒向NameServer发送心跳包，心跳包中包含 BrokerId、Broker地址、Broker名称、Broker所属集群名称等等，然后NameServer接收到心跳包后，会更新时间戳，记录这个Broker的最新存活时间。</p><p>NameServer在处理心跳包的时候，存在多个Broker同时操作一张Broker表，为了防止并发修改Broker表导致不安全，路由注册操作引入了ReadWriteLock读写锁，这个设计亮点允许多个消息生产者并发读，保证了消息发送时的高并发，但是同一时刻NameServer只能处理一个Broker心跳包，多个心跳包串行处理。这也是读写锁的经典使用场景，即读多写少。</p><h3 id="路由剔除"><a href="#路由剔除" class="headerlink" title="路由剔除"></a><strong>路由剔除</strong></h3><p>正常情况下，如果Broker关闭，则会与NameServer断开长连接，Netty的通道关闭监听器会监听到连接断开事件，然后会将这个Broker信息剔除掉。</p><p>异常情况下，NameServer中有一个定时任务，每隔10秒扫描一下Broker表，如果某个Broker的心跳包最新时间戳距离当前时间超多120秒，也会判定Broker失效并将其移除。</p><p>特别的，对于一些日常运维工作，例如：Broker升级，RocketMQ提供了一种优雅剔除路由信息的方式。如在升级一个Master节点之前，可以先通过命令行工具禁止这个Broker的写权限，发送消息到这个Broker的请求，都会收到一个NO_PERMISSION响应，客户端会自动重试其他的Broker。</p><p>当观察到这个broker没有流量后，再将这个broker移除。</p><h3 id="路由发现"><a href="#路由发现" class="headerlink" title="路由发现"></a><strong>路由发现</strong></h3><p>路由发现是客户端的行为，这里的客户端主要说的是生产者和消费者。具体来说：</p><ul><li>对于生产者，可以发送消息到多个Topic，因此一般是在发送第一条消息时，才会根据Topic获取从NameServer获取路由信息。</li><li>对于消费者，订阅的Topic一般是固定的，所在在启动时就会拉取。</li></ul><p>那么生产者/消费者在工作的过程中，如果路由信息发生了变化怎么处理呢？如：Broker集群新增了节点，节点宕机或者Queue的数量发生了变化。细心的读者注意到，前面讲解NameServer在路由注册或者路由剔除过程中，并不会主动推送会客户端的，这意味着，需要由客户端拉取主题的最新路由信息。</p><p>事实上，RocketMQ客户端提供了定时拉取Topic最新路由信息的机制。</p><h2 id="一致性问题"><a href="#一致性问题" class="headerlink" title="一致性问题"></a>一致性问题</h2><p>定时拉取，还不能解决所有的问题。因为客户端默认是每隔30秒会定时请求NameServer并获取最新的路由表，意味着客户端获取路由信息总是会有30秒的延时。这就带来一个严重的问题，客户端无法实时感知Broker服务器的宕机。如果生产者和消费者在这30秒内，依然会向这个宕机的broker发送或消费消息呢？</p><h1 id="生产者重试机制"><a href="#生产者重试机制" class="headerlink" title="生产者重试机制"></a><strong>生产者重试机制</strong></h1><h2 id="普通消息的重试"><a href="#普通消息的重试" class="headerlink" title="普通消息的重试"></a><strong>普通消息的重试</strong></h2><p>对于普通消息，消息发送默认采用round-robin机制来选择发送到哪一个队列，如果发送失败，默认重试2次。由于之前发送失败的Queue必然位于某个Broker上，在重试过程中，这个失败的Broker上的Queue都不会选择，这里主要是考虑，既然发送到这个Broker上某个Queue失败了，那么发送到这个Broker上的Queue失败的可能性依然很大，所以选择其他Broker。</p><p>但是一定会这样吗？例如Broker集群只是由一组Master/Slave组成，发送消息只会选择Master，如果这个Master失败了，没有其他Master可选，此时依然会选择这个Master上的其他Queue。</p><p>在实际生产环境中，通常Broker集群至少由2组Master/Slave组成，甚至更多，例如我司就是3主3从。这样就可以很好的利用RocketMQ对于普通消息发送的重试机制，每次重试到不同的Broker上。</p><p>事情到这里并没有结束，这段代码只是单次发送消息失败重试选择队列的逻辑。实际情况可能是，在Broker宕机期间，可能会发送多条消息，那么每次都可能会选择到失败的Broker上的Queue，然后再重试，尽管重试可能会成功，但是每次发送消息的耗时会增加。因此，MQFaultStrategy实际上还提供了以下两个功能(超出本文范畴，将会后续其他文章中讲解)：</p><ul><li>失败隔离：即发送消息到某个broker失败之后，将其进行隔离，优先从其他正常的broker中进行选择</li><li>延迟隔离：优先发送消息到延迟比较小的broker</li></ul><p>对于无序消息，通过这种异常重试机制，就可以保证消息发送的高可用了。同时由于不需要NameServer通知众多不固定的生产者，也降低了NameServer实现的复杂性。</p><p><strong>既然重试机制有这么明显的好处，那么对于普通有序消息，和严格有序消息，rocketmq为什么默认不进行重试呢？</strong></p><p>答案很简单，这些消息只能发送某个特定的Broker上的某个特定的Queue中，如果发送失败，重试失败的可能依然很大，所以默认不进行重试。如果需要重试，需要业务方自己来做。</p><h2 id="普通有序消息失败情况下的短暂无序"><a href="#普通有序消息失败情况下的短暂无序" class="headerlink" title="普通有序消息失败情况下的短暂无序"></a><strong>普通有序消息失败情况下的短暂无序</strong></h2><p>首先说明，对于普通有序消息，RocketMQ是不会进行重试的。如果需要重试，那么业务RD同学需要自己编写重试代码，例如通过一个for循环，最多重试几次。<strong>但是业务自己的重试是有问题的，即会破坏消息的有序性。</strong></p><p>这里主要说明：对于普通有序消息，在异常情况下，如何经历短暂无序之后再恢复有序。</p><p><strong>异常情况下的短暂无序</strong></p><p>在异常情况下，例如一个Broker宕机，路由信息刷新后，这个Broker上队列就会从List集合中移除。此时按照相同的方式选择队列，就会选择到其他队列上，造成了无序。但是这个无序是很短暂的，因为之后同一个用户的信息，都会发送到同一个新的队列上。</p><p>如果宕机的broker恢复了，那么再次经历一下短暂无序，之后又变得有序了。</p><h2 id="严格有序消息的重试"><a href="#严格有序消息的重试" class="headerlink" title="严格有序消息的重试"></a><strong>严格有序消息的重试</strong></h2><p>对于严格有序消息，由于直接指定了一个MessageQueue。如果这个MessageQueue所在的Broker宕机了，那么之后的重试必然都失败，只有无限重试，直到成功。因此，非必要的情况下，是不建议使用严格有序消息的。</p><h1 id="客户端NameServer选择策略"><a href="#客户端NameServer选择策略" class="headerlink" title="客户端NameServer选择策略"></a><strong>客户端NameServer选择策略</strong></h1><p>前面讲解了客户端在获取路由信息时，每次都会尝试先从缓存的路由表中查找Topic路由信息，如果找不到，那么就去NameServer更新尝试。</p><p>具体选择哪个NameServer，也是使用round-robin的策略。需要注意的是，尽管使用round-robin策略，但是在选择了一个NameServer节点之后，后面总是会优先选择这个NameServer，除非与这个NameServer节点通信出现异常的情况下，才会选择其他节点。</p><p>为什么客户端不与所有NameServer节点建立连接呢，而是只选择其中一个？可能是，通常NameServer节点是固定的几个，但是客户端的数量可能是成百上千，为了减少每个NameServer节点的压力，所以每个客户端节点只随机与其中一个NameServer节点建立连接。</p><p>为了尽可能保证NameServer集群每个节点的负载均衡，在round-robin策略选择时，每个客户端的初始随机位置都不同。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">private final AtomicInteger namesrvIndex = new AtomicInteger(initValueIndex());</span><br></pre></td></tr></table></figure><p>其中initValueIndex()就是计算一个随机值，之后每次选择NameServer时，namesrvIndex+1之后，对namesrvAddrList取模，计算在数据下标的位置，尝试创建连接，一旦创建成功，会将当前选择的NameServer地址记录到namesrvAddrChoosed字段中：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">private final AtomicReference&lt;String&gt; namesrvAddrChoosed = new AtomicReference&lt;String&gt;();</span><br></pre></td></tr></table></figure><p>如果某个NameServer节点创建连接失败是，会自动重试其他节点。具体可参见：getAndCreateNameserverChannel 。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;NameServer的作用&quot;&gt;&lt;a href=&quot;#NameServer的作用&quot; class=&quot;headerlink&quot; title=&quot;NameServer的作用&quot;&gt;&lt;/a&gt;&lt;strong&gt;NameServer的作用&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;&lt;img src=
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="消息队列" scheme="https://arvenseyz.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>ES聚合搜索</title>
    <link href="https://arvenseyz.github.io/2021/12/01/12-1%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>https://arvenseyz.github.io/2021/12/01/12-1技术笔记/</id>
    <published>2021-12-01T07:17:13.000Z</published>
    <updated>2021-12-01T08:09:07.725Z</updated>
    
    <content type="html"><![CDATA[<h2 id="指标和桶"><a href="#指标和桶" class="headerlink" title="指标和桶"></a>指标和桶</h2><p>es的聚合操作是aggs，是aggregations的简写。</p><p>聚合简单分为两部分，指标和桶。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">COUNT</span>(color) </span><br><span class="line"><span class="keyword">FROM</span> <span class="keyword">table</span> </span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> color</span><br></pre></td></tr></table></figure><p>group by color相当于桶。</p><p><em>桶</em>  简单来说就是满足特定条件的文档的集合：</p><ul><li>一个雇员属于  <em>男性</em>  桶或者  <em>女性</em>  桶</li><li>奥尔巴尼属于  <em>纽约</em>  桶</li><li>日期2014-10-28属于  <em>十月</em>  桶</li></ul><p>COUNT(color)相当于指标</p><p>大多数 <em>指标</em> 是简单的数学运算（例如最小值、平均值、最大值，还有汇总）</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">GET /cars/transactions/_search</span><br><span class="line">&#123;</span><br><span class="line">   <span class="attr">"size"</span> : <span class="number">0</span>,</span><br><span class="line">   <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">      <span class="attr">"colors"</span>: &#123;</span><br><span class="line">         <span class="attr">"terms"</span>: &#123;</span><br><span class="line">            <span class="attr">"field"</span>: <span class="string">"color"</span></span><br><span class="line">         &#125;,</span><br><span class="line">         <span class="attr">"aggs"</span>: &#123; </span><br><span class="line">            <span class="attr">"avg_price"</span>: &#123; </span><br><span class="line">               <span class="attr">"avg"</span>: &#123;</span><br><span class="line">                  <span class="attr">"field"</span>: <span class="string">"price"</span> </span><br><span class="line">               &#125;</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">...</span><br><span class="line">   "aggregations": &#123;</span><br><span class="line">      "colors": &#123;</span><br><span class="line">         "buckets": [</span><br><span class="line">            &#123;</span><br><span class="line">               <span class="attr">"key"</span>: <span class="string">"red"</span>,</span><br><span class="line">               <span class="attr">"doc_count"</span>: <span class="number">4</span>,</span><br><span class="line">               <span class="attr">"avg_price"</span>: &#123; </span><br><span class="line">                  <span class="attr">"value"</span>: <span class="number">32500</span></span><br><span class="line">               &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">               <span class="attr">"key"</span>: <span class="string">"blue"</span>,</span><br><span class="line">               <span class="attr">"doc_count"</span>: <span class="number">2</span>,</span><br><span class="line">               <span class="attr">"avg_price"</span>: &#123;</span><br><span class="line">                  <span class="attr">"value"</span>: <span class="number">20000</span></span><br><span class="line">               &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">               <span class="attr">"key"</span>: <span class="string">"green"</span>,</span><br><span class="line">               <span class="attr">"doc_count"</span>: <span class="number">2</span>,</span><br><span class="line">               <span class="attr">"avg_price"</span>: &#123;</span><br><span class="line">                  <span class="attr">"value"</span>: <span class="number">21000</span></span><br><span class="line">               &#125;</span><br><span class="line">            &#125;</span><br><span class="line">         ]</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>第一个aggs里的term，就是指定桶，即按color分桶。</p><p>第二个aggs就是指标了，avg是聚合函数。</p><h2 id="过滤"><a href="#过滤" class="headerlink" title="过滤"></a>过滤</h2><p>过滤有两种，聚合前过滤和聚合后过滤，即对应sql里的where和having</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">GET /cars/transactions/_search</span><br><span class="line">&#123;</span><br><span class="line">   <span class="attr">"size"</span> : <span class="number">0</span>,</span><br><span class="line">   <span class="attr">"query"</span>:&#123;</span><br><span class="line">      <span class="attr">"match"</span>: &#123;</span><br><span class="line">         <span class="attr">"make"</span>: <span class="string">"ford"</span></span><br><span class="line">      &#125;</span><br><span class="line">   &#125;,</span><br><span class="line">   <span class="attr">"aggs"</span>:&#123;</span><br><span class="line">      <span class="attr">"recent_sales"</span>: &#123;</span><br><span class="line">         <span class="attr">"filter"</span>: &#123; </span><br><span class="line">            <span class="attr">"range"</span>: &#123;</span><br><span class="line">               <span class="attr">"sold"</span>: &#123;</span><br><span class="line">                  <span class="attr">"from"</span>: <span class="string">"now-1M"</span></span><br><span class="line">               &#125;</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;,</span><br><span class="line">         <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">            <span class="attr">"average_price"</span>:&#123;</span><br><span class="line">               <span class="attr">"avg"</span>: &#123;</span><br><span class="line">                  <span class="attr">"field"</span>: <span class="string">"price"</span> </span><br><span class="line">               &#125;</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>即只有时间在现在到一个月前的数据会被聚合。</p><p>实际上过滤器可以直接写在query里，似乎性能更好。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">GET /cars/transactions/_search</span><br><span class="line">&#123;</span><br><span class="line">    <span class="attr">"size"</span> : <span class="number">0</span>,</span><br><span class="line">    <span class="attr">"query"</span>: &#123;</span><br><span class="line">        <span class="attr">"match"</span>: &#123;</span><br><span class="line">            <span class="attr">"make"</span>: <span class="string">"ford"</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"post_filter"</span>: &#123;    </span><br><span class="line">        <span class="attr">"term"</span> : &#123;</span><br><span class="line">            <span class="attr">"color"</span> : <span class="string">"green"</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"aggs"</span> : &#123;</span><br><span class="line">        <span class="attr">"all_colors"</span>: &#123;</span><br><span class="line">            <span class="attr">"terms"</span> : &#123; <span class="attr">"field"</span> : <span class="string">"color"</span> &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>即只看green的</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;指标和桶&quot;&gt;&lt;a href=&quot;#指标和桶&quot; class=&quot;headerlink&quot; title=&quot;指标和桶&quot;&gt;&lt;/a&gt;指标和桶&lt;/h2&gt;&lt;p&gt;es的聚合操作是aggs，是aggregations的简写。&lt;/p&gt;
&lt;p&gt;聚合简单分为两部分，指标和桶。&lt;/p&gt;
&lt;fig
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="ES" scheme="https://arvenseyz.github.io/tags/ES/"/>
    
  </entry>
  
  <entry>
    <title>执行计划的extra</title>
    <link href="https://arvenseyz.github.io/2021/11/30/11-30%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>https://arvenseyz.github.io/2021/11/30/11-30技术笔记-1/</id>
    <published>2021-11-30T07:57:33.000Z</published>
    <updated>2021-12-01T07:17:21.217Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Using-fileSort"><a href="#Using-fileSort" class="headerlink" title="Using fileSort"></a>Using fileSort</h2><p>使用文件排序，是指拿到这些行后再排序，具体在哪排，内存还是磁盘，取决于大小，所有列还是排序列+id再回表取决于代价</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> t1 <span class="keyword">order</span> <span class="keyword">by</span> create_time</span><br></pre></td></tr></table></figure><h2 id="Using-temporary"><a href="#Using-temporary" class="headerlink" title="Using temporary"></a>Using temporary</h2><p>需要临时表来储存结构，比如对没有索引的列来group by</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> t1 <span class="keyword">group</span> <span class="keyword">by</span> create_time</span><br></pre></td></tr></table></figure><h2 id="Using-index"><a href="#Using-index" class="headerlink" title="Using index"></a>Using index</h2><p>使用覆盖索引，即索引树上即可拿到字段，无需回表</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> a <span class="keyword">from</span> t1 <span class="keyword">where</span> a =<span class="number">11</span></span><br></pre></td></tr></table></figure><h2 id="Using-where"><a href="#Using-where" class="headerlink" title="Using where"></a>Using where</h2><p>意味着全表扫描或者在查找使用索引的情况下，但是还有查询条件不在索引字段当中.</p><p>Using where: 仅仅表示MySQL服务器在收到存储引擎返回的记录后进行“后过滤”。</p><p><strong>1： 查询条件中的相关列，不是索引字段， 全表扫描后，通过Using where过滤获取所需的数据。</strong></p><p>通俗来说，因为字段D没有索引，所以必须全表扫描，然后在服务器层使用WHERE过滤数据。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">COUNT</span>(*) <span class="keyword">FROM</span> <span class="keyword">TEST</span> <span class="keyword">WHERE</span> D = <span class="string">'2000-01-01'</span>;</span><br></pre></td></tr></table></figure><p>2： <strong>（type=ref)非唯一性索引扫描，但是由于索引未覆盖所有查询条件(字段d并未包含在聚集索引</strong>PRIMARY中**)，在存储引擎返回记录后，仍然需要过滤数据。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">COUNT</span>(i1) <span class="keyword">FROM</span> <span class="keyword">TEST</span> <span class="keyword">WHERE</span> i1 = <span class="number">3</span> <span class="keyword">AND</span> d &gt; <span class="number">321</span></span><br></pre></td></tr></table></figure><h2 id="Using-index-condition"><a href="#Using-index-condition" class="headerlink" title="Using index condition"></a>Using index condition</h2><p>索引下推。存储引擎在访问索引的时候检查筛选字段在索引中的WHERE条件</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> t1 <span class="keyword">where</span> age&gt;<span class="number">9</span> <span class="keyword">and</span> <span class="keyword">name</span> <span class="keyword">like</span> <span class="string">'%张'</span></span><br></pre></td></tr></table></figure><p>即使建立了age和name的联合索引，该查询也只会走age，但是在走age的时候，它可以把name条件带上，顺便就筛了。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Using-fileSort&quot;&gt;&lt;a href=&quot;#Using-fileSort&quot; class=&quot;headerlink&quot; title=&quot;Using fileSort&quot;&gt;&lt;/a&gt;Using fileSort&lt;/h2&gt;&lt;p&gt;使用文件排序，是指拿到这些行后再排序，具体在
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="数据库" scheme="https://arvenseyz.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>图数据库基础语法</title>
    <link href="https://arvenseyz.github.io/2021/10/25/10-25%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-2/"/>
    <id>https://arvenseyz.github.io/2021/10/25/10-25技术笔记-2/</id>
    <published>2021-10-25T10:28:27.000Z</published>
    <updated>2021-10-26T07:20:42.291Z</updated>
    
    <content type="html"><![CDATA[<h2 id="图数据库优势"><a href="#图数据库优势" class="headerlink" title="图数据库优势"></a>图数据库优势</h2><p><a href="https://imgtu.com/i/54fgPS" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/10/25/54fgPS.png" alt="54fgPS.png"></a></p><ul><li><p>关系复杂的模型用图的形式表达容易</p></li><li><p>关系查询性能可控（<strong><em>我的好友所在的公司有多少名员工？</em></strong>）</p></li></ul><h2 id="图数据库基本语法"><a href="#图数据库基本语法" class="headerlink" title="图数据库基本语法"></a>图数据库基本语法</h2><h3 id="基本定义"><a href="#基本定义" class="headerlink" title="基本定义"></a>基本定义</h3><ul><li><p>由点(Vertex)、边(Edge)、属性(Property)构成；</p></li><li><p>点(Vertex)是实体、概念对象</p></li><li><p>&lt;type(uint32_t), ID(uint64_t&gt; 二元组唯一标记一个点</p></li><li><p>type标记了一类点的集合，可以把type理解为table，不同type，是不同table</p></li><li><p>属性：点上可以有多种属性，属性可以是常见基本类型，</p></li><li><p>schema: 同一种type的点，其属性key以及属性类型必须一致</p></li><li><p>边(Edge)是点之间的关系、联系</p></li><li><p>边有起点+终点，边上类型，type（string）；和点一样，同样的type类型的边必须有同样的属性属性：和点上属性一样，支持多种基本类型</p></li></ul><h3 id="germlin语法"><a href="#germlin语法" class="headerlink" title="germlin语法"></a>germlin语法</h3><p>gremlin语言是图遍历（traverse）式语言，简单起见，可以理解为，先在图上定位到一个点，然后从这个点开始做图上的深度/宽度遍历，在图上每一步遍历用step来描述，不同的step有不同的功能，用step的组合来实现图上游走</p><h3 id="创建一个天龙八部人物图"><a href="#创建一个天龙八部人物图" class="headerlink" title="创建一个天龙八部人物图"></a>创建一个天龙八部人物图</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Gremlin: g.addV().property(&apos;id&apos;, 1001).property(&apos;type&apos;, 5).property(&apos;name&apos;, &apos;段正淳&apos;).property(&apos;power&apos;, 60).toList()</span><br><span class="line">Gremlin: g.addV().property(&apos;id&apos;, 1002).property(&apos;type&apos;, 5).property(&apos;name&apos;, &apos;段延庆&apos;).property(&apos;power&apos;, 75).toList()</span><br><span class="line">Gremlin: g.addV().property(&apos;id&apos;, 1003).property(&apos;type&apos;, 5).property(&apos;name&apos;, &apos;王语嫣&apos;).property(&apos;power&apos;, 2).toList()</span><br><span class="line">Gremlin: g.addV().property(&apos;id&apos;, 1004).property(&apos;type&apos;, 5).property(&apos;name&apos;, &apos;阿朱&apos;).property(&apos;power&apos;, 5).toList()</span><br><span class="line">Gremlin: g.addV().property(&apos;id&apos;, 1005).property(&apos;type&apos;, 5).property(&apos;name&apos;, &apos;段誉&apos;).property(&apos;power&apos;, 80).toList()</span><br><span class="line">Gremlin: g.addV().property(&apos;id&apos;, 1006).property(&apos;type&apos;, 5).property(&apos;name&apos;, &apos;叶二娘&apos;).property(&apos;power&apos;, 40).toList()</span><br><span class="line">Gremlin: g.addV().property(&apos;id&apos;, 1007).property(&apos;type&apos;, 5).property(&apos;name&apos;, &apos;乔峰&apos;).property(&apos;power&apos;, 90).toList()</span><br><span class="line">Gremlin: g.addV().property(&apos;id&apos;, 1008).property(&apos;type&apos;, 5).property(&apos;name&apos;, &apos;虚竹&apos;).property(&apos;power&apos;, 85).toList()</span><br><span class="line">Gremlin: g.addE(&apos;relatives&apos;).from(1001, 5).to(1002, 5).property(&apos;relation&apos;, &apos;兄弟&apos;).toList()</span><br><span class="line">Gremlin: g.addE(&apos;relatives&apos;).from(1001, 5).to(1003, 5).property(&apos;relation&apos;, &apos;父女&apos;).toList()</span><br><span class="line">Gremlin: g.addE(&apos;relatives&apos;).from(1001, 5).to(1004, 5).property(&apos;relation&apos;, &apos;父女&apos;).toList()</span><br><span class="line">Gremlin: g.addE(&apos;relatives&apos;).from(1002, 5).to(1005, 5).property(&apos;relation&apos;, &apos;父子&apos;).toList()</span><br><span class="line">Gremlin: g.addE(&apos;relatives&apos;).from(1002, 5).to(1006, 5).property(&apos;relation&apos;, &apos;义妹&apos;).toList()</span><br><span class="line">Gremlin: g.addE(&apos;relatives&apos;).from(1003, 5).to(1005, 5).property(&apos;relation&apos;, &apos;夫妻&apos;).toList()</span><br><span class="line">Gremlin: g.addE(&apos;relatives&apos;).from(1004, 5).to(1007, 5).property(&apos;relation&apos;, &apos;夫妻&apos;).toList()</span><br><span class="line">Gremlin: g.addE(&apos;relatives&apos;).from(1005, 5).to(1008, 5).property(&apos;relation&apos;, &apos;结拜兄弟&apos;).toList()</span><br><span class="line">Gremlin: g.addE(&apos;relatives&apos;).from(1006, 5).to(1008, 5).property(&apos;relation&apos;, &apos;母子&apos;).toList()</span><br><span class="line">Gremlin: g.addE(&apos;relatives&apos;).from(1007, 5).to(1005, 5).property(&apos;relation&apos;, &apos;结拜兄弟&apos;).toList()</span><br><span class="line">Gremlin: g.addE(&apos;relatives&apos;).from(1008, 5).to(1007, 5).property(&apos;relation&apos;, &apos;结拜兄弟&apos;).toList()</span><br></pre></td></tr></table></figure><h3 id="查询语法"><a href="#查询语法" class="headerlink" title="查询语法"></a>查询语法</h3><p>查询点类型是5，id是1005的点，以及它的属性（查询属性时，指定属性名性能更好，原因估计是下文的点切割）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">g.V(vertex(1001,5)).toList()</span><br><span class="line">Result: [Vertex&#123;Id:1001, Type:5&#125;]</span><br><span class="line">g.V(vertex(1001,5)).properties()</span><br><span class="line">Result: [Property&#123;Key:name, Value:&quot;段正淳&quot;&#125;, Property&#123;Key:power, Value:60&#125;]</span><br></pre></td></tr></table></figure><h3 id="遍历"><a href="#遍历" class="headerlink" title="遍历"></a>遍历</h3><p>如上文，操作是定位一个点，然后再图上游走</p><p><a href="https://imgtu.com/i/5If0bR" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/10/26/5If0bR.png" alt="5If0bR.png"></a></p><p>定位一个点后，找到它的出边，即段正淳的关系</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">» g.V(vertex(1001,5)).outE(&quot;relatives&quot;)</span><br><span class="line">Result: [Edge&#123;OutV:Vertex&#123;Id:1001, Type:5&#125;, InV:Vertex&#123;Id:1004, Type:5&#125;, Type:relatives&#125;, Edge&#123;OutV:Vertex&#123;Id:1001, Type:5&#125;, InV:Vertex&#123;Id:1003, Type:5&#125;, Type:relatives&#125;, Edge&#123;OutV:Vertex&#123;Id:1001, Type:5&#125;, InV:Vertex&#123;Id:1002, Type:5&#125;, Type:relatives&#125;]</span><br></pre></td></tr></table></figure><p>找到一个点某种类型过滤属性的边，即段正淳的兄弟关系</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">» g.V(vertex(1001,5)).outE(&quot;relatives&quot;).has(&apos;relation&apos;,&apos;兄弟&apos;).toList()</span><br><span class="line">Result: [Edge&#123;OutV:Vertex&#123;Id:1001, Type:5&#125;, InV:Vertex&#123;Id:1002, Type:5&#125;, Type:relatives&#125;]</span><br></pre></td></tr></table></figure><p>进一步，找到段正淳的兄弟</p><p>遍历法，找到兄弟边，再找到兄弟边链接的点</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">» g.V(vertex(1001,5)).outE(&quot;relatives&quot;).has(&apos;relation&apos;,&apos;兄弟&apos;).inV().toList()</span><br><span class="line">Result: [Vertex&#123;Id:1002, Type:5&#125;]</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;图数据库优势&quot;&gt;&lt;a href=&quot;#图数据库优势&quot; class=&quot;headerlink&quot; title=&quot;图数据库优势&quot;&gt;&lt;/a&gt;图数据库优势&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://imgtu.com/i/54fgPS&quot; target=&quot;_blank&quot; r
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="图数据库" scheme="https://arvenseyz.github.io/tags/%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>redis的redlock锁</title>
    <link href="https://arvenseyz.github.io/2021/10/11/10-11%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>https://arvenseyz.github.io/2021/10/11/10-11技术笔记-1/</id>
    <published>2021-10-11T08:49:43.000Z</published>
    <updated>2021-10-25T10:30:15.259Z</updated>
    
    <content type="html"><![CDATA[<ul><li><h3 id="加锁"><a href="#加锁" class="headerlink" title="加锁"></a>加锁</h3></li></ul><p>官方推荐至少 5 个redis实例，而且都是主库，它们之间没有任何关系，都是一个个孤立的实例，流程如下：</p><ol><li>客户端先获取「当前时间戳T1」。</li><li>客户端依次向这 5 个 Redis 实例发起加锁请求（SET命令），且每个请求会设置超时时间（毫秒级，要远小于锁的有效时间），如果某一个实例加锁失败（包括网络超时、锁被其它人持有等各种异常情况），就立即向下一个 Redis 实例申请加锁。</li><li>如果客户端从 3 个（大多数）以上 Redis 实例加锁成功，则再次获取「当前时间戳T2」，如果 T2 - T1 &lt; 锁的过期时间，此时，认为客户端加锁成功，否则认为加锁失败。</li><li>加锁成功，去操作共享资源（例如修改 MySQL 某一行，或发起一个 API 请求）。</li><li>加锁失败，向全部节点发起释放锁请求。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;&lt;h3 id=&quot;加锁&quot;&gt;&lt;a href=&quot;#加锁&quot; class=&quot;headerlink&quot; title=&quot;加锁&quot;&gt;&lt;/a&gt;加锁&lt;/h3&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;官方推荐至少 5 个redis实例，而且都是主库，它们之间没有任何关系，都是一个个孤立的实例，流程
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="redis" scheme="https://arvenseyz.github.io/tags/redis/"/>
    
      <category term="分布式" scheme="https://arvenseyz.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>redis分布式锁</title>
    <link href="https://arvenseyz.github.io/2021/10/09/10-9%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>https://arvenseyz.github.io/2021/10/09/10-9技术笔记-1/</id>
    <published>2021-10-09T06:52:04.000Z</published>
    <updated>2021-10-11T08:50:16.995Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Redis是AP系统"><a href="#Redis是AP系统" class="headerlink" title="Redis是AP系统"></a>Redis是AP系统</h2><p>先抛个结论：</p><p>“redis多机房同步是最终一致的，如有分布式锁的需求，会有锁不上的情况，业务可根据文档考虑使用强一致的存储组件！” from redis 用户文档</p><p>因此redis锁只能作为弱校验，而不能作为强依赖，必须要其他强一致的系统保证其一致性。</p><h2 id="Redis锁实现原理"><a href="#Redis锁实现原理" class="headerlink" title="Redis锁实现原理"></a>Redis锁实现原理</h2><p>而redis锁锁不住的原因要从redis锁的实现讲起。redis锁主要基于两个命令，<strong>setnx &amp;</strong> <strong>cad</strong>，（注意不是redlock，redlock和这两个命令没有关系，下面最后一个部分会提）</p><p><strong>加锁setnx</strong></p><p>setnx命令会被redis client解析为</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SET key value NX PX 30000</span><br></pre></td></tr></table></figure><ul><li>其中key通常为我们想锁住的<code>key</code>，而<code>value</code>应当为一个随机数，原因在解锁的部分讲</li><li><code>NX</code>代表只有key为空时才会set成功</li><li><code>PX 30000</code> 指过期时间30s</li></ul><p><strong>解锁</strong>  <strong>cad</strong> <strong>（已被公司级别支持）</strong></p><p>cad指<code>compare and delete</code>操作，该操作其实内部执行Redis lua脚本保证cad操作的中不会被其他操作穿插</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">if redis.call(&quot;get&quot;,KEYS[1]) == ARGV[1] then </span><br><span class="line">  return redis.call(&quot;del&quot;,KEYS[1])</span><br><span class="line">else </span><br><span class="line">  return 0 </span><br><span class="line">end</span><br></pre></td></tr></table></figure><ul><li>为什么锁还需要设置随机<code>value</code>去compare？因为虽然redis数据库单线程，但是客户端却可能为多线程，试想以下逻辑：</li></ul><p><a href="https://imgtu.com/i/5FANLj" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/10/09/5FANLj.png" alt="5FANLj.png"></a></p><p>若发生以上时序，client1由于处理请求时被阻塞，导致client2获取的锁会被client1解锁，进而导致锁失效。特别是我们应用代码中通常设置的时长较短（1s - 5s），更增加以上情况出现的几率。</p><ul><li>i/o timeout如何做？</li></ul><p>有些人会觉得奇怪为什么上面的这段代码没有做错误校验，正确的做法是不是应该是这样？</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">err := redis.SetNX(key, value, duration)</span><br><span class="line">if err != nil &#123;</span><br><span class="line">    return </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其实不然，试想<code>SetNX</code> 发生timeout，但其实Redis客户端<strong>收到</strong>该请求，只是respond<strong>回复超时</strong>，该锁会一直被持有直到timeout。</p><p>比较正确的逻辑为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">err := redis.SetNX(key, randomNum, duration)</span><br><span class="line">defer redis.CAD(key, randomNum)</span><br><span class="line">if err != nil &#123;</span><br><span class="line">    return </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>由randomNum来保证key有且仅会被本客户端线程解锁，即使失败，也不会把其他客户端线程的锁unlock（因为randomNum不一致，compare阶段错误）。该逻辑更体现了设置randomNum为value的必要性。这个随机数应当可以保证在一段时间内只被同一client持有，比较偷懒的方法是使用server id + unix microsecond时间戳，在大部分场景下应该足够了。</p><ul><li>Expire time如何定？</li></ul><p>其实这也是个两难问题，若超时时间过短，则锁不住整个流程处理时间，可能被抢锁；若超时时间过长，则解锁操作<code>redis.CAD(key, randomNum)</code>失败时，会导致key被锁住过长时间。因此需根据实际业务场景而定。</p><h2 id="分布式redis情况如何？"><a href="#分布式redis情况如何？" class="headerlink" title="分布式redis情况如何？"></a>分布式redis情况如何？</h2><p>即使我们在实现上都按照完美的路径，以上实现也是基于单机情况，在分布式场景下，由于redis多机房同步是最终一致的，当主节点不可用时，系统自动切换到副节点（即failover的过程），由于主从非同步，在failover的过程中会导致锁被抢。试想以下时序：</p><ol><li>master拿到锁a</li><li>slave1-master同步开启</li><li>master宕机，failover开始</li><li>slave1-master同步未完成</li><li>slave1被选举为master，锁a丢失，可被抢</li></ol><p>虽然很多人觉得failover的情况很少，以上可以忽略，实际上根据我们现在的使用方法，某个历史活动的并发情况而言，已经出现大量的并发锁被抢引起的错误（日均300+，from QPS大概400左右的并发请求）。</p><h2 id="正确姿势如何做？"><a href="#正确姿势如何做？" class="headerlink" title="正确姿势如何做？"></a>正确姿势如何做？</h2><p>redis针对单机redis锁的问题，提出了redlock的解决方案，但是redlock也有些争议，同时其不太适合公司的redis架构，在这里不多做讨论。</p><p>如果要了解正确的锁姿势，首先要分析分布式锁的场景，一般来说，可以分为两种，为了效率加锁，和为了正确性加锁。</p><ul><li>为效率加锁，即为了一些计算的重复；即使失败，也只是把某些操作多做一遍，例如条件多校验一遍</li><li>为了正确性加锁，即不允许分布式锁失败；若失败可能产生不可回滚的脏数据</li></ul><p>若为了效率加锁，使用单机的redis锁已经足够，单重要的是清楚单机redis锁在分布式场景下的限制。</p><p>若为了正确性加锁，一定要使用强一致性保障（bytekv，zookeeper）等，基架推荐尝试bytekv。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Redis是AP系统&quot;&gt;&lt;a href=&quot;#Redis是AP系统&quot; class=&quot;headerlink&quot; title=&quot;Redis是AP系统&quot;&gt;&lt;/a&gt;Redis是AP系统&lt;/h2&gt;&lt;p&gt;先抛个结论：&lt;/p&gt;
&lt;p&gt;“redis多机房同步是最终一致的，如有分布式锁
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="redis" scheme="https://arvenseyz.github.io/tags/redis/"/>
    
      <category term="分布式" scheme="https://arvenseyz.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>es打分方式</title>
    <link href="https://arvenseyz.github.io/2021/09/27/9-27%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-3/"/>
    <id>https://arvenseyz.github.io/2021/09/27/9-27技术笔记-3/</id>
    <published>2021-09-27T09:19:34.000Z</published>
    <updated>2021-09-27T09:28:45.295Z</updated>
    
    <content type="html"><![CDATA[<h2 id="计算公式"><a href="#计算公式" class="headerlink" title="计算公式"></a>计算公式</h2><p><code>Lucene</code>和<code>es</code>的打分机制是一个公式。将查询作为输入，使用不同的手段来确定每一篇文档的得分，将每一个因素最后通过公式综合起来，返回该文档的最终得分。这个综合考量的过程，就是我们希望相关的文档被优先返回的考量过程。在<code>Lucene</code>和<code>es</code>中这种相关性称为得分。<br>在开始计算得分之前，<code>es</code>使用了被搜索词条的频率和它有多常见来影响得分，从两个方面理解：</p><ul><li>一个词条在某篇文档中出现的次数越多，该文档就越相关。</li><li>一个词条如果在不同的文档中出现的次数越多，它就越不相关！</li></ul><p>我们称之为<code>TF-IDF</code>，<code>TF</code>是词频（term frequency），而<code>IDF</code>是逆文档频率（inverse document frequency）。</p><p>此外还有两个因素</p><ul><li><p><strong>Document Frequency(DF)文档频率</strong>：即单词出现的文档数。</p></li><li><p><strong>Field-length Norm</strong>：文档越短，相关性越高，field长度，field越长，相关度越弱</p></li></ul><p>逆文档词频是一个重要的因素，用来平衡词条的词频。比如我们搜索<code>the 996.ICU</code>。单词<code>the</code>几乎出现在所有的文档中（中文中比如<code>的</code>），如果这个鬼东西要不被均衡一下，那么<code>the</code>的频率将完全淹没<code>996.ICU</code>。所以，逆文档词频就有效的均衡了<code>the</code>这个常见词的相关性影响。以达到实际的相关性得分将会对查询的词条有一个更准确地描述。<br>当词频和逆文档词频计算完成。就可以使用<code>TF-IDF</code>公式来计算文档的得分了</p><p>我们通过<code>explain=true</code>，es会返回如何打分的</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">GET py1/doc/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"match"</span>: &#123;</span><br><span class="line">      <span class="attr">"title"</span>: <span class="string">"北京"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"explain"</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="attr">"_source"</span>: <span class="string">"title"</span>, </span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>会返回一个复杂的公式。</p><h2 id="手动控制"><a href="#手动控制" class="headerlink" title="手动控制"></a>手动控制</h2><p>通过boosting可以人为控制某个字段的在评分过程中的比重，有两种类型：</p><ul><li><p>索引期间的boosting</p></li><li><p>查询期间的boosting</p></li></ul><p>通过在mapping中设置boost参数，可以在索引期间改变字段的评分权重：</p><p>一旦映射建立完成，那么所有name字段都会自动拥有一个boost值，并且是以降低精度的数值存储在Lucene内部的索引结构中。只有一个字节用于存储浮点型数值（存不下就损失精度了），计算文档的最终得分时可能会损失精度。</p><p>另外，boost是应用与词条的。因此，再被boost的字段中如果匹配上了多个词条，就意味着计算多次的boost，这将会进一步增加字段的权重，可能会影响最终的文档得分。</p><p>查询期间的boosting可以避免上述问题。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;计算公式&quot;&gt;&lt;a href=&quot;#计算公式&quot; class=&quot;headerlink&quot; title=&quot;计算公式&quot;&gt;&lt;/a&gt;计算公式&lt;/h2&gt;&lt;p&gt;&lt;code&gt;Lucene&lt;/code&gt;和&lt;code&gt;es&lt;/code&gt;的打分机制是一个公式。将查询作为输入，使用不同的手段来
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="ES" scheme="https://arvenseyz.github.io/tags/ES/"/>
    
  </entry>
  
  <entry>
    <title>ES段和段合并</title>
    <link href="https://arvenseyz.github.io/2021/09/24/9-24%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>https://arvenseyz.github.io/2021/09/24/9-24技术笔记-1/</id>
    <published>2021-09-24T06:56:04.000Z</published>
    <updated>2021-09-24T07:11:44.965Z</updated>
    
    <content type="html"><![CDATA[<h1 id="segment"><a href="#segment" class="headerlink" title="segment"></a>segment</h1><p>lucene内部的数据是由⼀个个segment组成的，写⼊lucene的数据并不直接落盘，⽽是先写在内存中，经过了refresh间隔，lucene才将该时间段写⼊的全部数据refresh成⼀个segment，segment多了之后会进⾏merge成更⼤的segment。</p><p>lucene查询时会遍历每个segment完成。由于lucene写⼊的数据是在内存中完成，所以写⼊效率⾮常⾼。但是也存在丢失数据的⻛险，所以Elasticsearch基于此现象实现了translog，只有在segment数据落盘后，Elasticsearch才会删除对应的translog。</p><ul><li><p>每个分片都是一个 Lucene 索引实例，您可以将其视作一个独立的搜索引擎，它能够对 Elasticsearch 集群中的数据子集进行索引并处理相关查询；</p></li><li><p>每个分片包含多个segment（段），每一个segment都是一个倒排索引。</p></li></ul><p>在查询的时，会把所有的segment查询结果汇总归并为最终的分片查询结果返回。</p><p>在 lucene 中，为了实现高索引速度，故使用了segment 分段架构存储。</p><p>一批写入数据保存在一个段中，其中每个段是磁盘中的单个文件。</p><p>由于两次写入之间的文件操作非常繁重，因此将一个段设为不可变的，以便所有后续写入都转到New段。</p><p>由于自动刷新流程每秒会创建一个新的段（由动态配置参数：refresh_interval 决定），这样会导致短时间内的段数量暴增。</p><p>而段数目太多会带来较大的麻烦。</p><ul><li><p>消耗资源：每一个段都会消耗文件句柄、内存和cpu运行周期；</p></li><li><p>搜索变慢：每个搜索请求都必须轮流检查每个段；所以段越多，搜索也就越慢。</p></li></ul><p>Elasticsearch 通过在后台进行段合并来解决这个问题。</p><p>小的段被合并到大的段，然后这些大的段再被合并到更大的段。</p><h1 id="段合并"><a href="#段合并" class="headerlink" title="段合并"></a>段合并</h1><p>段合并的时候会将那些旧的已删除文档从文件系统中清除。</p><p>被删除的文档（或被更新文档的旧版本）不会被拷贝到新的大段中。</p><p>启动段合并不需要你做任何事。进行索引和搜索时会自动进行。</p><p>合并大的段需要消耗大量的I/O和CPU资源，如果任其发展会影响搜索性能。Elasticsearch在默认情况下会对合并流程进行资源限制，所以搜索仍然 有足够的资源很好地执行。</p><ul><li><p>当索引的时候，刷新（refresh）操作会创建新的段并将段打开以供搜索使用。</p></li><li><p>合并进程选择一小部分大小相似的段，并且在后台将它们合并到更大的段中。这并不会中断索引和搜索。</p></li></ul><p>代价呢</p><ul><li><p>磁盘IO操作的代价；</p></li><li><p>速度慢的系统中，段合并会显著影响性能。</p></li></ul><h1 id="手动段合并"><a href="#手动段合并" class="headerlink" title="手动段合并"></a>手动段合并</h1><p><code>optimize</code> API大可看做是 <em>强制合并</em> API。它会将一个分片强制合并到 <code>max_num_segments</code> 参数指定大小的段数目。 这样做的意图是减少段的数量（通常减少到一个），来提升搜索性能。</p><p>在特定情况下，使用  <code>optimize</code>  API 颇有益处。例如在日志这种用例下，每天、每周、每月的日志被存储在一个索引中。 老的索引实质上是只读的；它们也并不太可能会发生变化。</p><p>在这种情况下，使用optimize优化老的索引，将每一个分片合并为一个单独的段就很有用了；这样既可以节省资源，也可以使搜索更加快速</p><h1 id="迁移索引"><a href="#迁移索引" class="headerlink" title="迁移索引"></a>迁移索引</h1><p>使用 <code>optimize</code> API 触发段合并的操作不会受到任何资源上的限制。这可能会消耗掉你节点上全部的I/O资源, 使其没有余裕来处理搜索请求，从而有可能使集群失去响应。 如果你想要对索引执行 <code>optimize</code>，你需要先使用分片分配（查看 <a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/retiring-data.html#migrate-indices" title="迁移旧索引" target="_blank" rel="noopener">迁移旧索引</a>）把索引移到一个安全的节点，再执行。</p><p>随着数据被记录，很有可能存在一个  <em>热点</em>  索引——今日的索引。 所有新文档都会被加到那个索引，几乎所有查询都以它为目标。那个索引应当使用你最好的硬件。</p><p>Elasticsearch 是如何得知哪台是你最好的服务器呢？你可以通过给每台服务器指定任意的标签来告诉它。 例如，你可以像这样启动一个节点：</p><p>./bin/elasticsearch –node.box_type strong</p><p><code>box_type</code>  参数是完全随意的——你可以将它随意命名只要你喜欢——但你可以用这些任意的值来告诉 Elasticsearch 将一个索引分配至何处。</p><p>我们可以通过按以下配置创建今日的索引来确保它被分配到我们最好的服务器上：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PUT /logs_2014-10-01 &#123; &quot;settings&quot;: &#123; &quot;index.routing.allocation.include.box_type&quot; : &quot;strong&quot; &#125; &#125;</span><br></pre></td></tr></table></figure><p>昨日的索引不再需要我们最好的服务器了，我们可以通过更新索引设置将它移动到标记为  <code>medium</code>  的节点上：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">POST /logs_2014-09-30/_settings &#123; &quot;index.routing.allocation.include.box_type&quot; : &quot;medium&quot; &#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;segment&quot;&gt;&lt;a href=&quot;#segment&quot; class=&quot;headerlink&quot; title=&quot;segment&quot;&gt;&lt;/a&gt;segment&lt;/h1&gt;&lt;p&gt;lucene内部的数据是由⼀个个segment组成的，写⼊lucene的数据并不直接落盘，⽽是先写在
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="ES" scheme="https://arvenseyz.github.io/tags/ES/"/>
    
  </entry>
  
  <entry>
    <title>Roaring BitMap</title>
    <link href="https://arvenseyz.github.io/2021/09/23/9-23%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>https://arvenseyz.github.io/2021/09/23/9-23技术笔记/</id>
    <published>2021-09-23T06:20:29.000Z</published>
    <updated>2021-09-23T06:31:56.593Z</updated>
    
    <content type="html"><![CDATA[<p>ES会缓存频率比较高的filter查询，其中的原理也比较简单，即生成<code>(fitler, segment)</code>和id列表的映射，但是和倒排索引不同，我们只把常用的filter缓存下来而倒排索引是保存所有的，并且filter缓存应该足够快，不然直接查询不就可以了。ES直接把缓存的filter放到内存里面，映射的posting list放入磁盘中。</p><p>RBM的主要思路是：将32位无符号整数按照高16位分桶，即最多可能有216=65536个桶，论文内称为container。存储数据时，按照数据的高16位找到container（找不到就会新建一个），再将低16位放入container中。也就是说，一个RBM就是很多container的集合。</p><p>如下所示。</p><p><img src="https://bytedance.feishu.cn/space/api/box/stream/download/asynccode/?code=YmY1YzA1NDRiOTFmZDFiYjZiMWE2NmZiZGI3ZDlmM2VfMW9qbVFITERKZnB4eEFIcU5rSFZpS1RWUktwRW9CUVpfVG9rZW46Ym94Y24zYUswQXJqTEtNUXdYT1FmM2JqVTFlXzE2MzIzNzg2OTQ6MTYzMjM4MjI5NF9WNA" alt></p><p>图中示出了三个container：</p><ul><li><p>高16位为0000H的container，存储有前1000个62的倍数。</p></li><li><p>高16位为0001H的container，存储有[216, 216+100)区间内的100个数。</p></li><li><p>高16位为0002H的container，存储有[2×216, 3×216)区间内的所有偶数，共215个。</p></li></ul><p><strong>ArrayContainer</strong></p><p>当桶内数据的基数不大于4096时，会采用它来存储，其本质上是一个unsigned short类型的有序数组。数组初始长度为4，随着数据的增多会自动扩容（但最大长度就是4096）。另外还维护有一个计数器，用来实时记录基数。</p><p>上图中的前两个container基数都没超过4096，所以均为ArrayContainer。</p><p><strong>BitmapContainer</strong></p><p>当桶内数据的基数大于4096时，会采用它来存储，其本质就是上一节讲过的普通位图，用长度固定为1024的unsigned long型数组表示，亦即位图的大小固定为216位（8KB）。它同样有一个计数器。</p><p>上图中的第三个container基数远远大于4096，所以要用BitmapContainer存储。</p><p><strong>RunContainer</strong></p><p>RunContainer在图中并未示出，初始的RBM实现中也没有它，而是在本节开头的第二篇论文中新加入的。它使用可变长度的unsigned short数组存储用行程长度编码（RLE）压缩后的数据。举个例子，连续的整数序列<code>11, 12, 13, 14, 15, 27, 28, 29</code>会被RLE压缩为两个二元组<code>11, 4, 27, 2</code>，表示11后面紧跟着4个连续递增的值，27后面跟着2个连续递增的值。</p><p>由此可见，RunContainer的压缩效果可好可坏。考虑极端情况：如果所有数据都是连续的，那么最终只需要4字节；如果所有数据都不连续（比如全是奇数或全是偶数），那么不仅不会压缩，还会膨胀成原来的两倍大。所以，RBM引入RunContainer是作为其他两种container的折衷方案。</p><p><strong>shared_container</strong></p><p>这种容器它本身是不存储数据的，只是用它来指向arraycontainer,bitmapcontainer或runcontainer,就好比指针的作用一样，这个指针可以被多个对象拥有，但是指针所指针的实质东西是被这多个对象所共享的。在我们进行roaringbitmap之间的拷贝的时候，有时并不需要将一个container拷贝多份，那么我们就可以使用sharedcontainer来指向实际的container，然后把sharedcontainer赋给多个roaringbitmap对象持有，这个roaringbitmap对象就可以根据sharedcontainer找到真正存储数据的container,这可以省去不必要的空间浪费。</p><p><img src="https://bytedance.feishu.cn/space/api/box/stream/download/asynccode/?code=YTJmYzJlNTUwZTQ3YWY0NDI3YzY0ZTViMmVlOTYxNTRfQm1oMUhOMlJFeGFSSkFxOE9CUG5OV3BybDhKYzk1dnJfVG9rZW46Ym94Y244NWJCNGd2dGpwNWc1ZG9hMk82NlhlXzE2MzIzNzg2OTQ6MTYzMjM4MjI5NF9WNA" alt></p><p>roaringbitmap除了比bitmap占用内存少之外，其并集和交集操作的速度也要比bitmap的快。原因归结为以下几点：</p><ol><li>计算上的优化</li></ol><p>对于roaringbitmap本质上是将大块的bitmap分成各个小块，其中每个小块在需要存储数据的时候才会存在。所以当进行交集或并集运算的时候，roaringbitmap只需要去计算存在的一些块而不需要像bitmap那样对整个大的块进行计算。如果块内非常稀疏，那么只需要对这些小整数列表进行集合的 AND、OR 运算，这样的话计算量还能继续减轻。这里既不是用空间换时间，也没有用时间换空间，而是用逻辑的复杂度同时换取了空间和时间。</p><p>同时在roaringbitmap中32位长的数据，被分割成高 16 位和低 16 位，高 16 位表示块偏移，低16位表示块内位置，单个块可以表达 64k 的位长，也就是 8K 字节。这样可以保证单个块都可以全部放入 L1 Cache，可以显著提升性能。</p><ol start="2"><li>程序逻辑上的优化</li></ol><p>（1）roaringbitmap维护了排好序的一级索引，以及有序的arraycontainer当进行交集操作的时候，只需要根据一级索引中对应的值来获取需要合并的容器，而不需要合并的容器则不需要对其进行操作直接过滤掉。</p><p>（2）当进行合并的arraycontainer中数据个数相差过大的时候采用基于二分查找的方法对arraycontainer求交集,避免不必要的线性合并花费的时间开销。</p><p>（3）roaingbitmap在做并集的时候同样根据一级索引只对相同的索引的容器进行合并操作，而索引不同的直接添加到新的roaringbitmap上即可，不需要遍历容器。</p><p>（4）.roaringbitmap在合并容器的时候会先预测结果，生成对应的容器，避免不必要的容器转换操作。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;ES会缓存频率比较高的filter查询，其中的原理也比较简单，即生成&lt;code&gt;(fitler, segment)&lt;/code&gt;和id列表的映射，但是和倒排索引不同，我们只把常用的filter缓存下来而倒排索引是保存所有的，并且filter缓存应该足够快，不然直接查询不就可
      
    
    </summary>
    
    
      <category term="ES" scheme="https://arvenseyz.github.io/tags/ES/"/>
    
  </entry>
  
  <entry>
    <title>FOR</title>
    <link href="https://arvenseyz.github.io/2021/09/22/9-21%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-2/"/>
    <id>https://arvenseyz.github.io/2021/09/22/9-21技术笔记-2/</id>
    <published>2021-09-22T09:11:15.000Z</published>
    <updated>2021-09-23T06:19:51.450Z</updated>
    
    <content type="html"><![CDATA[<p>在进行查询的时候经常会进行组合查询，比如查询同时包含<code>choice</code>和<code>the</code>的文档，那么就需要分别查出包含这两个单词的文档的id，然后取这两个id列表的<strong>交集</strong>；如果是查包含<code>choice</code><strong>或者</strong><code>the</code>的文档，那么就需要分别查出posting list然后取<strong>并集</strong>。为了能够高效的进行交集和并集的操作，posting list里面的id都是有序的。同时为了减小存储空间，所有的id都会进行<strong>delta编码</strong>（delta-encoding，我觉得可以翻译成<strong>增量编码</strong>）</p><p>比如现在有id列表<code>[73, 300, 302, 332, 343, 372]</code>，转化成每一个id相对于前一个id的增量值（第一个id的前一个id默认是0，增量就是它自己）列表是<code>[73, 227, 2, 30, 11, 29]</code>。在这个新的列表里面，所有的id都是小于255的，所以每个id只需要<strong>一个字节</strong>存储。</p><p>实际上ES会做的更加精细，它会把所有的文档分成很多个block，每个block正好包含256个文档，然后单独对每个文档进行增量编码，计算出存储这个block里面所有文档最多需要多少位来保存每个id，并且把这个位数作为头信息（header）放在每个block 的前面。这个技术叫Frame of Reference，我翻译成索引帧。</p><p>比如对上面的数据进行压缩（假设每个block只有3个文件而不是256），压缩过程如下</p><p><img src="https://s3.bmp.ovh/imgs/2021/09/c8cd99dd7c742a88.png" alt></p><p>在返回结果的时候，其实也并不需要把所有的数据直接解压然后一股脑全部返回，可以直接返回一个迭代器iterator，直接通过迭代器的next方法逐一取出压缩的id，这样也可以极大的节省计算和内存开销。<br>通过以上的方式可以极大的节省posting list的空间消耗，提高查询性能。不过ES为了提高filter过滤器查询的性能，还做了更多的工作，那就是缓存。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在进行查询的时候经常会进行组合查询，比如查询同时包含&lt;code&gt;choice&lt;/code&gt;和&lt;code&gt;the&lt;/code&gt;的文档，那么就需要分别查出包含这两个单词的文档的id，然后取这两个id列表的&lt;strong&gt;交集&lt;/strong&gt;；如果是查包含&lt;code&gt;choic
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="ES" scheme="https://arvenseyz.github.io/tags/ES/"/>
    
  </entry>
  
  <entry>
    <title>FST</title>
    <link href="https://arvenseyz.github.io/2021/09/22/9-22%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-2/"/>
    <id>https://arvenseyz.github.io/2021/09/22/9-22技术笔记-2/</id>
    <published>2021-09-22T03:20:52.000Z</published>
    <updated>2021-09-22T07:23:18.318Z</updated>
    
    <content type="html"><![CDATA[<h2 id="FST（Finite-State-Transducer）"><a href="#FST（Finite-State-Transducer）" class="headerlink" title="FST（Finite State Transducer）"></a>FST（Finite State Transducer）</h2><p>FST类似一种TRIE树。</p><p><a href="https://imgtu.com/i/4N3OO0" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/22/4N3OO0.png" alt="4N3OO0.png"></a></p><p><a href="https://imgtu.com/i/4N8Em6" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/09/22/4N8Em6.png" alt="4N8Em6.png"></a></p><p>可见FST和字典树类似，区别在于，它不但共享了前缀，还共享了后缀。</p><h2 id="怎么构建"><a href="#怎么构建" class="headerlink" title="怎么构建"></a>怎么构建</h2><p>FST树的构建比较简单，但其依赖于前提<strong><em>输入有序</em></strong></p><p>只需要每次和上一个输入进行最大前缀匹配即可。</p><p><img src="https://s3.bmp.ovh/imgs/2021/09/a813ad0d38865fba.png" alt></p><p>插入“do”与，前一个单词“deep”进行最大前缀匹配，发现是d，则在d边后增加新边o，o边指向终点。</p><h1 id="怎么用"><a href="#怎么用" class="headerlink" title="怎么用"></a>怎么用</h1><p>Lucene在存储倒排索引时，分为2个文件: 词典文件(.tim), 词典索引文件(.tip)。其中.tip中存储的就是多个FST，<br>FST中存储的是&lt;单词前缀，以该前缀开头的所有Term的压缩块在磁盘中的位置&gt;。</p><p>ES的词典，实际上分了两级，Terms Dictionary 通过 .tim 后缀文件存储，其内部采用 NodeBlock 对 Term 进行压缩前缀存储，处理过程会将相同前缀的的 Term 压缩为一个 NodeBlock，NodeBlock 会存储公共前缀，然后将每个 Term 的后缀以及对应 Term 的 Posting 关联信息处理为一个 Entry 保存到 Block。</p><p><img src="https://s3.bmp.ovh/imgs/2021/09/13ba20217a706cd5.png" alt></p><p>在上图中可以看到 Block 中还包含了 Block，这里是为了处理包含相同前缀的 Term 集合内部部分 Term 又包含了相同前缀。</p><p>举个例子，在下图中为公共前缀为 a 的 Term 集合，内部部分 Term 的又包含了相同前缀 ab，这时这部分 Term 就会处理为一个嵌套的 Block。</p><p>Terms Dictionary 是按 NodeBlock 存储在.tim 文件上。当文档数量越来越多的时，Dictionary 中的 Term 也会越来越多，那查询效率必然也会逐渐变低。</p><p>因此需要一个很好的数据结构为 Dictionary 建构一个索引，这就是 Terms Index(.tip文件存储)，Lucene 采用了 FST 这个数据结构来实现这个索引。</p><p>实际上，<strong>FST的结构非常复杂，我们可以简单的将其理解为一个高效的K-V结构，而且空间占用率更高</strong>。这里想简单强调一下：<strong>Lucene到底在FST里存了什么数据？</strong> 如果你已经了解FST在Lucene中充当的角色和作用的话，我想你可能会误认为FST中存了Dictionary中所有的Terms数据，这样可以通过FST是找到具体的Term的位置，或者通过FST可以切实获知一个Term是否存在。</p><p><strong>然而，事实并非如此。</strong> FST即不能知道某个Term在Dictionary(.tim)文件上具体的位置，也不能仅通过FST就能确切的知道Term是否真实存在。它只能告诉你，查询的Term可能在这些Blocks上，到底存不存在FST并不能给出确切的答案，<strong>因为FST是通过Dictionary的每个Block的前缀构成，所以通过FST只可以直接找到这个Block在.tim文件上具体的File Pointer</strong>，并无法直接找到Terms。</p><h3 id="倒排索引的实现"><a href="#倒排索引的实现" class="headerlink" title="倒排索引的实现"></a>倒排索引的实现</h3><ul><li>通过 Term Index 数据（.tip文件）中的 StartFP 获取指定字段的 FST</li><li>通过 FST 找到指定 Term 在 Term Dictionary（.tim 文件）可能存在的 Block</li><li>将对应 Block 加载内存，遍历 Block 中的 Entry，通过后缀（Suffix）判断是否存在指定 Term</li><li>存在则通过 Entry 的 TermStat 数据中各个文件的 FP 获取 Posting 数据</li><li>如果需要获取 Term 对应的所有 DocId 则直接遍历 TermFreqs，如果获取指定 DocId 数据则通过 SkipData快速跳转</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;FST（Finite-State-Transducer）&quot;&gt;&lt;a href=&quot;#FST（Finite-State-Transducer）&quot; class=&quot;headerlink&quot; title=&quot;FST（Finite State Transducer）&quot;&gt;&lt;/a&gt;FS
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="ES" scheme="https://arvenseyz.github.io/tags/ES/"/>
    
  </entry>
  
  <entry>
    <title>ES的搜索阶段</title>
    <link href="https://arvenseyz.github.io/2021/09/18/9-16%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>https://arvenseyz.github.io/2021/09/18/9-16技术笔记/</id>
    <published>2021-09-18T08:54:44.000Z</published>
    <updated>2021-09-18T09:48:31.610Z</updated>
    
    <content type="html"><![CDATA[<h1 id="查询阶段"><a href="#查询阶段" class="headerlink" title="查询阶段"></a>查询阶段</h1><p>在初始 <em>查询阶段</em> 时， 查询会广播到索引中每一个分片拷贝（主分片或者副本分片）。 每个分片在本地执行搜索并构建一个匹配文档的 <em>优先队列</em>。</p><p>查询阶段包含以下三个步骤:</p><ol><li>客户端发送一个  search  请求到   一个节点 ， 该节点 会创建一个大小为  <code>from + size</code>  的空优先队列。</li><li>节点将查询请求转发到索引的每个主分片或副本分片中。每个分片在本地执行查询并添加结果到大小为  <code>from + size</code>  的本地有序优先队列中。</li><li>每个分片返回各自优先队列中所有文档的 ID 和排序值给协调节点  ，它合并这些值到自己的优先队列中来产生一个全局排序后的结果列表。</li></ol><p>当一个搜索请求被发送到某个节点时，这个节点就变成了协调节点。 这个节点的任务是广播查询请求到所有相关分片并将它们的响应整合成全局排序后的结果集合，这个结果集合会返回给客户端。</p><h1 id="取回阶段"><a href="#取回阶段" class="headerlink" title="取回阶段"></a>取回阶段</h1><p>分布式阶段由以下步骤构成：</p><ol><li>协调节点辨别出哪些文档需要被取回并向相关的分片提交多个  <code>GET</code>  请求。</li><li>每个分片加载并  <em>丰富</em>  文档，如果有需要的话，接着返回文档给协调节点。</li><li>一旦所有的文档都被取回了，协调节点返回结果给客户端。</li></ol><p>协调节点首先决定哪些文档  <em>确实</em>  需要被取回。例如，如果我们的查询指定了  <code>{ &quot;from&quot;: 90, &quot;size&quot;: 10 }</code>  ，最初的90个结果会被丢弃，只有从第91个开始的10个结果需要被取回。这些文档可能来自和最初搜索请求有关的一个、多个甚至全部分片。</p><p>协调节点给持有相关文档的每个分片创建一个  <a href="https://www.elastic.co/guide/cn/elasticsearch/guide/2.x/distrib-multi-doc.html" title="多文档模式" target="_blank" rel="noopener">multi-get request</a>  ，并发送请求给同样处理查询阶段的分片副本。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;查询阶段&quot;&gt;&lt;a href=&quot;#查询阶段&quot; class=&quot;headerlink&quot; title=&quot;查询阶段&quot;&gt;&lt;/a&gt;查询阶段&lt;/h1&gt;&lt;p&gt;在初始 &lt;em&gt;查询阶段&lt;/em&gt; 时， 查询会广播到索引中每一个分片拷贝（主分片或者副本分片）。 每个分片在本地执行搜索并
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="ES" scheme="https://arvenseyz.github.io/tags/ES/"/>
    
  </entry>
  
  <entry>
    <title>ES的Scroll查询</title>
    <link href="https://arvenseyz.github.io/2021/09/15/9-15%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>https://arvenseyz.github.io/2021/09/15/9-15技术笔记-1/</id>
    <published>2021-09-15T08:27:28.000Z</published>
    <updated>2021-09-18T10:04:43.513Z</updated>
    
    <content type="html"><![CDATA[<p>如scroll=1m则把查询结果在下一次请求上来时暂存1分钟，response比传统的返回多了一个scroll_id，下次带上这个scroll_id即可找回这个缓存的结果。这里就scroll完成的逻辑。</p><p>Scroll方式通过一次查询请求后维护一个临时的索引快照的search context，此后的增删查改操作并不会影响这个快照数据信息，后续的查询只需要根据游标去取数据，直到结果集中返回的 hits 字段为空，就表示遍历结束。效率比较高。在5.x之后，还可以通过slice分片来实现并行导出。</p><p>想象下，srcoll没有from，只能从头开始，比如size10，某种sort，分片接到请求后，构建优先队列，拿到top10返回，然后保存该优先队列。第二次请求，协调者可以告诉该分片，这次需要大于多少的10个。节点接着操作该树即可。</p><p>它的缺点就是维护一个search context需要占用很多资源，而且在快照建立之后数据变化如删除和更新操作是不能被感知到的，所以不能够用于实时和高并发的场景。</p><p>scroll先从各个分片根据搜索结果获取文档ID排序后返回到协调节点，协调节点再进行排序，第一次和from+size流程一样，区别在于通过scroll会把这次搜索的文档ID都汇总到协调节点并缓存起来，下次根据分页获取的时候不再重新构造，而是直接从缓存里获取</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">GET yz_alias/_search?scroll=2m</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">10</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"_scroll_id"</span> : <span class="string">"DnF1ZXJ5VGhlbkZldGNoAwAAAAAAsiN1FkpGQ2dUa1BNUVUyeUpVSzY1bUduVEEAAAAAAMAg5RZNaWx1TmFSUVRYUzBmV3dpOGRYUUpnAAAAAADAIOQWTWlsdU5hUlFUWFMwZld3aThkWFFKZw=="</span>,</span><br><span class="line">  <span class="attr">"took"</span> : <span class="number">10</span>,</span><br><span class="line">  ....</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>第二次搜索的时候，只需要用srcollid搜即可</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">GET /_search/scroll</span><br><span class="line">&#123;</span><br><span class="line">    <span class="attr">"scroll"</span>: <span class="string">"2m"</span>, </span><br><span class="line">    <span class="attr">"scroll_id"</span> : <span class="string">"DnF1ZXJ5VGhlbkZldGNoAwAAAAAAwDyLFk1pbHVOYVJRVFhTMGZXd2k4ZFhRSmcAAAAAALI-KhZKRkNnVGtQTVFVMnlKVUs2NW1HblRBAAAAAACyPisWSkZDZ1RrUE1RVTJ5SlVLNjVtR25UQQ=="</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;如scroll=1m则把查询结果在下一次请求上来时暂存1分钟，response比传统的返回多了一个scroll_id，下次带上这个scroll_id即可找回这个缓存的结果。这里就scroll完成的逻辑。&lt;/p&gt;
&lt;p&gt;Scroll方式通过一次查询请求后维护一个临时的索引快照
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="ES" scheme="https://arvenseyz.github.io/tags/ES/"/>
    
  </entry>
  
  <entry>
    <title>ES的search after</title>
    <link href="https://arvenseyz.github.io/2021/09/14/9-14%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>https://arvenseyz.github.io/2021/09/14/9-14技术笔记/</id>
    <published>2021-09-14T06:29:27.000Z</published>
    <updated>2021-09-15T08:27:14.906Z</updated>
    
    <content type="html"><![CDATA[<h1 id="search-after"><a href="#search-after" class="headerlink" title="search after"></a>search after</h1><p>es搜索带sort字段时，也会返回，sort对应的值</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">GET yz_alias/_search?pretty</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">10</span>,</span><br><span class="line">  <span class="attr">"sort"</span>: &#123;</span><br><span class="line">    <span class="attr">"date"</span>: <span class="string">"asc"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">"hits" : [</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="attr">"_index"</span> : <span class="string">"yz_test"</span>,</span><br><span class="line">    <span class="attr">"_type"</span> : <span class="string">"_doc"</span>,</span><br><span class="line">    <span class="attr">"_id"</span> : <span class="string">"1"</span>,</span><br><span class="line">    <span class="attr">"_score"</span> : <span class="literal">null</span>,</span><br><span class="line">    <span class="attr">"_source"</span> : &#123;</span><br><span class="line">      <span class="attr">"title"</span> : <span class="string">"Some short title"</span>,</span><br><span class="line">      <span class="attr">"date"</span> : <span class="string">"2015-01-01"</span>,</span><br><span class="line">      <span class="attr">"content"</span> : <span class="string">"A very long content field..."</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"sort"</span> : [</span><br><span class="line">      <span class="number">1420070400000</span></span><br><span class="line">    ]</span><br><span class="line">  &#125;,</span><br></pre></td></tr></table></figure><p>这时把sort的值，放到search after里，可以继续往下搜</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">GET yz_alias/_search?pretty</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">10</span>,</span><br><span class="line">  <span class="attr">"sort"</span>: &#123;</span><br><span class="line">    <span class="attr">"date"</span>: <span class="string">"asc"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"search_after"</span>: [</span><br><span class="line">    <span class="number">1420070400000</span></span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">"hits" : [</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="attr">"_index"</span> : <span class="string">"yz_test2"</span>,</span><br><span class="line">    <span class="attr">"_type"</span> : <span class="string">"_doc"</span>,</span><br><span class="line">    <span class="attr">"_id"</span> : <span class="string">"3"</span>,</span><br><span class="line">    <span class="attr">"_score"</span> : <span class="literal">null</span>,</span><br><span class="line">    <span class="attr">"_source"</span> : &#123;</span><br><span class="line">      <span class="attr">"title"</span> : <span class="string">"Some short title2"</span>,</span><br><span class="line">      <span class="attr">"date"</span> : <span class="string">"2016-01-01"</span>,</span><br><span class="line">      <span class="attr">"content"</span> : <span class="string">"A very long content field..."</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"sort"</span> : [</span><br><span class="line">      <span class="number">1451606400000</span></span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>search after的好处是，不用把前n页的数据全部拿到，但是searchAfter也是全部搜索了一遍，只不过在collect过程中添加了一个上一页最后doc和当前返回的doc对比，这个过程时间复杂度为o(n)，也就是说，相比于search，并不能优化速度，时间复杂度还是o(n)，但是至少不会oom，可以搜出来。</p><p>举个例子。</p><p>一共10个分片，每个分片10条数据。现在需要第91到100条。</p><p>from+size的方式，必须的每个分片都吐出所有数据，然后协调者把这100条排序。</p><p>因为每个分片不知道其他分片数据的情况。</p><p>而search after的数据，只需要每个分片给出大于第90数据的数据即可。但是这个分片依然要扫描所有数据，才知道哪些数据大于90的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;search-after&quot;&gt;&lt;a href=&quot;#search-after&quot; class=&quot;headerlink&quot; title=&quot;search after&quot;&gt;&lt;/a&gt;search after&lt;/h1&gt;&lt;p&gt;es搜索带sort字段时，也会返回，sort对应的值&lt;/p&gt;
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="ES" scheme="https://arvenseyz.github.io/tags/ES/"/>
    
  </entry>
  
  <entry>
    <title>ES分布式</title>
    <link href="https://arvenseyz.github.io/2021/08/17/8-17%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>https://arvenseyz.github.io/2021/08/17/8-17技术笔记/</id>
    <published>2021-08-17T06:58:31.000Z</published>
    <updated>2021-08-17T08:19:38.824Z</updated>
    
    <content type="html"><![CDATA[<h2 id="并发控制"><a href="#并发控制" class="headerlink" title="并发控制"></a>并发控制</h2><p>Elasticsearch 是分布式的。当文档创建、更新或删除时， 新版本的文档必须复制到集群中的其他节点。Elasticsearch 也是异步和并发的，这意味着这些复制请求被并行发送，并且到达目的地时也许  <em>顺序是乱的</em>  。 Elasticsearch 需要一种方法确保文档的旧版本不会覆盖新的版本。</p><p>当我们之前讨论  <code>index</code>  ，  <code>GET</code>  和  <code>delete</code>  请求时，我们指出每个文档都有一个  <code>_version</code>  （版本）号，当文档被修改时版本号递增。 Elasticsearch 使用这个  <code>_version</code>  号来确保变更以正确顺序得到执行。如果旧版本的文档在新版本之后到达，它可以被简单的忽略。</p><p>操作数据时，可以指定版本，这样如果我们指定的版本号，小于当前版本号，会返回失败。</p><h2 id="选主"><a href="#选主" class="headerlink" title="选主"></a>选主</h2><p>ES集群中也会选举一个节点成为<strong>主节点</strong>，主节点它的职责是维护全局集群状态，在节点加入或离开集群的时候重新分配分片。</p><ul><li>集群层面的配置</li><li>集群内有哪些节点</li><li>各索引的设置，映射，分析器和别名等</li><li>索引内各分片所在的节点位置</li></ul><p>所有主要的文档级别API（索引，删除，搜索）都不与主节点通信，主节点并不需要涉及到文档级别的变更和搜索等操作，所以当集群只拥有一个主节点的情况下，即使流量的增加它也不会成为瓶颈。 任何节点都可以成为主节点。如果集群中就只有一个节点，那么它同时也就是主节点。</p><h5 id="Bully算法"><a href="#Bully算法" class="headerlink" title="Bully算法"></a>Bully算法</h5><p>每个节点有一个唯一ID，然后对集群中所有的节点ID进行排序，选取其中最小的ID所属的节点作为Master。<br>Bully算法的问题： 假设当前Master因为负载过重而假死，然后ID第二大的被选举为新的Master，这时旧的Master恢复然后又被选举为Master然后又会因为负载过重而假死……</p><h3 id="Zen-Discovery"><a href="#Zen-Discovery" class="headerlink" title="Zen Discovery"></a>Zen Discovery</h3><p>例如，Master负载过重而假死，集群拥有第二大ID的节点被选为新主，这时原来的Master恢复，再次被选为新主，然后又假死<br>ES 通过推迟选举，直到当前的 Master 失效来解决上述问题，只要当前主节点不挂掉，就不重新选主。但是容易产生脑裂（双主），为此，再通过“法定得票人数过半”解决脑裂问题</p><p>只有一个 Leader将当前版本的全局集群状态推送到每个节点。 ZenDiscovery（默认）过程就是这样的:</p><p>每个节点计算最高的已知节点ID，并向该节点发送领导投票<br>如果一个节点收到足够多的票数，并且该节点也为自己投票，那么它将扮演领导者的角色，开始发布集群状态。<br>所有节点都会参数选举,并参与投票,但是,只有有资格成为 master 的节点的投票才有效.<br>————————————————</p><ol><li><p>过滤出具有Master资格的节点（filterPingResponses）</p></li><li><p>选出临时Master。根据PingResponse结果构建两个列表：activeMasters和masterCandidates。</p><p>– 如果activeMasters非空，则从activeMasters中选择最合适的作为Master；</p><p>– 如果activeMasters为空，则从masterCandidates中选举，结果可能选举成功，也可能选举失败。</p></li><li><p>判断临时Master是否是本节点。</p><p>– 如果临时Master是本节点：则等待其他节点选我，默认30秒超时，成功的话就发布新的clusterState。（当选总统候选人，只等选票过半了）</p><p>– 如果临时Master是其他节点：则不再接受其他节点的join请求，并向Master节点发送加入请求。（没资格选举，就只能送人头了）</p></li></ol><h3 id="Raft"><a href="#Raft" class="headerlink" title="Raft"></a>Raft</h3><p>7版本后已改用Raft</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;并发控制&quot;&gt;&lt;a href=&quot;#并发控制&quot; class=&quot;headerlink&quot; title=&quot;并发控制&quot;&gt;&lt;/a&gt;并发控制&lt;/h2&gt;&lt;p&gt;Elasticsearch 是分布式的。当文档创建、更新或删除时， 新版本的文档必须复制到集群中的其他节点。Elastics
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="ES" scheme="https://arvenseyz.github.io/tags/ES/"/>
    
  </entry>
  
  <entry>
    <title>ES索引别名</title>
    <link href="https://arvenseyz.github.io/2021/08/16/8-16%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>https://arvenseyz.github.io/2021/08/16/8-16技术笔记-1/</id>
    <published>2021-08-16T07:01:50.000Z</published>
    <updated>2021-08-16T09:52:15.398Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ES别名"><a href="#ES别名" class="headerlink" title="ES别名"></a>ES别名</h1><p>索引别名可以指向一个或多个索引，并且可以在任何需要索引名称的API中使用。</p><h3 id="创建别名"><a href="#创建别名" class="headerlink" title="创建别名"></a>创建别名</h3><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">POST /_aliases?pretty</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"actions"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"add"</span>: &#123;</span><br><span class="line">        <span class="attr">"index"</span>: <span class="string">"yz_test"</span>,</span><br><span class="line">        <span class="attr">"alias"</span>: <span class="string">"yz_alias"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"add"</span>: &#123;</span><br><span class="line">        <span class="attr">"index"</span>: <span class="string">"yz_test1"</span>,</span><br><span class="line">        <span class="attr">"alias"</span>: <span class="string">"yz_alias"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="通过别名搜索"><a href="#通过别名搜索" class="headerlink" title="通过别名搜索"></a>通过别名搜索</h3><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">GET yz_alias/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"stored_fields"</span>: [ <span class="string">"title"</span>, <span class="string">"date"</span> ] ,</span><br><span class="line">    <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"bool"</span>: &#123;</span><br><span class="line">      <span class="attr">"must"</span>: &#123;</span><br><span class="line">        <span class="attr">"term"</span>: &#123;</span><br><span class="line">          <span class="attr">"content"</span>:<span class="string">"long"</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"took"</span> : <span class="number">7</span>,</span><br><span class="line">  <span class="attr">"timed_out"</span> : <span class="literal">false</span>,</span><br><span class="line">  <span class="attr">"_shards"</span> : &#123;</span><br><span class="line">    <span class="attr">"total"</span> : <span class="number">2</span>,</span><br><span class="line">    <span class="attr">"successful"</span> : <span class="number">2</span>,</span><br><span class="line">    <span class="attr">"skipped"</span> : <span class="number">0</span>,</span><br><span class="line">    <span class="attr">"failed"</span> : <span class="number">0</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"hits"</span> : &#123;</span><br><span class="line">    <span class="attr">"total"</span> : &#123;</span><br><span class="line">      <span class="attr">"value"</span> : <span class="number">2</span>,</span><br><span class="line">      <span class="attr">"relation"</span> : <span class="string">"eq"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"max_score"</span> : <span class="number">0.2876821</span>,</span><br><span class="line">    <span class="attr">"hits"</span> : [</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">"_index"</span> : <span class="string">"yz_test1"</span>,</span><br><span class="line">        <span class="attr">"_type"</span> : <span class="string">"_doc"</span>,</span><br><span class="line">        <span class="attr">"_id"</span> : <span class="string">"1"</span>,</span><br><span class="line">        <span class="attr">"_score"</span> : <span class="number">0.2876821</span>,</span><br><span class="line">        <span class="attr">"fields"</span> : &#123;</span><br><span class="line">          <span class="attr">"date"</span> : [</span><br><span class="line">            <span class="string">"2015-01-01T00:00:00.000Z"</span></span><br><span class="line">          ],</span><br><span class="line">          <span class="attr">"title"</span> : [</span><br><span class="line">            <span class="string">"Some short title"</span></span><br><span class="line">          ]</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">"_index"</span> : <span class="string">"yz_test"</span>,</span><br><span class="line">        <span class="attr">"_type"</span> : <span class="string">"_doc"</span>,</span><br><span class="line">        <span class="attr">"_id"</span> : <span class="string">"1"</span>,</span><br><span class="line">        <span class="attr">"_score"</span> : <span class="number">0.18232156</span>,</span><br><span class="line">        <span class="attr">"fields"</span> : &#123;</span><br><span class="line">          <span class="attr">"date"</span> : [</span><br><span class="line">            <span class="string">"2015-01-01T00:00:00.000Z"</span></span><br><span class="line">          ],</span><br><span class="line">          <span class="attr">"title"</span> : [</span><br><span class="line">            <span class="string">"Some short title"</span></span><br><span class="line">          ]</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可见，会把相同别名下索引的数据全部搜出来。</p><h3 id="索引模版"><a href="#索引模版" class="headerlink" title="索引模版"></a>索引模版</h3><p>Elasticsearch 不要求你在使用一个索引前创建它。 对于日志记录类应用，依赖于自动创建索引比手动创建要更加方便。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">PUT /_template/yz_template</span><br><span class="line"> &#123;</span><br><span class="line"> <span class="attr">"index_patterns"</span>: <span class="string">"yz_test*"</span>,</span><br><span class="line"> <span class="attr">"order"</span>: <span class="number">1</span>,</span><br><span class="line"> <span class="attr">"settings"</span>: &#123;</span><br><span class="line"> <span class="attr">"number_of_shards"</span>: <span class="number">1</span></span><br><span class="line"> &#125;,</span><br><span class="line">   <span class="attr">"mappings"</span>: &#123;</span><br><span class="line">    <span class="attr">"properties"</span>: &#123;</span><br><span class="line">      <span class="attr">"title"</span>: &#123;</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"text"</span>,</span><br><span class="line">        <span class="attr">"store"</span>: <span class="literal">true</span> </span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"date"</span>: &#123;</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"date"</span>,</span><br><span class="line">        <span class="attr">"store"</span>: <span class="literal">true</span> </span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"content"</span>: &#123;</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"text"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> &#125;,</span><br><span class="line"> <span class="attr">"aliases"</span>: &#123;</span><br><span class="line"> <span class="attr">"yz_alias"</span>: &#123;&#125;</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个模板指定了所有名字以 <code>yz_test</code> 为起始的索引的默认设置，不论它是手动还是自动创建的。 </p><p>这样我们写入数据时，会自动创建索引：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">PUT yz_test2/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"title"</span>:   <span class="string">"Some short title2"</span>,</span><br><span class="line">  <span class="attr">"date"</span>:    <span class="string">"2015-01-01"</span>,</span><br><span class="line">  <span class="attr">"content"</span>: <span class="string">"A very long content field..."</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这时，我们再使用别名搜索，可以搜出三个索引的数据。</p><h2 id="利用别名重建索引"><a href="#利用别名重建索引" class="headerlink" title="利用别名重建索引"></a>利用别名重建索引</h2><p>我们有一个索引my_index_v1，使用别名my_index</p><p>我们决定修改索引中一个字段的映射。当然，我们不能修改现存的映射，所以我们必须重新索引数据。 首先, 我们用新映射创建索引 <code>my_index_v2</code> </p><p>然后我们将数据从 <code>my_index_v1</code> 重新索引到 <code>my_index_v2</code>。方法如<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.6/docs-reindex.html" target="_blank" rel="noopener">Reindex API</a></p><p>数据迁移完成后切换别名</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">POST /_aliases</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"actions"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"add"</span>: &#123;</span><br><span class="line">        <span class="attr">"index"</span>: <span class="string">"my_index_v2"</span>,</span><br><span class="line">        <span class="attr">"alias"</span>: <span class="string">"my_index"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"remove"</span>: &#123;</span><br><span class="line">        <span class="attr">"index"</span>: <span class="string">"my_index_v1"</span>,</span><br><span class="line">        <span class="attr">"alias"</span>: <span class="string">"my_index"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="filter别名"><a href="#filter别名" class="headerlink" title="filter别名"></a>filter别名</h3><p>别名时设置filter，通过这个别名就只能看到符合过滤器过滤后的结果了</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">POST /_aliases</span><br><span class="line">&#123;</span><br><span class="line">    <span class="attr">"actions"</span> : [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"add"</span> : &#123;</span><br><span class="line">                 <span class="attr">"index"</span> : <span class="string">"test1"</span>,</span><br><span class="line">                 <span class="attr">"alias"</span> : <span class="string">"alias2"</span>,</span><br><span class="line">                 <span class="attr">"filter"</span> : &#123; <span class="attr">"term"</span> : &#123; <span class="attr">"user"</span> : <span class="string">"kimchy"</span> &#125; &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="路由别名"><a href="#路由别名" class="headerlink" title="路由别名"></a>路由别名</h3><p>所有具有此别名的操作将自动修改为使用进行路由:</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">POST /_aliases</span><br><span class="line">&#123;</span><br><span class="line">    <span class="attr">"actions"</span> : [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"add"</span> : &#123;</span><br><span class="line">                 <span class="attr">"index"</span> : <span class="string">"test"</span>,</span><br><span class="line">                 <span class="attr">"alias"</span> : <span class="string">"alias1"</span>,</span><br><span class="line">                 <span class="attr">"routing"</span> : <span class="string">"1"</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>还可以为搜索和索引操作指定不同的路由值</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">POST /_aliases</span><br><span class="line">&#123;</span><br><span class="line">    <span class="attr">"actions"</span> : [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"add"</span> : &#123;</span><br><span class="line">                 <span class="attr">"index"</span> : <span class="string">"test"</span>,</span><br><span class="line">                 <span class="attr">"alias"</span> : <span class="string">"alias2"</span>,</span><br><span class="line">                 <span class="attr">"search_routing"</span> : <span class="string">"1,2"</span>,</span><br><span class="line">                 <span class="attr">"index_routing"</span> : <span class="string">"2"</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;ES别名&quot;&gt;&lt;a href=&quot;#ES别名&quot; class=&quot;headerlink&quot; title=&quot;ES别名&quot;&gt;&lt;/a&gt;ES别名&lt;/h1&gt;&lt;p&gt;索引别名可以指向一个或多个索引，并且可以在任何需要索引名称的API中使用。&lt;/p&gt;
&lt;h3 id=&quot;创建别名&quot;&gt;&lt;a hre
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="ES" scheme="https://arvenseyz.github.io/tags/ES/"/>
    
  </entry>
  
  <entry>
    <title>BDK树</title>
    <link href="https://arvenseyz.github.io/2021/08/12/8-12%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>https://arvenseyz.github.io/2021/08/12/8-12技术笔记-1/</id>
    <published>2021-08-12T08:27:52.000Z</published>
    <updated>2021-08-13T07:42:01.647Z</updated>
    
    <content type="html"><![CDATA[<p>说到ES，就想到倒排索引，但是有个问题，我们在数字比大小的场景，倒排索引怎么实现呢？</p><p>即range怎么实现的？</p><p>早期的ES，只能把范围转化成in，最多再多一些小优化，自动产生一些区间的term，构建一个基于数字的字典树，但在大范围时依然没用，并且不太好支持多范围查询。</p><p>现在版本，ES对于数字类型，用的不是倒排索引，而是 Block k-d tree</p><h1 id="Block-k-d-tree"><a href="#Block-k-d-tree" class="headerlink" title="Block k-d tree"></a>Block k-d tree</h1><h2 id="k-d-tree"><a href="#k-d-tree" class="headerlink" title="k-d tree"></a>k-d tree</h2><p>k-d树（k-dimensional树的简称），是一种分割k维数据空间的数据结构。主要应用于多维空间关键数据的搜索（如：范围搜索和最近邻搜索）。</p><p>我们想象下二分搜索树：</p><p><strong>二叉搜索树则是在二叉树的基础上加了一些规则</strong>：</p><ul><li>左子树的值都小于父节点</li><li>右子树的值都大于父节点</li></ul><p>如果把BST中的所有元素看成一维线段上的所有点，从树的根节点开始每个节点都会把线段分成两段。</p><p><img src="https://s3.bmp.ovh/imgs/2021/08/365f9e0e6ca0052c.jpeg" alt></p><p>所以BST本质上就是一维K-D树(或者叫做1-D树)</p><p>现在将树中的元素推广到二维平面上的点，树的每一层按照维度轮流划分。比如，奇数层按x轴划分，偶数层按y轴划分，这样就得到一棵二维K-D树(2-d树)</p><p><img src="https://s3.bmp.ovh/imgs/2021/08/345c1f9a74431519.jpeg" alt></p><p>很明显，K-D树和BST一样不仅可以精确查找，也更适合做范围查询，但K-D树比BST更强，它能对多个维度进行范围查询。</p><p>比如：</p><p>Person1(age:18,hight:176)，Person2(age:19,height:181) … Person10(age:23,height:171)</p><p>想要查找年龄在20岁以上并且身高在170到180之间的所有人，用K-D树就能很好的解决。</p><h2 id="K-D-B树"><a href="#K-D-B树" class="headerlink" title="K-D-B树"></a>K-D-B树</h2><p>既然KD树是高维的二叉搜索树，那么它自然也会继承二叉搜索树的缺点：会退化成链表。</p><p>二叉搜索树解决这个问题的办法是：AVL树，红黑树。那么这个办法能否推广到高维空间呢，答案是不能。</p><p>还有个解决方法是B树。有没有高维B树呢，有的：</p><p><img src="https://s3.bmp.ovh/imgs/2021/08/5871bb9a6111b295.jpeg" alt></p><p>但是B树也有问题：B树如果节点中的子节点树超过规定的阶数，就会发生节点分裂（数据库中经常称之为“页”分裂）。</p><p><img src="https://s3.bmp.ovh/imgs/2021/08/15b47785e81116d8.gif" alt></p><p>高维B树当然也继承了这个问题，并且更加严重页分裂的时候不能以B树“一刀切”的方式解决。</p><p>以二维K-D-B树为例，一个节点数据过多，需要分裂时，就需要拆分区域。拆分区域的过程中大概率会出现拆分该区域的子区域。</p><p>所以写入性能很差</p><h2 id="B-K-D树"><a href="#B-K-D树" class="headerlink" title="B-K-D树"></a>B-K-D树</h2><p>再次优化。</p><p>BKD树是二叉树和B+树的组合。比较特殊的是，内部node必须是一个完全二叉树，而叶子node存储的则和K-D-B树一模一样。</p><p><img src="https://s3.bmp.ovh/imgs/2021/08/f6f737dc48a79824.png" alt></p><p><img src="https://s3.bmp.ovh/imgs/2021/08/fdf434231d85f737.jpeg" alt></p><p>B-K-D树结合了二叉树和B+树的特性。比较特殊的是，内部节点必须形成一个完全二叉树，而叶子节点存储方式和K-D-B树叶子相同。</p><p>和堆类似，B-K-D树的内部节点组成了一个完全二叉树。这样的好处是节点不需要存储指向子节点的指针，根据父节点索引即可算出子节点索引。假如一个节点的位置在i ，那这个节点的左节点在位置2 i，右节点在2 i + 1 。</p><p>内部节点本身不包含数据，所有数据存储在叶子节点。较小的节点也意味着内存中可以缓存更多的节点。这一点和B+树类似。</p><p>另外B-K-D树的内部树永远不会被修改，而是使用一种策略来添加新数据。</p><p>首先，有一个大小为M的Buffer。在那片论文里，它是被保存在内存的。这个Buffer, 可能仅仅是一个数组或者性能更好的一些数据结构，毕竟是有查询需求的。论文并没有指明这个Buffer的最优大小，但是直觉上来说，至少应该和K-D树节点一样大。</p><p><img src="https://s3.bmp.ovh/imgs/2021/08/fdf434231d85f737.jpeg" alt></p><p>这里用了类似LSM树的技术。</p><p>如果BKD树由N个数据，那么它有 log2(N/M)个可修改的K-D树。每一个树都是前一个树的2倍。数据首先被插入到内存里的Buffer里，一旦Buffer满了，先定位到第1个为空的树。这个Buffer的数据，以及空树之前所有节点的数据一起生成一个满的平衡树。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;说到ES，就想到倒排索引，但是有个问题，我们在数字比大小的场景，倒排索引怎么实现呢？&lt;/p&gt;
&lt;p&gt;即range怎么实现的？&lt;/p&gt;
&lt;p&gt;早期的ES，只能把范围转化成in，最多再多一些小优化，自动产生一些区间的term，构建一个基于数字的字典树，但在大范围时依然没用，并且
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="ES" scheme="https://arvenseyz.github.io/tags/ES/"/>
    
  </entry>
  
</feed>
