<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Arvense</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://arvenseyz.github.io/"/>
  <updated>2022-04-12T06:13:00.669Z</updated>
  <id>https://arvenseyz.github.io/</id>
  
  <author>
    <name>Arvense</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>mysql锁</title>
    <link href="https://arvenseyz.github.io/2022/04/08/4-8%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>https://arvenseyz.github.io/2022/04/08/4-8技术笔记/</id>
    <published>2022-04-08T08:22:52.000Z</published>
    <updated>2022-04-12T06:13:00.669Z</updated>
    
    <content type="html"><![CDATA[<h2 id="复习下隔离级别"><a href="#复习下隔离级别" class="headerlink" title="复习下隔离级别"></a>复习下隔离级别</h2><p>读未提交，会读到别的事务没提交的数据，会脏读（读到未持久化的数据）。</p><p>读已提交，读取别的事务提交的数据，在事务过程中，由于别的事务提交了数据，前后读到的数据不一样，会不可重复读。</p><p>可重复读，别的事务对该行的操作，对自己不可见。但是防不了插入新数据，count会不对，会幻读。</p><p>读串行化</p><h2 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h2><h3 id="表锁"><a href="#表锁" class="headerlink" title="表锁"></a>表锁</h3><p>LOCK TABLES table_name [READ | WRITE]</p><p>直接锁表。两种模式，读锁和写锁。</p><p>读锁的状态下，自己可以读，不能写，写会报错。</p><p>别人可以上读锁，也可以不上锁直接读，不上写直接写会阻塞，等待所有的读锁释放。</p><p>写锁状态下，自己可以写可以读。</p><p>别人上锁、读、写都会阻塞，等待写锁释放。</p><h3 id="行锁"><a href="#行锁" class="headerlink" title="行锁"></a>行锁</h3><h4 id="排他锁"><a href="#排他锁" class="headerlink" title="排他锁"></a>排他锁</h4><p>即行的写锁,X锁，select …..  for update</p><p>当前写操作没有完成前，它会阻断其他写锁和读锁。</p><p>事务对数据加上X锁时，只允许此事务读取和修改此数据，并且其它事务不能对该数据加任何锁（都会阻塞）</p><h3 id="共享锁"><a href="#共享锁" class="headerlink" title="共享锁"></a>共享锁</h3><p>即行的读锁,S锁</p><p>SELECT * FROM table_name WHERE … IN SHARE MODE;</p><p>加了S锁后，该事务只能对数据进行读取而不能修改，并且其它事务只能加S锁，不能加X锁。</p><p>读取结果集的最新版本，同时防止其他事务产生更新的数据版本。</p><p>由于数据的最新版本是不断变化的，所以本读取模式需要强制阻断最新版本的变化，保证自己读取到的是所有人都一致认可的名副其实的最新版本。</p><p><code>MySQL</code>官方文档的例子来说，假如存在两张有关系的表：PARENT和CHILD，使用普通的SELECT语句（快照读）来查询表PARENT并验证父行是否存在后再将子行插入CHILD表，这种方式安全吗？答案是否定的，因为其他会话可能会在你这个会话的SELECT和INSERT之间的某个时间点删除了父行，这个删除操作你是无法察觉到的。</p><h3 id="加锁时机"><a href="#加锁时机" class="headerlink" title="加锁时机"></a>加锁时机</h3><p><strong>update,delete,insert都会自动给涉及到的数据加上排他锁</strong>，select语句默认不会加任何锁类型。</p><p>所以加过排他锁的数据行在其他事务种是不能修改数据的，也不能通过for update和lock in share mode锁的方式查询数据，但可以直接通过select …from…查询数据，因为普通查询没有任何锁机制。</p><h3 id="意向锁"><a href="#意向锁" class="headerlink" title="意向锁"></a>意向锁</h3><p><strong>意向锁都是表锁。</strong>意向锁的存在是为了允许事务在行级上的锁和表级上的锁同时存在。</p><p>意向锁实际上不是给用户用的，而是为了解决性能问题，内部的实现。</p><p>一个事务在加表锁的时候是如何确定这张表的记录行上面有没有加锁呢？</p><p>很显然，最简单的方式就是一行一行遍历每条数据，分别去判断每行有没有被锁住。但是这方法性能有问题，所以才有的意向锁。</p><p><code>当一个事务想要获取表中某一行的（共享/排他）锁的时候，它会自动尝试给当前表的加上意向（共享/排他）锁</code><br>。然后，表锁和行锁之间的兼容互斥性就变成了表锁和意向锁之间的竞争关系。</p><p><strong>意向锁只会与表级的共享 互斥锁具有互斥性</strong>。</p><p>意向锁之间互相兼容，因此针对表中的记录加锁不会因为意向锁而产生互斥，行锁之间的竞争关系是行锁与行锁的竞争，意向锁并不会参与其中；</p><p>意向锁和表级锁会产生互斥，这里互斥的作用就是用于表锁的第二个检查。</p><h2 id="锁升级"><a href="#锁升级" class="headerlink" title="锁升级"></a>锁升级</h2><p>行锁升级为表锁的原因之一是： SQL 语句中未使用到索引，或者说使用的索引未被数据库认可（相当于没有使用索引）。</p><p>如果在数据库的设计中认为锁时一种稀有资源，而且像避免锁的开销，那数据库会频繁出现锁升级现象。（多个行锁还不如一个表锁）</p><p>InnoDB默认采用行锁，在未使用索引字段查询时升级为表锁。MySQL这样设计并不是给你挖坑。它有自己的设计目的。<br>即便你在条件中使用了索引字段，MySQL会根据自身的执行计划，考虑是否使用索引(所以explain命令中会有possible_key 和 key)。如果MySQL认为全表扫描效率更高，它就不会使用索引，这种情况下InnoDB将使用表锁，而不是行锁。因此，在分析锁冲突时，别忘了检查SQL的执行计划，以确认是否真正使用了索引。</p><p>第一种情况：全表更新。事务需要更新大部分或全部数据，且表又比较大。若使用行锁，会导致事务执行效率低，从而可能造成其他事务长时间锁等待和更多的锁冲突。</p><p>第二种情况：多表级联。事务涉及多个表，比较复杂的关联查询，很可能引起死锁，造成大量事务回滚。这种情况若能一次性锁定事务涉及的表，从而可以避免死锁、减少数据库因事务回滚带来的开销。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;复习下隔离级别&quot;&gt;&lt;a href=&quot;#复习下隔离级别&quot; class=&quot;headerlink&quot; title=&quot;复习下隔离级别&quot;&gt;&lt;/a&gt;复习下隔离级别&lt;/h2&gt;&lt;p&gt;读未提交，会读到别的事务没提交的数据，会脏读（读到未持久化的数据）。&lt;/p&gt;
&lt;p&gt;读已提交，读取别
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="数据库" scheme="https://arvenseyz.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>rocketMq和kafka比较</title>
    <link href="https://arvenseyz.github.io/2022/04/06/4-6%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>https://arvenseyz.github.io/2022/04/06/4-6技术笔记/</id>
    <published>2022-04-06T06:37:57.000Z</published>
    <updated>2022-04-08T08:23:00.611Z</updated>
    
    <content type="html"><![CDATA[<p>rocketMq定位是在线，kafka是离线，这个怎么理解。</p><p>这里的理解是Kafka吞吐高，rocketMq可用性高。</p><h2 id="存储区别"><a href="#存储区别" class="headerlink" title="存储区别"></a>存储区别</h2><p>Kafka 以 Topic 作为文件存储的基本单元，即每个 Topic 有其对应的数据文件和索引文件。消息直接存储在partition中，对单topic为顺序写。</p><p>这样预期结果是，磁盘顺序写+顺序读，性能很好。</p><p>但问题是，是分topic的，如果topic很多，要不停的切topic，顺序读写就被破坏了，降低了性能。</p><p>存储上不分topic，所以这些topic的内容写在一块的。即CommitLog。这样写是顺序写，但是读，由于各topic的内容在一块，只能索引读，即随即读。</p><h2 id="同步刷盘"><a href="#同步刷盘" class="headerlink" title="同步刷盘"></a>同步刷盘</h2><p>指的是数据从pageCache到磁盘的时机</p><p>rocketMq支持同步刷盘，同步刷盘其实并不是每一次请求都刷盘，想象下，qps很大时，这样问题很大，</p><p>刷盘服务有两个队列，requestsWrite : 写队列，主要用于向该线程添加刷盘任务 requestsRead : 读队列，主要用于执行特定的刷盘任务，这是是GroupCommitService 设计的一个亮点，把读写分离，每处理完requestsRead中的任务，就交换这两个队列。</p><p>进行同步刷盘的服务为 GroupCommitService，当请求被提交给GroupCommitService后，GroupCommitService并不是立即处理，而是先放到内部的一个请求队列中，并利用waitPoint通知新请求到来。</p><p>当 GroupCommitService 被唤醒后，便会将 requestsWrite 中的请求交换到 requestsRead中，避免产生锁竞争。</p><p>GroupCommitService 在启动后会在死循环中调用doCommit（）方法，而doCommit（）则不断遍历requestsRead中的请求，进行处理。</p><p>可见这里最终调用了CommitLog.this.mappedFileQueue.flush(0) 来进行刷盘。</p><p>同步刷盘的任务虽然也是在异步线程中执行，但是消息存储的主流程中会同步等待刷盘结果，所以本质上还是同步操作。</p><p>Kafka不支持配置同步刷盘，但是可以配置log.flush.interval.messages  //多少条消息，刷盘1次 默认值 LONG.MAX_VALUE。</p><p>如果配成1，那就是同步刷盘，但是这也就是真的每个请求都刷盘，可以想像性能很差。</p><h2 id="零拷贝"><a href="#零拷贝" class="headerlink" title="零拷贝"></a>零拷贝</h2><p>mmap是用户态和内核态，共享了文件的内存映射，实现这样的映射关系后，进程就可以采用指针的方式读写操作这一段内存，而系统会自动回写脏页面到对应的文件磁盘上，即完成了对文件的操作而不必再调用 read，write 等系统调用函数。相反，内核空间对这段区域的修改也直接反映用户空间，从而可以实现不同进程间的文件共享。</p><p><strong>简单的说，使用mmap之后，数据无需拷贝到用户空间中，应用程序可以直接操作Page Cache中的数据。</strong></p><p>sendfile相当于把文件里的数据，直接到pageCache-&gt;网卡等硬件的缓冲区，跳过了用户空间，整个流程，减少了一次CPU Copy，减少了两次的上下文切换，相比于传统IO确实提升了性能。</p><p>RocketMQ和Kafka都使用到了零拷贝的技术。</p><p>RocketMQ底层对CommitLog、ConsumeQueue之类的磁盘文件的读写操作，基本上都会采用mmap技术来实现。</p><p>kafka的日志文件并没有用到 mmap，而索引文件用了 mmap。</p><p>对于MQ而言，无非就是生产者发送数据到MQ然后持久化到磁盘，之后消费者从MQ读取数据。</p><p>对于RocketMQ来说这两个步骤使用的是<code>mmap+write</code>，而Kafka则是使用<code>mmap+write</code>持久化数据，发送数据使用<code>sendfile</code>。</p><p>看起来sendfile的性能比mmap好，那为什么rocketMq不用sendfile呢，因为<code>sendfile</code>方法IO数据对用户空间完全不可见，所以只能适用于完全不需要用户空间处理的情况，而RocketMQ将所有队列的数据都写入了CommitLog，消费者批量消费时需要读出来进行应用层过滤，所以不能用sendfile。</p><h2 id="rebalance"><a href="#rebalance" class="headerlink" title="rebalance"></a>rebalance</h2><p>rocketMq的rebalance是去中心化的，各个消费者各自rebalance，这样保证了高可用，缺点是，由于各个消费者不知道其他的情况，有序消息在rebalance时，失败重试会乱序。</p><p>kafka的rebalance是中心化的，每个消费组都会有一个coordinator，Coordinator负责处理管理组内的消费者和位移管理，Coordinator发生Rebalance的时候，Coordinator并不会主动通知组内的所有Consumer重新加入组，而是当Consumer向Coordinator发送心跳的时候，Coordinator将Rebalance的状况通过心跳响应告知Consumer。Rebalance机制整体可以分为两个步骤，一个是Joining the Group，另外一个是分配Synchronizing Group State。</p><p>缺点是rebalance时会夯住。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;rocketMq定位是在线，kafka是离线，这个怎么理解。&lt;/p&gt;
&lt;p&gt;这里的理解是Kafka吞吐高，rocketMq可用性高。&lt;/p&gt;
&lt;h2 id=&quot;存储区别&quot;&gt;&lt;a href=&quot;#存储区别&quot; class=&quot;headerlink&quot; title=&quot;存储区别&quot;&gt;&lt;/a&gt;
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="消息队列" scheme="https://arvenseyz.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>分布式事务方案</title>
    <link href="https://arvenseyz.github.io/2022/03/21/3-21%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>https://arvenseyz.github.io/2022/03/21/3-21技术笔记/</id>
    <published>2022-03-21T06:22:09.000Z</published>
    <updated>2022-03-31T09:26:27.934Z</updated>
    
    <content type="html"><![CDATA[<h1 id="AT模式"><a href="#AT模式" class="headerlink" title="AT模式"></a>AT模式</h1><p>AT 模式是无侵入的分布式事务解决方案，适用于不希望对业务进行改造的场景，几乎0学习成本。</p><p>与其他模式的区别便是代理数据源，通过被DataSourceProxy代理后，你所执行的sql，会被提取，解析，保存前镜像后，再执行业务sql，再保存后镜像，以便与后续出现异常，进行二阶段的回滚操作。</p><p>AT 模式下，把每个数据库被当做是一个 Resource，Seata 里称为 DataSource Resource。业务通过 JDBC 标准接口访问数据库资源时，Seata 框架会对所有请求进行拦截，做一些操作。每个本地事务提交时，Seata RM（Resource Manager，资源管理器） 都会向 TC（Transaction Coordinator，事务协调器） 注册一个分支事务。当请求链路调用完成后，发起方通知 TC 提交或回滚分布式事务，进入二阶段调用流程。此时，TC 会根据之前注册的分支事务回调到对应参与者去执行对应资源的第二阶段。TC 是怎么找到分支事务与资源的对应关系呢？每个资源都有一个全局唯一的资源 ID，并且在初始化时用该 ID 向 TC 注册资源。在运行时，每个分支事务的注册都会带上其资源 ID。这样 TC 就能在二阶段调用时正确找到对应的资源。</p><p>在一阶段，Seata 会拦截业务 SQL，首先解析 SQL 语义，找到业务 SQL要更新的业务数据，在业务数据被更新前，将其保存成 <code>before image</code>，然后执行业务 SQL 更新业务数据，在业务数据更新之后，再将其保存成 <code>after image</code>，最后生成行锁。以上操作全部在一个数据库事务内完成，这样保证了一阶段操作的原子性。</p><p>AT 模式的第二阶段会根据第一阶段的情况决定是进行全局提交还是全局回滚操作。对服务端来说，等到一阶段完成未抛异常，全局事务的发起方会向服务端申请提交这个全局事务，服务端根据 xid 查询出该全局事务后加锁并关闭这个全局事务，目的是防止该事务后续还有分支继续注册上来，同时将其状态从 Begin 修改为 Committing。</p><p>紧接着，判断该全局事务下的分支类型是否均为 AT 类型，若是则服务端会进行异步提交，因为 AT 模式下一阶段完成数据已经落地。服务端仅仅修改全局事务状态为 AsyncCommitting，然后会有一个定时线程池去存储介质（File 或者 Database）中查询出待提交的全局事务日志进行提交，如果全局事务提交成功则会释放全局锁并删除事务日志。</p><h1 id="XA模式"><a href="#XA模式" class="headerlink" title="XA模式"></a>XA模式</h1><p>XA 模式是利用分支事务中数据库对 XA 协议的支持来实现的。</p><p>XA 模式的流程跟其他模式一样：</p><ol><li><p>TM 开启全局事务  </p></li><li><p>RM 向 TC 注册分支事务  </p></li><li><p>RM 向 TC 报告分支事务状态  </p></li><li><p>TC 向 RM 发送 commit/rollback 请求  </p></li><li><p>TM 结束全局事务</p></li></ol><p>mysql具体执行步骤如下：</p><ol><li><code>XA START &quot;transfer_money&quot;</code>：这个表示开启一个 XA 事务，后面的字符串是事务的 xid，这是一个唯一字符串，开启之后，事务的状态变为  <code>ACTIVE</code>。</li><li><code>update account set amount=amount-10 where account_no=&#39;A&#39;</code>; 这个表示执行具体的 SQL。</li><li><code>XA END &quot;transfer_money&quot;</code>：这个表示结束一个 XA 事务，此时事务的状态转为  <code>IDLE</code>。</li><li><code>XA PREPARE &quot;transfer_money&quot;</code>：这个将事务置为 PREPARE 状态。</li><li><code>XA COMMIT &quot;transfer_money&quot;</code>：这个用来提交事务，提交之后，事务的状态就是 COMMITED。</li></ol><p>最后一步，可以通过  <code>XA COMMIT</code>  来提交，也可以通过  <code>XA ROLLBACK</code>  来回滚，回滚后事务的状态就是 ROLLBACK。</p><h2 id="优劣势"><a href="#优劣势" class="headerlink" title="优劣势"></a>优劣势</h2><p>劣势</p><ol><li>数据锁定</li></ol><p>当使用 XA 事务时，数据在整个事务处理过程结束前，都被锁定，读写都按隔离级别的定义约束起来。这确实是 XA 模式的一个劣势，不过这也是获得更高隔离性和全局一致性所要付出的代价。补偿型事务处理机制（AT、TCC）虽然不存在这个问题，但是却牺牲了隔离性。AT 模式使用全局锁保障基本的写隔离，实际上也是锁定数据的，只不过锁在 TC 侧集中管理，解锁效率高且没有阻塞的问题。</p><ol start="2"><li>协议阻塞</li></ol><p>XA prepare 后，分支事务进入阻塞阶段，收到 XA commit 或 XA rollback 前必须阻塞等待。议的阻塞机制本身并不是问题，关键问题在于协议阻塞遇上数据锁定，如果一个参与全局事务的资源 “失联” 了（收不到分支事务结束的命令），那么它锁定的数据，将一直被锁定，进而可能因此产生死锁。这是 XA 协议的核心痛点，也是 Seata 引入 XA 模式要重点解决的问题，Seata 中主要是解决了失联问题，并通过增加自解锁机制来解决这个问题。</p><ol start="3"><li>性能差</li></ol><p>这可能是被诟病最多的地方了，XA 模式性能的损耗主要来自两个方面：一方面，事务协调过程，增加单个事务的 RT；另一方面，并发事务数据的锁冲突，降低吞吐。</p><p>和不使用分布式事务支持的运行场景比较，性能肯定是下降的，这点毫无疑问。本质上，事务（无论是本地事务还是分布式事务）机制就是拿部分 性能的牺牲 ，换来 编程模型的简单。</p><p>AT 模式性能优势主要在于：集中管理全局数据锁，锁的释放不需要 RM 参与，释放锁非常快；另外，全局提交的事务，完成阶段 异步化。</p><h1 id="TCC-模式"><a href="#TCC-模式" class="headerlink" title="TCC 模式"></a><strong>TCC 模式</strong></h1><p>TCC 模式需要用户根据自己的业务场景实现 Try、Confirm 和 Cancel 三个操作；事务发起方在一阶段执行 Try 方式，在二阶段提交执行 Confirm 方法，二阶段回滚执行 Cancel 方法。</p><p>tcc的特点是，业务方需要自己实现。</p><p>有以下几点需要注意</p><p><strong>允许空回滚</strong></p><p>Cancel 接口设计时需要允许空回滚。在 Try 接口因为丢包时没有收到，事务管理器会触发回滚，这时会触发 Cancel 接口，这时 Cancel 执行时发现没有对应的事务 xid 或主键时，需要返回回滚成功。让事务服务管理器认为已回滚，否则会不断重试，而 Cancel 又没有对应的业务数据可以进行回滚。</p><p><strong>防悬挂控制</strong></p><p>悬挂的意思是：Cancel 比 Try 接口先执行，出现的原因是 Try 由于网络拥堵而超时，事务管理器生成回滚，触发 Cancel 接口，而最终又收到了 Try 接口调用，但是 Cancel 比 Try 先到。按照前面允许空回滚的逻辑，回滚会返回成功，事务管理器认为事务已回滚成功，则此时的 Try 接口不应该执行，否则会产生数据不一致，所以我们在 Cancel 空回滚返回成功之前先记录该条事务 xid 或业务主键，标识这条记录已经回滚过，Try 接口先检查这条事务xid或业务主键如果已经标记为回滚成功过，则不执行 Try 的业务操作。</p><p><strong>幂等控制</strong></p><p>幂等性的意思是：对同一个系统，使用同样的条件，一次请求和重复的多次请求对系统资源的影响是一致的。因为网络抖动或拥堵可能会超时，事务管理器会对资源进行重试操作，所以很可能一个业务操作会被重复调用，为了不因为重复调用而多次占用资源，需要对服务设计时进行幂等控制，通常我们可以用事务 xid 或业务主键判重来控制。</p><h1 id="SAGA"><a href="#SAGA" class="headerlink" title="SAGA"></a>SAGA</h1><p>Saga 模式适用于业务流程长且需要保证事务最终一致性的业务系统，Saga 模式一阶段就会提交本地事务，无锁、长流程情况下可以保证性能。</p><p>事务参与者可能是其它公司的服务或者是遗留系统的服务，无法进行改造和提供 TCC 要求的接口，可以使用 Saga 模式。</p><p>Saga模式的优势是：</p><ul><li>一阶段提交本地数据库事务，无锁，高性能；</li><li>参与者可以采用事务驱动异步执行，高吞吐；</li><li>补偿服务即正向服务的“反向”，易于理解，易于实现；</li></ul><p>缺点：Saga 模式由于一阶段已经提交本地数据库事务，且没有进行“预留”动作，所以不能保证隔离性。相当于是未提交读。</p><p>分布式事务内先给用户A充值, 然后给用户B扣减余额, 如果在给A用户充值成功, 在事务提交以前, A用户把余额消费掉了, 如果事务发生回滚, 这时则没有办法进行补偿了。</p><p>与TCC实践经验相同的是，Saga 模式中，每个事务参与者的冲正、逆向操作，需要支持：</p><ul><li>空补偿：逆向操作早于正向操作时；</li><li>防悬挂控制：空补偿后要拒绝正向操作</li><li>幂等</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;AT模式&quot;&gt;&lt;a href=&quot;#AT模式&quot; class=&quot;headerlink&quot; title=&quot;AT模式&quot;&gt;&lt;/a&gt;AT模式&lt;/h1&gt;&lt;p&gt;AT 模式是无侵入的分布式事务解决方案，适用于不希望对业务进行改造的场景，几乎0学习成本。&lt;/p&gt;
&lt;p&gt;与其他模式的区别便
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="分布式" scheme="https://arvenseyz.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>未读数系统设计</title>
    <link href="https://arvenseyz.github.io/2022/03/17/3-17%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>https://arvenseyz.github.io/2022/03/17/3-17技术笔记/</id>
    <published>2022-03-17T07:45:15.000Z</published>
    <updated>2022-03-21T06:21:57.927Z</updated>
    
    <content type="html"><![CDATA[<p>显然不能用通用的计数系统来做未读数，因为有系统通知这种东西，一条系统通知，所有人未读数加1，这样写扩散太严重了。</p><h1 id="系统通知"><a href="#系统通知" class="headerlink" title="系统通知"></a>系统通知</h1><p>能用拉的方式，系统通知实际上是存储在一个大的列表中的，这个列表对所有用户共享，也就是所有人看到的都是同一份系统通知的数据。不过不同的人最近看到的消息不同，所以每个人会有不同的未读数。因此，你可以记录一下在这个列表中每个人看过最后一条消息的 ID，然后统计这个 ID 之后有多少条消息，这就是未读数了。</p><p>用户访问系统通知页面需要设置未读数为 0，我们需要将用户最近看过的通知 ID 设置为最新的一条系统通知 ID；</p><p>如果最近看过的通知 ID 为空，则认为是一个新的用户，返回未读数为 0；</p><p>对于非活跃用户，比如最近一个月都没有登录和使用过系统的用户，可以把用户最近看过的通知 ID 清空，节省内存空间。</p><h1 id="信息流"><a href="#信息流" class="headerlink" title="信息流"></a>信息流</h1><p>首先，在通用计数器中记录每一个用户发布的博文数；</p><p>然后在 Redis 或者 Memcached 中记录一个人所有关注人的博文数快照，当用户点击未读消息重置未读数为 0 时，将他关注所有人的博文数刷新到快照中；</p><p>这样，他关注所有人的博文总数减去快照中的博文总数就是他的信息流未读数。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;显然不能用通用的计数系统来做未读数，因为有系统通知这种东西，一条系统通知，所有人未读数加1，这样写扩散太严重了。&lt;/p&gt;
&lt;h1 id=&quot;系统通知&quot;&gt;&lt;a href=&quot;#系统通知&quot; class=&quot;headerlink&quot; title=&quot;系统通知&quot;&gt;&lt;/a&gt;系统通知&lt;/h1&gt;&lt;
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="系统设计" scheme="https://arvenseyz.github.io/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>quic协议</title>
    <link href="https://arvenseyz.github.io/2022/03/15/3-15%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>https://arvenseyz.github.io/2022/03/15/3-15技术笔记/</id>
    <published>2022-03-15T13:33:32.000Z</published>
    <updated>2022-03-16T06:43:46.404Z</updated>
    
    <content type="html"><![CDATA[<p>什么都是有代价的，tcp为什么慢，是因为tcp可靠。</p><h2 id="tcp为什么可靠"><a href="#tcp为什么可靠" class="headerlink" title="tcp为什么可靠"></a>tcp为什么可靠</h2><h3 id="校验和（Checksum）"><a href="#校验和（Checksum）" class="headerlink" title="校验和（Checksum）"></a>校验和（Checksum）</h3><p><strong>TCP 和 UDP 都支持最基本的校验和算法</strong>。当要传输数据的时候，数据会被分片，我们把每个分片看作一个字节数组。然后在分片中，预留几个字节去存储校验和。校验和随着数据分片一起传输到目的地，目的地会用同样的算法再次计算校验和。如果二者校验和不一致，代表中途数据发生了损坏。</p><p><strong>对于 TCP 和 UDP，都实现了校验和算法，但二者的区别是，TCP 如果发现校验核对不上，也就是数据损坏，会主动丢失这个封包并且重发。而 UDP 什么都不会处理，UDP 把处理的权利交给使用它的程序员</strong>。</p><h3 id="请求-应答-连接模型"><a href="#请求-应答-连接模型" class="headerlink" title="请求/应答/连接模型"></a>请求/应答/连接模型</h3><p>另一种保证可靠性的方法是<strong>请求响应和连接的模型</strong>。TCP 实现了请求、响应和连接的模型，UDP 没有实现这个模型。</p><p>也就是三次握手四次挥手，https更复杂，因为还要s。</p><h3 id="封包排序"><a href="#封包排序" class="headerlink" title="封包排序"></a>封包排序</h3><p><strong>可靠性有一个最基本的要求是数据有序发出、无序传输，并且有序组合。TCP 协议保证了这种可靠性，UDP 则没有保证</strong>。</p><p>在传输之前，数据被拆分成分块。在 TCP 中叫作一个<strong>TCP Segment</strong>。在 UDP 中叫作一个<strong>UDP Datagram</strong>。Datagram 单词的含义是数据传输的最小单位。在到达目的地之后，尽管所有的数据分块可能是乱序到达的，但为了保证可靠性，乱序到达的数据又需要被重新排序，恢复到原有数据的顺序。</p><p><strong>在这个过程当中，TCP 利用了滑动窗口、快速重传等算法，保证了数据的顺序。而 UDP，仅仅是为每个 Datagram 标注了序号，并没有帮助应用程序进行数据的排序</strong>，<strong>这也是 TCP 和 UDP 在保证可靠性上一个非常重要的区别。</strong></p><h2 id="QUIC为什么快"><a href="#QUIC为什么快" class="headerlink" title="QUIC为什么快"></a>QUIC为什么快</h2><p>所以udp快但是不可靠，不可靠的场景使用udp当然好，但是可靠的场景就不能用了吗？也有用的，比如基于quic的http3。</p><p>于是问题来了，怎么可靠呢，还不是在网络层实现传输层的可靠性保障，如果这样的话，岂不是绕回去了，等于在网络层实现了tcp。</p><p>话是这么说的，其实tcp有很多缺点，但是历史包袱太重，缺点改不了，虽然只是在网络层实现了tcp，但改了缺点，也提升了性能。</p><h3 id="连接建立延时低"><a href="#连接建立延时低" class="headerlink" title="连接建立延时低"></a><strong>连接建立延时低</strong></h3><p>QUIC 使用了 DH 算法进行密钥协商。</p><p>思考下为什么https要3rtt，一共6次交互才能建立连接。</p><ol><li><p>可靠和安全分离，http要三次握手，加密要3次</p></li><li><p>第三次握手可以带上业务数据了，但是没有</p></li></ol><p>QUIC即改进了这两点，所以只需要两步，协商连接id，验证连接id，第三步就可以用这个id发数据了。</p><p>client 在首次连接后，会把 server 的config存下，之后再次发起连接时，因为已经有config了，可以直接从上面的第 3 步开始，而这一步已经可以发送业务数据了，所以，非首次连接时，QUIC 可以做到 0RTT</p><h3 id="解决队首阻塞"><a href="#解决队首阻塞" class="headerlink" title="解决队首阻塞"></a>解决队首阻塞</h3><p>https的阻塞其实有三个方面，第一个是http是基于文本的，没法分帧，所以不能多路复用，导致只有上一个请求的所有数据包被传输完毕下一个请求的数据包才可以被传输。</p><p>第二是，TLS 协议也存在队头阻塞问题TLS 基于 Record 组织数据，将一堆数据放在一起（即一个 Record）加密，加密完后又拆分成多个 TCP 包传输。一般每个 Record 16K，包含 12 个 TCP 包，这样如果 12 个 TCP 包中有任何一个包丢失，那么整个 Record 都无法解密。</p><p>Http2基于2进制，分帧，所以有了多路复用，但是tcp级别上还是有队首阻塞。<code>采用HTTP/2时</code>，浏览器一般会在<code>单个TCP</code>连接中创建并行的几十个乃至上百个传输。如果HTTP/2连接双方的网络中有一个数据包丢失，或者任何一方的网络出现中断，整个TCP连接就会暂停，丢失的数据包需要被重新传输。因为<code>TCP是一个按序传输的通道</code>，因此如果其中一个点丢失了，通道上之后的内容就都需要等待。<strong>随着丢包率的增加</strong>，HTTP/2的表现越来越差。在2%的丢包率（一个很差的网络质量）中，测试结果表明HTTP/1用户的性能更好。我们看一个例子，在一条 TCP 连接上同时发送 4 个 Stream，其中 Stream1 已正确送达，Stream2 中的第 3 个 Frame 丢失，TCP 处理数据时有严格的前后顺序，先发送的 Frame 要先被处理，这样就会要求发送方重新发送第 3 个 Frame，Stream3 和 Stream4 虽然已到达但却不能被处理，那么这时整条连接都被阻塞。</p><p>第三是TCP层面的队首阻塞，TCP为了保证有序，又兼顾效率，采用了滑动窗口，但是窗口的首个元素丢包，会导致窗口滑不动，依然会阻塞。</p><p>看一下quic怎么解决这些问题。</p><ol><li><p>基于二进制分帧，多路复用</p></li><li><p>加密基于packet，不用打包</p></li><li><p>流量控制分为Stream和Connection两种级别的控制。这里Connection就是QUIC握手后建立的连接，Stream可以理解为链路上的请求。Connection里的Stream相互独立，不会互相阻塞，Stream采用的不是滑动窗口推进的方法，而是类似收到推进的方法。</p></li></ol><p>对于Stream而言，起始的接收窗口就是其最大接收窗口（max receive window），随着接收者接收到一部分数据后，接收窗口变小。而接收到的数据中，有一部分已经读取（图中黄色部分），这部分数据的量到达一定的阈值后，就需要更新接收窗口并告知发送者。QUIC将这个阈值定义为：</p><p>update when (flow control receive offset - consumed bytes) &lt; (max receive window / 2);</p><p>也就是当已经读取的数据大于最大接收窗口的一半时，发送WINDOW_UPDATE帧告诉发送者，接收窗口已经更新。比如告诉发送者，窗口后移了Bytes consumes字节。</p><p>QUIC协议中同一个Stream内，滑动窗口的移动仅取决于接收到的最大字节偏移（尽管期间可能有部分数据未被接收），而对于TCP而言，窗口滑动必须保证此前的包都有序的接收到了，其中一个packet丢失就会导致窗口等待。</p><h3 id="改进的拥塞控制"><a href="#改进的拥塞控制" class="headerlink" title="改进的拥塞控制"></a><strong>改进的拥塞控制</strong></h3><p>目前QUIC默认采用Cubic拥塞控制算法来实现拥塞控制，就这点来看和TCP采用的是一套机制（譬如我们熟知的慢开始、拥塞避免、快重传、快恢复策略），但QUIC的这套拥塞控制策略还是与TCP有一些明显的区别和改进：</p><p><strong>- 灵活性</strong></p><p>TCP协议内置在系统协议栈层面，你想要改变其拥塞控制策略，需要在系统层面进行修改。而QUIC基于UDP，当你想要改变拥塞控制算法，或者进行调优工作，只需要在应用层进行修改，这并不是一件困难的事情，而且对其他应用没有影响。目前谷歌提供了两套算法（Cubic和NewReno）以供选择，并提供了一套很灵活友好的接口，让你去实验新的拥塞控制算法，而且还可以为不同应用设定不同的拥塞控制策略。</p><p><strong>- 提供更为详细的信息</strong></p><p>QUIC提供了更加详细而准确的信息。如其严格单调递增的Packet序列 ，能够很容易的区分packet是来自重传还是首次传输，避免了重传模糊。再如QUIC携带有关收到数据包和发送ACK之间延迟的信息，可以更准确的计算RTT时间。</p><p>另外，相对于TCp的SACK（Selective Acknowledgments，用来标注哪些包已经收到了让对方更方便的选择性重传），QUIC还提供了更大范围(0-256)的NACK（Negative Acknowledgments，用来标注哪些包没有收到），来帮助发送者快速的重传丢失包。</p><p><strong>- 尽可能避免超时重传</strong></p><p>为了尽可能的实现快重传而不是超时重传，QUIC采用了Tail Loss Probes (TLPs)实现某些情况下的快重传机制触发。</p><h3 id="链接迁移"><a href="#链接迁移" class="headerlink" title="链接迁移"></a>链接迁移</h3><p>当客户端IP或端口发生变化时（这在移动端比较常见），TCP连接基于两端的ip:port四元组标示，因此会重新握手，而UDP不面向连接，不用握手。其上层的QUIC链路由于使用了64位Connection id作为唯一标识，四元组变化不影响链路的标示，也不用重新握手。因此网络链接状态变化时不会增加额外的握手重连耗时。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;什么都是有代价的，tcp为什么慢，是因为tcp可靠。&lt;/p&gt;
&lt;h2 id=&quot;tcp为什么可靠&quot;&gt;&lt;a href=&quot;#tcp为什么可靠&quot; class=&quot;headerlink&quot; title=&quot;tcp为什么可靠&quot;&gt;&lt;/a&gt;tcp为什么可靠&lt;/h2&gt;&lt;h3 id=&quot;校验和（Che
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="计算机网络" scheme="https://arvenseyz.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>GMP模型</title>
    <link href="https://arvenseyz.github.io/2022/03/14/3-14%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>https://arvenseyz.github.io/2022/03/14/3-14技术笔记-1/</id>
    <published>2022-03-14T06:58:15.000Z</published>
    <updated>2022-03-15T13:33:36.989Z</updated>
    
    <content type="html"><![CDATA[<h1 id="用户态和内核态"><a href="#用户态和内核态" class="headerlink" title="用户态和内核态"></a>用户态和内核态</h1><p>Kernel 运行在超级权限模式（Supervisor Mode）下，所以拥有很高的权限。按照权限管理的原则，多数应用程序应该运行在最小权限下。因此，很多操作系统，将内存分成了两个区域：</p><ul><li>内核空间（Kernal Space），这个空间只有内核程序可以访问；</li><li>用户空间（User Space），这部分内存专门给应用程序使用。</li></ul><h2 id="用户态和内核态-1"><a href="#用户态和内核态-1" class="headerlink" title="用户态和内核态"></a>用户态和内核态</h2><p>用户空间中的代码被限制了只能使用一个局部的内存空间，我们说这些程序在<strong>用户态（User Mode）</strong>  执行。内核空间中的代码可以访问所有内存，我们称这些程序在<strong>内核态（Kernal Mode）</strong>  执行。</p><h2 id="系统调用过程"><a href="#系统调用过程" class="headerlink" title="系统调用过程"></a>系统调用过程</h2><p>如果用户态程序需要执行系统调用，就需要切换到内核态执行。</p><p>内核程序执行在内核态（Kernal Mode），用户程序执行在用户态（User Mode）。当发生系统调用时，用户态的程序发起系统调用。因为系统调用中牵扯特权指令，用户态程序权限不足，因此会中断执行，也就是 Trap（Trap 是一种中断）。</p><p>发生中断后，当前 CPU 执行的程序会中断，跳转到中断处理程序。内核程序开始执行，也就是开始处理系统调用。内核处理完成后，主动触发 Trap，这样会再次发生中断，切换回用户态工作。</p><h1 id="线程模型"><a href="#线程模型" class="headerlink" title="线程模型"></a>线程模型</h1><h4 id="进程和线程"><a href="#进程和线程" class="headerlink" title="进程和线程"></a>进程和线程</h4><p>一个应用程序启动后会在内存中创建一个执行副本，这就是<strong>进程</strong>。Linux 的内核是一个 Monolithic Kernel（宏内核），因此可以看作一个进程。也就是开机的时候，磁盘的内核镜像被导入内存作为一个执行副本，成为内核进程。</p><p>进程可以分成用户态进程和内核态进程两类。用户态进程通常是应用程序的副本，内核态进程就是内核本身的进程。如果用户态进程需要申请资源，比如内存，可以通过系统调用向内核申请。</p><p><strong>那么用户态进程如果要执行程序，是否也要向内核申请呢</strong>？</p><p>程序在现代操作系统中并不是以进程为单位在执行，而是以一种轻量级进程（Light Weighted Process），也称作线程（Thread）的形式执行。</p><p>一个进程可以拥有多个线程。进程创建的时候，一般会有一个主线程随着进程创建而创建。</p><p>如果进程想要创造更多的线程，就需要思考一件事情，这个线程创建在用户态还是内核态。</p><p>你可能会问，难道不是用户态的进程创建用户态的线程，内核态的进程创建内核态的线程吗？</p><p>其实不是，进程可以通过 API 创建用户态的线程，也可以通过系统调用创建内核态的线程，接下来我们说说用户态的线程和内核态的线程。</p><h4 id="用户态线程"><a href="#用户态线程" class="headerlink" title="用户态线程"></a>用户态线程</h4><p>用户态线程也称作用户级线程（User Level Thread）。操作系统内核并不知道它的存在，它完全是在用户空间中创建。</p><p>用户级线程有很多优势，比如。</p><ul><li><strong>管理开销小</strong>：创建、销毁不需要系统调用。</li><li><strong>切换成本低</strong>：用户空间程序可以自己维护，不需要走操作系统调度。</li></ul><p>但是这种线程也有很多的缺点。</p><ul><li><strong>与内核协作成本高</strong>：比如这种线程完全是用户空间程序在管理，当它进行 I/O 的时候，无法利用到内核的优势，需要频繁进行用户态到内核态的切换。</li><li><strong>线程间协作成本高</strong>：设想两个线程需要通信，通信需要 I/O，I/O 需要系统调用，因此用户态线程需要支付额外的系统调用成本。</li><li><strong>无法利用多核优势</strong>：比如操作系统调度的仍然是这个线程所属的进程，所以无论每次一个进程有多少用户态的线程，都只能并发执行一个线程，因此一个进程的多个线程无法利用多核的优势。</li><li><strong>操作系统无法针对线程调度进行优化</strong>：当一个进程的一个用户态线程阻塞（Block）了，操作系统无法及时发现和处理阻塞问题，它不会更换执行其他线程，从而造成资源浪费。</li></ul><h4 id="内核态线程"><a href="#内核态线程" class="headerlink" title="内核态线程"></a>内核态线程</h4><p>内核态线程也称作内核级线程（Kernel Level Thread）。这种线程执行在内核态，可以通过系统调用创造一个内核级线程。</p><p>内核级线程有很多优势。</p><ul><li><strong>可以利用多核 CPU 优势</strong>：内核拥有较高权限，因此可以在多个 CPU 核心上执行内核线程。</li><li><strong>操作系统级优化</strong>：内核中的线程操作 I/O 不需要进行系统调用；一个内核线程阻塞了，可以立即让另一个执行。</li></ul><p>当然内核线程也有一些缺点。</p><ul><li><strong>创建成本高</strong>：创建的时候需要系统调用，也就是切换到内核态。</li><li><strong>扩展性差</strong>：由一个内核程序管理，不可能数量太多。</li><li><strong>切换成本较高</strong>：切换的时候，也同样存在需要内核操作，需要切换内核态。</li></ul><h4 id="一对一（One-to-One）模型"><a href="#一对一（One-to-One）模型" class="headerlink" title="一对一（One to One）模型"></a>一对一（One to One）模型</h4><p>该模型为每个用户态的线程分配一个单独的内核态线程，在这种情况下，每个用户态都需要通过系统调用创建一个绑定的内核线程，并附加在上面执行。 这种模型允许所有线程并发执行，能够充分利用多核优势，Windows NT 内核采取的就是这种模型。但是因为线程较多，对内核调度的压力会明显增加。</p><h4 id="多对多（Many-To-Many）模型"><a href="#多对多（Many-To-Many）模型" class="headerlink" title="多对多（Many To Many）模型"></a>多对多（Many To Many）模型</h4><p>这种模式下会为 n 个用户态线程分配 m 个内核态线程。m 通常可以小于 n。一种可行的策略是将 m 设置为核数。这种多对多的关系，减少了内核线程，同时也保证了多核心并发。Linux 目前采用的就是该模型。</p><h1 id="GMP"><a href="#GMP" class="headerlink" title="GMP"></a>GMP</h1><p><a href="https://imgtu.com/i/bOgpTJ" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2022/03/14/bOgpTJ.jpg" alt="bOgpTJ.jpg"></a></p><p>G ———– goroutine: 即Go协程，每个go关键字都会创建一个协程。</p><p>M ———- thread内核级线程，所有的G都要放在M上才能运行。</p><p>P ———– processor处理器，调度G到M上，其维护了一个队列，存储了所有需要它来调度的G。</p><p>Goroutine 调度器P和 OS 调度器是通过 M 结合起来的，每个 M 都代表了 1 个内核线程，OS 调度器负责把内核线程分配到 CPU 的核上执行</p><h3 id="有关-P-和-M-的数量问题"><a href="#有关-P-和-M-的数量问题" class="headerlink" title="有关 P 和 M 的数量问题"></a>有关 P 和 M 的数量问题</h3><ol><li><p>P 的数量：  </p><p>由程序启动时环境变量 $GOMAXPROCS 或 runtime方法GOMAXPROCS()决定，  </p><p>这意味着在程序执行的任意时刻都只有 $MAXPROCS个goroutine在执行 ,一般设置为cpu的核心数</p></li><li><p>M 的数量  </p><p>2.1 go 语言本身的限制，go 程序启动时会设置M的最大数量，默认10000，但是内核很难支持这么多的线程，  </p><p>所以可以忽略，  </p><p>2.1 runtime/debug中的SetMaxThreads函数，设置 M 的最大数量  </p><p>2.3 当一个M阻塞了，会创建新的M  </p></li><li>M和P的数量没有绝对关系，一个M阻塞，P就会创建或者切换其它的M，所以即使P的数量是1，也有可能创建出很多个M出来。</li></ol><h3 id="P-和-M-何时会被创建"><a href="#P-和-M-何时会被创建" class="headerlink" title="P 和 M 何时会被创建"></a>P 和 M 何时会被创建</h3><ol><li>P 何时创建：在确定了P的最大数量n后，runtime运行时系统会根据这个数量创建n个P  </li><li><p>M 何时创建：没有足够的M来关联P并运行其中可运行的G；比如此时所有的M都阻塞住了，  </p><p>但是P中还有很多就绪任务，此时就会去创建新的M。从这看M的数量应该是略多于P</p></li></ol><h3 id="复用线程："><a href="#复用线程：" class="headerlink" title="复用线程："></a>复用线程：</h3><p>避免重复的创建、销毁线程，而是对线程的复用</p><p>work stealing机制：当本线程M无可运行的G时，会尝试从其它线程绑定的P中偷取G，而不是销毁线程<br>hand off机制：当本线程M因为G进行系统调用时阻塞，线程M释放绑定的P，交给其它空闲的线程M去执行<br>利用并行：GOMAXPROCS设置P的数量，最多有GOMAXPROCS个线程分布在多个CPU上运行，<br>GOMAXPROCS也限制了并发的程度，当设置 GOMAXPROCS = CPU核数/2 时，则最多利用了一半的CPU核进行并行  </p><h3 id="抢占"><a href="#抢占" class="headerlink" title="抢占"></a>抢占</h3><p> 在coroutine中要等待一个协程让出CPU才执行下一个协程，而在go中，一个goroutine最多占用CPU 10ms,  </p><p>防止其它goroutine被饿死，这就是goroutine不同于其它coroutine的区别  </p><h3 id="全局G队列"><a href="#全局G队列" class="headerlink" title="全局G队列"></a>全局G队列</h3><p>在新的调度器中依然有全局G队列，但是功能被弱化了，当M执行 work stealing 从其它P队列偷不到G时，  </p><p>它可以从全局G队列获取G</p><h2 id="调度过程"><a href="#调度过程" class="headerlink" title="调度过程"></a>调度过程</h2><p><a href="https://imgtu.com/i/bOgMtA" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2022/03/14/bOgMtA.jpg" alt="bOgMtA.jpg"></a></p><p>1、我们通过 go func()来创建一个goroutine；  </p><p>2、有两个存储G的队列，一个是局部调度器P的本地队列、一个是全局G队列。新创建的G会先保存在P的本地队列中，如果P的本地队列已经满了就会保存在全局的队列中；  </p><p>3、G只能运行在M中，一个M必须持有一个P，M与P是1：1的关系。M会从P的本地队列弹出一个可执行状态的G来执行，如果P的本地队列为空，就会想其他的MP组合偷取一个可执行的G来执行；  </p><p>4、一个M调度G执行的过程是一个循环机制；  </p><p>5、当M执行某一个G时候如果发生了syscall或则其余阻塞操作，M会阻塞，如果当前有一些G在执行，runtime会把这个线程M从P中摘除(detach)，然后再创建一个新的操作系统的线程(如果有空闲的线程可用就复用空闲线程)来服务于这个P；  </p><p>6、当M系统调用结束时候，这个G会尝试获取一个空闲的P执行，并放入到这个P的本地队列。如果获取不到P，那么这个线程M变成休眠状态， 加入到空闲线程中，然后这个G会被放入全局队列中。</p><h2 id="调度器的生命周期"><a href="#调度器的生命周期" class="headerlink" title="调度器的生命周期"></a>调度器的生命周期</h2><p><a href="https://imgtu.com/i/bOgN7Q" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2022/03/14/bOgN7Q.jpg" alt="bOgN7Q.jpg"></a></p><h2 id="特殊的M0和G0"><a href="#特殊的M0和G0" class="headerlink" title="特殊的M0和G0"></a>特殊的M0和G0</h2><p><strong>M0</strong></p><p><code>M0</code>是启动程序后的编号为0的主线程，这个M对应的实例会在全局变量runtime.m0中，不需要在heap上分配，M0负责执行初始化操作和启动第一个G， 在之后M0就和其他的M一样了。</p><p><strong>G0</strong></p><p><code>G0</code>是每次启动一个M都会第一个创建的gourtine，G0仅用于负责调度的G，G0不指向任何可执行的函数, 每个M都会有一个自己的G0。在调度或系统调用时会使用G0的栈空间, 全局变量的G0是M0的G0。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;用户态和内核态&quot;&gt;&lt;a href=&quot;#用户态和内核态&quot; class=&quot;headerlink&quot; title=&quot;用户态和内核态&quot;&gt;&lt;/a&gt;用户态和内核态&lt;/h1&gt;&lt;p&gt;Kernel 运行在超级权限模式（Supervisor Mode）下，所以拥有很高的权限。按照权限管
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="操作系统" scheme="https://arvenseyz.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="Go" scheme="https://arvenseyz.github.io/tags/Go/"/>
    
  </entry>
  
  <entry>
    <title>点赞数系统设计</title>
    <link href="https://arvenseyz.github.io/2022/03/11/3-10%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>https://arvenseyz.github.io/2022/03/11/3-10技术笔记/</id>
    <published>2022-03-11T03:41:12.000Z</published>
    <updated>2022-03-11T06:20:06.944Z</updated>
    
    <content type="html"><![CDATA[<h1 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h1><p>想象下点赞的场景</p><ol><li><p>读写qps都很高</p></li><li><p>当点赞数较大时，允许数据不太准</p></li><li><p>没有搜索场景，只有id读</p></li><li><p>接受写延迟</p></li></ol><p>存储上当然就是id-&gt;点赞数</p><h1 id="存储"><a href="#存储" class="headerlink" title="存储"></a>存储</h1><p>既然是kv数据，那么肯定用nosql，这里看看redis。</p><p>第一是热点写问题，redis写性能极强，单机几万qps，对于redis没压力，不行上集群。</p><p>第二是高读取qps，redis集群同样能支持百万级别。</p><p>实际上，可能有多个数字，转发数，评论数等等，读取的时候几乎都是同时读取的，要不要考虑存一起。存一起的问题是没法写，那还不如mget，一起读。</p><h1 id="幂等和分时"><a href="#幂等和分时" class="headerlink" title="幂等和分时"></a>幂等和分时</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">required Domain（基础服务的一级标识，一般为app_id）</span><br><span class="line">required Scene（场景标识，是domain的二级目录）</span><br><span class="line">required KeyType（计数的主体类型，比如是user_id/device_id/...）</span><br><span class="line">required Key（对应计数主体类型的值，比如KeyType选择了user_id，key就是对应user_id的值）</span><br><span class="line">required Category（计数维度，之前的Group字段）</span><br><span class="line">required ReqID（Domain+Scene+Category+KeyType+Key+CountTimestamp+ReqID组成唯一标识，接口幂等字段）</span><br><span class="line">required CountTimestamp（计数秒级时间戳，全球统一）</span><br><span class="line">required TimeZoneName（时区）  // 跨时区的数据注意该字段的一致性</span><br><span class="line">required AddCount（增数）</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">核心流程：</span><br><span class="line">1、入参校验（如果CountTimestamp属于35天前，拒绝请求）</span><br><span class="line">2、幂等检查</span><br><span class="line">   查询 key = &#123;rev_key&#125;:&#123;key_type&#125;:&#123;domain&#125;:&#123;scene&#125;:log:&#123;category&#125;:&#123;count_timestamp&#125;:&#123;req_id&#125; 是否已存在，存在返回“成功”</span><br><span class="line">3、主要逻辑</span><br><span class="line">    自动清理hour、day中超时数据、增加count、更新lastTime</span><br><span class="line">4、事务操作（cas）</span><br><span class="line">   insert 幂等记录：key = &#123;rev_key&#125;:&#123;key_type&#125;:&#123;domain&#125;:&#123;scene&#125;:log:&#123;category&#125;:&#123;count_timestamp&#125;:&#123;req_id&#125; / value = &#123;AddCount，CountTimestamp，TimeZoneName，RollbackStatus&#125;</span><br><span class="line">   insert hour计数24H数据：key = &#123;rev_key&#125;:&#123;key_type&#125;:&#123;domain&#125;:&#123;scene&#125;:hour:&#123;category&#125; / value = &#123;&quot;2021072116&quot;:&#123;Count，Reward，LastTime，LastReqID&#125;... &quot;2021072215&quot;:&#123;Count，LastTime，LastReqID&#125;&#125; </span><br><span class="line">   insert day计数35天数据：key = &#123;rev_key&#125;:&#123;key_type&#125;:&#123;domain&#125;:&#123;scene&#125;:day:&#123;category&#125; / value = &#123;&quot;20210623&quot;:&#123;Count，Reward，LastTime，LastReqID&#125;... &quot;20210722&quot;:&#123;Count，LastTime，LastReqID&#125;&#125; </span><br><span class="line">   insert total计数数据：key = &#123;rev_key&#125;:&#123;key_type&#125;:&#123;domain&#125;:&#123;scene&#125;:total:&#123;category&#125; / value = &#123;Count +=AddCount，LastTime，LastReqID，ResetTime&#125;</span><br><span class="line">   </span><br><span class="line">出参：</span><br><span class="line">NeedRetry(true/false)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;场景&quot;&gt;&lt;a href=&quot;#场景&quot; class=&quot;headerlink&quot; title=&quot;场景&quot;&gt;&lt;/a&gt;场景&lt;/h1&gt;&lt;p&gt;想象下点赞的场景&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;读写qps都很高&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;当点赞数较大时，允许数据不太准&lt;/p&gt;
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="系统设计" scheme="https://arvenseyz.github.io/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>热搜系统设计</title>
    <link href="https://arvenseyz.github.io/2022/03/09/3-9%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>https://arvenseyz.github.io/2022/03/09/3-9技术笔记/</id>
    <published>2022-03-09T10:11:59.000Z</published>
    <updated>2022-03-09T12:29:11.796Z</updated>
    
    <content type="html"><![CDATA[<p>寻找数据流中出现最频繁的k个元素(find top k frequent items in a data stream)。这个问题也称为 Heavy Hitters.</p><p>这题也是从实践中提炼而来的，例如搜索引擎的热搜榜，找出访问网站次数最多的前10个IP地址，等等。</p><h1 id="基础思路"><a href="#基础思路" class="headerlink" title="基础思路"></a>基础思路</h1><p>哈希表和小根堆</p><p>即元素和对应次数放在哈希表里，topN放在小根堆里。</p><p>每次先增加哈希表，然后再调整小根堆。</p><h1 id="容量和请求压力问题"><a href="#容量和请求压力问题" class="headerlink" title="容量和请求压力问题"></a>容量和请求压力问题</h1><p>元素过多哈希表装不下怎么办，分片即可，分n个哈希表，放在n个机器上，然后都取最后聚合。</p><h1 id="淘汰旧数据"><a href="#淘汰旧数据" class="headerlink" title="淘汰旧数据"></a>淘汰旧数据</h1><p>比如每分钟更新一次的24小时内热搜，做60*24个哈希表，分别是每分钟的热度，这样小根堆应该是所有哈希表次数之和然后更新。</p><p>一个后台进程删除老桶。</p><h1 id="Lossy-Couting-算法"><a href="#Lossy-Couting-算法" class="headerlink" title="Lossy Couting 算法"></a>Lossy Couting 算法</h1><p>即把数据流分段，分段的精细程度取决于需要的误差。</p><p>开始统计每个元素出现的频率，统计结束后，每个元素的频率减1，然后将出现次数为0的元素从HashMap中删除。</p><p>这样HashMap会一直较小。</p><p>朴素的思想是，出现频率高的元素，不太可能减一后变成0，如果某个元素在某个窗口内降到了0，说明它不太可能是高频元素，可以不再跟踪它的计数器了。随着处理的窗口越来越多，HashMap也会不断增长，同时HashMap里的低频元素会被清理出去，这样内存占用会保持在一个很低的水平。</p><p>但实际上是有bug的，比如一共有100万段，一个元素平均分布在这100万段中，每段1次，实际上这高频元素没统计到。</p><p>这就是为什么该算法不精确，但是根据二八定理，该事情不太可能发生。</p><p>比如说该流：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">班主任提出的四个测试，即武汉中考考察内容 </span><br><span class="line">语文测试、数学测试、英语测试和政治测试。</span><br></pre></td></tr></table></figure><p>每十个元素一段</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">班主任提出的四个测试 | ，即武汉中考考察内容 |</span><br><span class="line">语文测试、数学测试、 | 英语测试和政治测试。 |</span><br></pre></td></tr></table></figure><p>hashMap依次是</p><ol><li><p>空</p></li><li><p>[考,1]</p></li><li><p>[考,],[测,1],[试,1],[、,1]</p></li><li><p>[考,],[测,2],[试,1],[、,1]</p></li></ol><p>则频率最高是测，其次是考，试，、</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;寻找数据流中出现最频繁的k个元素(find top k frequent items in a data stream)。这个问题也称为 Heavy Hitters.&lt;/p&gt;
&lt;p&gt;这题也是从实践中提炼而来的，例如搜索引擎的热搜榜，找出访问网站次数最多的前10个IP地址，等
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="系统设计" scheme="https://arvenseyz.github.io/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>ES关联关系</title>
    <link href="https://arvenseyz.github.io/2022/03/08/3-8%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>https://arvenseyz.github.io/2022/03/08/3-8技术笔记/</id>
    <published>2022-03-08T06:59:33.000Z</published>
    <updated>2022-03-08T07:39:38.151Z</updated>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>Mysql中多表关联，我们可以通过left join 或者Join等实现；</p><p>ES5.X版本，借助父子文档实现多表关联，类似数据库中Join的功能；实现的核心是借助于ES5.X支持1个索引(index)下多个类型(type)。</p><p>ES6.X版本，由于每个索引下面只支持单一的类型（type）。</p><p>所以，ES6.X版本如何实现Join成为大家关注的问题。</p><h1 id="定义join"><a href="#定义join" class="headerlink" title="定义join"></a>定义join</h1><p>仍然是一个索引下，借助父子关系，实现类似Mysql中多表关联的操作。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">PUT my_join_index</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"mappings"</span>: &#123;</span><br><span class="line">    <span class="attr">"_doc"</span>: &#123;</span><br><span class="line">      <span class="attr">"properties"</span>: &#123;</span><br><span class="line">        <span class="attr">"my_join_field"</span>: &#123; </span><br><span class="line">          <span class="attr">"type"</span>: <span class="string">"join"</span>,</span><br><span class="line">          <span class="attr">"relations"</span>: &#123;</span><br><span class="line">            <span class="attr">"question"</span>: <span class="string">"answer"</span> </span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><p>1） “my_join_field”为join的名称。</p></li><li><p>2）“question”: “answer” 指：qustion为answer的父类。</p></li></ul><h1 id="插入文档"><a href="#插入文档" class="headerlink" title="插入文档"></a>插入文档</h1><p>父文档</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">PUT my_join_index/_doc/1?refresh</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"text"</span>: <span class="string">"This is a question"</span>,</span><br><span class="line">  <span class="attr">"my_join_field"</span>: <span class="string">"question"</span> </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PUT my_join_index/_doc/2?refresh</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"text"</span>: <span class="string">"This is another question"</span>,</span><br><span class="line">  <span class="attr">"my_join_field"</span>: <span class="string">"question"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>子文档</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">PUT my_join_index/_doc/3?routing=1&amp;refresh </span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"text"</span>: <span class="string">"This is an answer"</span>,</span><br><span class="line">  <span class="attr">"my_join_field"</span>: &#123;</span><br><span class="line">    <span class="attr">"name"</span>: <span class="string">"answer"</span>, </span><br><span class="line">    <span class="attr">"parent"</span>: <span class="string">"1"</span> </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PUT my_join_index/_doc/4?routing=1&amp;refresh</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"text"</span>: <span class="string">"This is another answer"</span>,</span><br><span class="line">  <span class="attr">"my_join_field"</span>: &#123;</span><br><span class="line">    <span class="attr">"name"</span>: <span class="string">"answer"</span>,</span><br><span class="line">    <span class="attr">"parent"</span>: <span class="string">"1"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>路由值是强制性的，因为父文件和子文件必须在相同的分片上建立索引。</li><li>“answer”是此子文档的加入名称。</li><li>parent指定此子文档的父文档ID：1</li></ul><h1 id="类型约束"><a href="#类型约束" class="headerlink" title="类型约束"></a>类型约束</h1><ol><li><p>每个索引只允许一个Join类型Mapping定义；</p></li><li><p>父文档和子文档必须在同一个分片上编入索引；这意味着，当进行删除、更新、查找子文档时候需要提供相同的路由值。</p></li><li><p>一个文档可以有多个子文档，但只能有一个父文档。</p></li><li><p>可以为已经存在的Join类型添加新的关系。</p></li><li><p>当一个文档已经成为父文档后，可以为该文档添加子文档。</p></li></ol><h1 id="检索"><a href="#检索" class="headerlink" title="检索"></a>检索</h1><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">GET my_join_index/_search</span><br><span class="line">&#123;</span><br><span class="line">    <span class="attr">"query"</span>: &#123;</span><br><span class="line">        <span class="attr">"has_parent"</span> : &#123;</span><br><span class="line">            <span class="attr">"parent_type"</span> : <span class="string">"question"</span>,</span><br><span class="line">            <span class="attr">"query"</span> : &#123;</span><br><span class="line">                <span class="attr">"match"</span> : &#123;</span><br><span class="line">                    <span class="attr">"text"</span> : <span class="string">"This is"</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">GET my_join_index/_search</span><br><span class="line">&#123;</span><br><span class="line"><span class="attr">"query"</span>: &#123;</span><br><span class="line">        <span class="attr">"has_child"</span> : &#123;</span><br><span class="line">            <span class="attr">"type"</span> : <span class="string">"answer"</span>,</span><br><span class="line">            <span class="attr">"query"</span> : &#123;</span><br><span class="line">                <span class="attr">"match"</span> : &#123;</span><br><span class="line">                    <span class="attr">"text"</span> : <span class="string">"This is question"</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="一对多和祖孙"><a href="#一对多和祖孙" class="headerlink" title="一对多和祖孙"></a>一对多和祖孙</h1><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">PUT join_ext_index</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"mappings"</span>: &#123;</span><br><span class="line">    <span class="attr">"_doc"</span>: &#123;</span><br><span class="line">      <span class="attr">"properties"</span>: &#123;</span><br><span class="line">        <span class="attr">"my_join_field"</span>: &#123;</span><br><span class="line">          <span class="attr">"type"</span>: <span class="string">"join"</span>,</span><br><span class="line">          <span class="attr">"relations"</span>: &#123;</span><br><span class="line">            <span class="attr">"question"</span>: [<span class="string">"answer"</span>, <span class="string">"comment"</span>]  </span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">question</span><br><span class="line">    /    \</span><br><span class="line">   /      \</span><br><span class="line">comment  answer</span><br><span class="line">           |</span><br><span class="line">           |</span><br><span class="line">          vote</span><br></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">PUT join_multi_index</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"mappings"</span>: &#123;</span><br><span class="line">    <span class="attr">"_doc"</span>: &#123;</span><br><span class="line">      <span class="attr">"properties"</span>: &#123;</span><br><span class="line">        <span class="attr">"my_join_field"</span>: &#123;</span><br><span class="line">          <span class="attr">"type"</span>: <span class="string">"join"</span>,</span><br><span class="line">          <span class="attr">"relations"</span>: &#123;</span><br><span class="line">            <span class="attr">"question"</span>: [<span class="string">"answer"</span>, <span class="string">"comment"</span>],  </span><br><span class="line">            <span class="attr">"answer"</span>: <span class="string">"vote"</span> </span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;p&gt;Mysql中多表关联，我们可以通过left join 或者Join等实现；&lt;/p&gt;
&lt;p&gt;ES5.X版本，借助父子文档实现多表关联，类似数据
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="ES" scheme="https://arvenseyz.github.io/tags/ES/"/>
    
  </entry>
  
  <entry>
    <title>ES嵌套类型</title>
    <link href="https://arvenseyz.github.io/2022/03/07/3-7%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>https://arvenseyz.github.io/2022/03/07/3-7技术笔记/</id>
    <published>2022-03-07T07:53:53.000Z</published>
    <updated>2022-03-08T07:29:50.419Z</updated>
    
    <content type="html"><![CDATA[<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"title"</span>: <span class="string">"Invest Money"</span>,</span><br><span class="line">  <span class="attr">"body"</span>: <span class="string">"Please start investing money as soon..."</span>,</span><br><span class="line">  <span class="attr">"tags"</span>: [<span class="string">"money"</span>, <span class="string">"invest"</span>],</span><br><span class="line">  <span class="attr">"published_on"</span>: <span class="string">"18 Oct 2017"</span>,</span><br><span class="line">  <span class="attr">"comments"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"William"</span>,</span><br><span class="line">      <span class="attr">"age"</span>: <span class="number">34</span>,</span><br><span class="line">      <span class="attr">"rating"</span>: <span class="number">8</span>,</span><br><span class="line">      <span class="attr">"comment"</span>: <span class="string">"Nice article.."</span>,</span><br><span class="line">      <span class="attr">"commented_on"</span>: <span class="string">"30 Nov 2017"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"John"</span>,</span><br><span class="line">      <span class="attr">"age"</span>: <span class="number">38</span>,</span><br><span class="line">      <span class="attr">"rating"</span>: <span class="number">9</span>,</span><br><span class="line">      <span class="attr">"comment"</span>: <span class="string">"I started investing after reading this."</span>,</span><br><span class="line">      <span class="attr">"commented_on"</span>: <span class="string">"25 Nov 2017"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"Smith"</span>,</span><br><span class="line">      <span class="attr">"age"</span>: <span class="number">33</span>,</span><br><span class="line">      <span class="attr">"rating"</span>: <span class="number">7</span>,</span><br><span class="line">      <span class="attr">"comment"</span>: <span class="string">"Very good post"</span>,</span><br><span class="line">      <span class="attr">"commented_on"</span>: <span class="string">"20 Nov 2017"</span></span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>现在假设我们想查找用户{name：john，age：34}评论过的所有博客帖子。 让我们再看一下上面的示例文档，找到评论过的用户。</p><table><thead><tr><th>name</th><th>age</th></tr></thead><tbody><tr><td>William</td><td>34</td></tr><tr><td>John</td><td>38</td></tr><tr><td>Smith</td><td>33</td></tr></tbody></table><p>从列表中我们可以清楚地看到，没有34岁的用户John。</p><p>如果我们这么搜</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">GET /blog/_search?pretty</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"bool"</span>: &#123;</span><br><span class="line">      <span class="attr">"must"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">"match"</span>: &#123;</span><br><span class="line">            <span class="attr">"comments.name"</span>: <span class="string">"John"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">"match"</span>: &#123;</span><br><span class="line">            <span class="attr">"comments.age"</span>: <span class="number">34</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>却能把文档搜出来。</p><h1 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h1><p>实际上，并不是搜的姿势问题，因为must的match之间，的确是且的关系。而是存的姿势问题。</p><p>我们知道，es是倒排索引，那实际上倒排索引如下</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"title"</span>:                    [ invest, money ],</span><br><span class="line">  <span class="attr">"body"</span>:                     [ as, investing, money, please, soon, start ],</span><br><span class="line">  <span class="attr">"tags"</span>:                     [ invest, money ],</span><br><span class="line">  <span class="attr">"published_on"</span>:             [ <span class="number">18</span> Oct <span class="number">2017</span> ]</span><br><span class="line">  <span class="string">"comments.name"</span>:            [ smith, john, william ],</span><br><span class="line">  <span class="attr">"comments.comment"</span>:         [ after, article, good, i, investing, nice, post, reading, started, this, very ],</span><br><span class="line">  <span class="attr">"comments.age"</span>:             [ <span class="number">33</span>, <span class="number">34</span>, <span class="number">38</span> ],</span><br><span class="line">  <span class="attr">"comments.rating"</span>:          [ <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span> ],</span><br><span class="line">  <span class="attr">"comments.commented_on"</span>:    [ <span class="number">20</span> Nov <span class="number">2017</span>, <span class="number">25</span> Nov <span class="number">2017</span>, <span class="number">30</span> Nov <span class="number">2017</span> ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从这倒排索引来看，的确能搜出来。</p><h1 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h1><p>解决方法就是把嵌套对象设置为嵌套类型</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">PUT /blog_new</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"mappings"</span>: &#123;</span><br><span class="line">    <span class="attr">"blog"</span>: &#123;</span><br><span class="line">      <span class="attr">"properties"</span>: &#123;</span><br><span class="line">        <span class="attr">"title"</span>: &#123;</span><br><span class="line">          <span class="attr">"type"</span>: <span class="string">"text"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"body"</span>: &#123;</span><br><span class="line">          <span class="attr">"type"</span>: <span class="string">"text"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"tags"</span>: &#123;</span><br><span class="line">          <span class="attr">"type"</span>: <span class="string">"keyword"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"published_on"</span>: &#123;</span><br><span class="line">          <span class="attr">"type"</span>: <span class="string">"keyword"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"comments"</span>: &#123;</span><br><span class="line">          <span class="attr">"type"</span>: <span class="string">"nested"</span>,</span><br><span class="line">          <span class="attr">"properties"</span>: &#123;</span><br><span class="line">            <span class="attr">"name"</span>: &#123;</span><br><span class="line">              <span class="attr">"type"</span>: <span class="string">"text"</span></span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="attr">"comment"</span>: &#123;</span><br><span class="line">              <span class="attr">"type"</span>: <span class="string">"text"</span></span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="attr">"age"</span>: &#123;</span><br><span class="line">              <span class="attr">"type"</span>: <span class="string">"short"</span></span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="attr">"rating"</span>: &#123;</span><br><span class="line">              <span class="attr">"type"</span>: <span class="string">"short"</span></span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="attr">"commented_on"</span>: &#123;</span><br><span class="line">              <span class="attr">"type"</span>: <span class="string">"text"</span></span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>并且使用嵌套查询</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">GET /blog_new/_search?pretty</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"bool"</span>: &#123;</span><br><span class="line">      <span class="attr">"must"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">"nested"</span>: &#123;</span><br><span class="line">            <span class="attr">"path"</span>: <span class="string">"comments"</span>,</span><br><span class="line">            <span class="attr">"query"</span>: &#123;</span><br><span class="line">              <span class="attr">"bool"</span>: &#123;</span><br><span class="line">                <span class="attr">"must"</span>: [</span><br><span class="line">                  &#123;</span><br><span class="line">                    <span class="attr">"match"</span>: &#123;</span><br><span class="line">                      <span class="attr">"comments.name"</span>: <span class="string">"john"</span></span><br><span class="line">                    &#125;</span><br><span class="line">                  &#125;,</span><br><span class="line">                  &#123;</span><br><span class="line">                    <span class="attr">"match"</span>: &#123;</span><br><span class="line">                      <span class="attr">"comments.age"</span>: <span class="number">34</span></span><br><span class="line">                    &#125;</span><br><span class="line">                  &#125;</span><br><span class="line">                ]</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>由于用户{name：john，age：34}没有匹配，上面的查询将不返回任何文档。</p><p>是因为es内部倒排索引变成了这样</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &#123;</span><br><span class="line">    "comments.name":    [ john ],</span><br><span class="line">    "comments.comment": [ after i investing started reading this ],</span><br><span class="line">    "comments.age":     [ 38 ],</span><br><span class="line">    "comments.rating":  [ 9 ],</span><br><span class="line">    "comments.date":    [ 25 Nov 2017 ]</span><br><span class="line">  &#125;,</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="attr">"comments.name"</span>:    [ william ],</span><br><span class="line">    <span class="attr">"comments.comment"</span>: [ article, nice ],</span><br><span class="line">    <span class="attr">"comments.age"</span>:     [ <span class="number">34</span> ],</span><br><span class="line">    <span class="attr">"comments.rating"</span>:   [ <span class="number">8</span> ],</span><br><span class="line">    <span class="attr">"comments.date"</span>:    [ <span class="number">30</span> Nov <span class="number">2017</span> ]</span><br><span class="line">  &#125;,</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="attr">"comments.name"</span>:    [ smith ],</span><br><span class="line">    <span class="attr">"comments.comment"</span>: [ good, post, very],</span><br><span class="line">    <span class="attr">"comments.age"</span>:     [ <span class="number">33</span> ],</span><br><span class="line">    <span class="attr">"comments.rating"</span>:   [ <span class="number">7</span> ],</span><br><span class="line">    <span class="attr">"comments.date"</span>:    [ <span class="number">20</span> Nov <span class="number">2017</span> ]</span><br><span class="line">  &#125;,</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="attr">"title"</span>:            [ invest, money ],</span><br><span class="line">    <span class="attr">"body"</span>:             [ as, investing, money, please, soon, start ],</span><br><span class="line">    <span class="attr">"tags"</span>:             [ invest, money ],</span><br><span class="line">    <span class="attr">"published_on"</span>:     [ <span class="number">18</span> Oct <span class="number">2017</span> ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;问题&quot;&gt;&lt;a href=&quot;#问题&quot; class=&quot;headerlink&quot; title=&quot;问题&quot;&gt;&lt;/a&gt;问题&lt;/h1&gt;&lt;figure class=&quot;highlight json&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span c
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="ES" scheme="https://arvenseyz.github.io/tags/ES/"/>
    
  </entry>
  
  <entry>
    <title>mongo的checkpoint和Journaling</title>
    <link href="https://arvenseyz.github.io/2022/03/04/3-4%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>https://arvenseyz.github.io/2022/03/04/3-4技术笔记/</id>
    <published>2022-03-04T07:41:57.000Z</published>
    <updated>2022-03-04T09:07:03.120Z</updated>
    
    <content type="html"><![CDATA[<h1 id="page"><a href="#page" class="headerlink" title="page"></a>page</h1><p>WiredTiger存储引擎里面，磁盘里集合数据和索引都是通过B+ Tree来组织的，但是提供给应用读写的数据都是发生在内存里的，WiredTiger会按需将磁盘的数据以page为单位加载到内存，同时在内存会构造相应的B+ Tree来存储这些数据。应用都是在内存中对Page进行增删改，内存中的Page会利用一些数据结构来记录应用的修改，然后经过reconcile(调和)生成新的Page(基于原Page修改后的Page)，然后等待evict线程将生成的新的Page写到磁盘，并丢弃旧的Page。</p><p>第一步：pages从磁盘读到内存；</p><p>第二步：pages在内存中被修改；</p><p>第三步：被修改的脏pages在内存被reconcile，完成后将discard这些pages。</p><p>第四步：pages被选中，加入淘汰队列，等待被evict线程淘汰出内存；</p><p>第五步：evict线程会将“干净“的pages直接从内存丢弃（因为相对于磁盘page来说没做任何修改），将经过reconcile处理后的磁盘映像写到磁盘再丢弃“脏的”pages。</p><h1 id="checkPoint"><a href="#checkPoint" class="headerlink" title="checkPoint"></a>checkPoint</h1><p>WiredTiger的写操作会默认写入 Cache ,并持久化到 WAL (Write Ahead Log)，每60s或Log文件达到2G做一次 checkpoint (当然我们也可以通过在写入时传入 j: true 的参数强制 journal 文件的同步 ，writeConcern { w: , j: , wtimeout: }) 产生快照文件。WiredTiger初始化时，恢复至最新的快照状态，然后再根据WAL恢复数据，保证数据的完整性。<br>本质上来说，Checkpoint相当于一个日志，记录了上次Checkpoint后相关数据文件的变化。</p><p>checkpoint 中文名为检查点，顾名思义，是检查某一时刻内存和磁盘中的数据状态，即从上一次检查点到现在哪些Page被删除，哪些Page被新建等，可以说是记录了数据库中内存数据相对于上一次检查点的一个快照。当向Disk写入数据时，WiredTiger将Snapshot中的所有数据以一致性方式写入到数据文件（Disk Files）中。一旦Checkpoint创建成功，WiredTiger保证数据文件和内存数据是一致性的，因此，Checkpoint担当的是还原点（Recovery Point），一旦发生系统故障，可以根据检查点恢复出最新一次检查点的状态，然后通过回放从检查点之后的journal日志恢复出断电前的数据。<br>总的来说，Checkpoint主要有两个目的：</p><p>一是将内存里面发生修改的数据写到数据文件进行持久化保存，确保数据一致性；</p><p>二是实现数据库在某个时刻意外发生故障，再次启动时，缩短数据库的恢复时间。</p><p>Checkpoint技术通过在内存中维护一定的数据结构(B+ Tree)，记录应用对数据的改动，即从上次checkpoint到现在的内存页的改动，和要删除的页等，然后通过定时刷新等触发方式，将内存中的Checkpoint 的B+ Tree刷新到磁盘。一旦checkpoint完成，磁盘中数据就和内存数据同步了，checkpoint可以生成新的live Tress来继续记录应用新的改动。</p><h3 id="journal日志"><a href="#journal日志" class="headerlink" title="journal日志"></a>journal日志</h3><p>checkpoint保证了每个检查点之间，内存数据同步到磁盘。但是两个checkpoint时间间隔内的数据也需要保证持久化，这个就要靠journal日志来实现了。</p><p>journal 是顺序写入的二进制日志文件，用于记录上一个Checkpoint之后发生的数据更新，能够将数据库从系统异常终止事件中还原到一个有效的状态。journal日志文件是预分配的，从图6: MongoDB数据目录文件可以看出，journal目录下的文件都是100MB，是预分配好的，可以提高性能。WiredTiger 为每个客户端发起的写操作创建一个日志记录。日志记录包括由初始写入引起的任何内部写入操作。例如，对集合中文档的更新可能会导致对索引的修改；WiredTiger 创建单个日志记录，其中包括文档更新操作及其关联的索引修改。每条日志记录都有一个唯一的标识符，<br>WiredTiger 的最小日志记录大小为 128 字节。MongoDB 将 WiredTiger 配置为使用内存缓冲来存储日志记录。线程协调分配并复制到它们的缓冲区部分，缓冲最大 128 kB 的所有日志记录。当满足以下条件时，journal会被刷入到磁盘中：</p><ul><li><p>每100ms</p></li><li><p>写操作时加了选项<code>{j:true}</code>  </p></li><li><p>当 WiredTiger 创建一个新的日志文件时。由于 MongoDB 使用 100 MB 的日志文件大小限制，WiredTiger 大约每 100 MB 数据创建一个新日志文件。</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;page&quot;&gt;&lt;a href=&quot;#page&quot; class=&quot;headerlink&quot; title=&quot;page&quot;&gt;&lt;/a&gt;page&lt;/h1&gt;&lt;p&gt;WiredTiger存储引擎里面，磁盘里集合数据和索引都是通过B+ Tree来组织的，但是提供给应用读写的数据都是发生在内存
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="mongo" scheme="https://arvenseyz.github.io/tags/mongo/"/>
    
  </entry>
  
  <entry>
    <title>redis与Reactor模式</title>
    <link href="https://arvenseyz.github.io/2022/03/01/3-1%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-2/"/>
    <id>https://arvenseyz.github.io/2022/03/01/3-1技术笔记-2/</id>
    <published>2022-03-01T07:18:04.000Z</published>
    <updated>2022-03-01T09:11:52.004Z</updated>
    
    <content type="html"><![CDATA[<h1 id="同步和阻塞"><a href="#同步和阻塞" class="headerlink" title="同步和阻塞"></a>同步和阻塞</h1><p>很多时候同步和阻塞是同义词，nio这里会分开说，怎么理解</p><p>首先，所有的io分为两步，第一步等待数据，第二步写入数据到输出。</p><p>比如等待打字是第一步，把键盘输入解析处理屏幕显示是第二步。</p><blockquote><p>阻塞：是否阻塞主要体现在调用的线程是否可以干别的，关注的是程序的等待状态</p><p>同步：是否同步体现在<strong>消息通信机制上</strong> 。</p><p>也就是说同步和异步说的是消息的通知机制，阻塞非阻塞说的是线程的状态 。</p></blockquote><p><strong>是否同步的判断依据是:是否针对的是整个过程，也就是2个阶段，是否有阻塞。</strong></p><p><strong>是否阻塞的判断依据是:按程序（线程）等待消息通知时的状态角度来说的，也就是主要是针对第一阶段来说。</strong></p><h1 id="五种IO模型"><a href="#五种IO模型" class="headerlink" title="五种IO模型"></a>五种IO模型</h1><h3 id="bio"><a href="#bio" class="headerlink" title="bio"></a>bio</h3><p>最传统当然是阻塞式的IO，即blocking，BIO</p><p>在这个IO模型中，用户空间的应用程序执行一个系统调用（recvform），这会导致应用程序阻塞，什么也不干，直到数据准备好，等待kernel准备好从网络上接收到的数据报 + 等待收到的报文被从kernel复制到buf中，recvfrom方法才会返回，最后进程再处理数据。</p><p>这就是阻塞式IO模型。</p><p>即起一个线程等待键盘输入（第一步），输入后，处理输出到屏幕（第二步）</p><h3 id="非阻塞式I-O"><a href="#非阻塞式I-O" class="headerlink" title="非阻塞式I/O"></a>非阻塞式I/O</h3><p>优化第一步为轮询，即为非阻塞io。</p><p>非阻塞的recvform系统调用调用之后，进程并没有被阻塞，内核马上返回给进程，如果数据还没准备好，此时会返回一个error。进程在返回之后，可以干点别的事情，然后再发起recvform系统调用。如此循环的进行recvform系统调用，检查内核数据，直到数据准备好，再拷贝数据到进程。<strong>拷贝数据整个过程，进程仍然是属于阻塞的状态</strong>。</p><h3 id="I-O复用"><a href="#I-O复用" class="headerlink" title="I/O复用"></a>I/O复用</h3><p>第一步优化为回调，这样一个线程可以监听多个回调，即为I/O复用</p><p>IO multiplexing就是我们说的select，poll，epoll 。为何叫多路复用，是因为它I/O多路复用可以同时监听多个fd，如此就减少了为每个需要监听的fd开启线程的开销。</p><p>select调用是内核级别的，可以等待多个socket，能实现同时对多个IO端口进行监听<code>，当其中任何一个socket的数据准好了，</code>就能返回进行可读<code>，</code>然后进程再进行recvform系统调用，将数据由内核拷贝到用户进程，这个过程是阻塞的。</p><p>I/O复用模型会用到select、poll、epoll函数，这几个函数也会使进程阻塞，但是和阻塞I/O所不同的的，这几个函数可以同时阻塞多个I/O操作`。而且可以同时对多个读操作，多个写操作的I/O函数进行检测，直到有数据可读或可写时（不是等到socket数据全部到达再处理, 而是有了一部分数据就会调用用户进程来处理），才真正调用I/O操作函数。</p><p>IO复用有人把其成为同步非阻塞的，也有称为同步阻塞。其实这个是否阻塞还需要看第一个阶段，第一个阶段有的阻塞，有的不阻塞。主要也是阻塞在select阶段，属于用户主动等待阶段，我们且规范为阻塞状态，所以，<code>把IO多路复用归为同步阻塞模式</code></p><h2 id="信号驱动式I-O"><a href="#信号驱动式I-O" class="headerlink" title="信号驱动式I/O"></a>信号驱动式I/O</h2><p>等待回调可以再优化，由一个线程阻塞等待，优化为信号驱动，这样监听回调线程也不阻塞。</p><p>信号驱动式I/O：首先我们允许Socket进行信号驱动IO,并安装一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，进程会收到一个SIGIO信号，可以在信号处理函数中调用I/O操作函数处理数据。</p><h3 id="异步I-O"><a href="#异步I-O" class="headerlink" title="异步I/O"></a>异步I/O</h3><p>异步IO不是顺序执行,用户进程进行aio_read系统调用之后，无论内核数据是否准备好，都会直接返回给用户进程，然后用户态进程可以去做别的事情。等到socket数据准备好了，内核直接复制数据给进程，<code>然后从内核向进程发送通知</code>。<code>IO两个阶段，进程都是非阻塞的</code>。</p><p><a href="https://imgtu.com/i/blpGfH" target="_blank" rel="noopener"><img src="https://s4.ax1x.com/2022/03/01/blpGfH.png" alt="blpGfH.png"></a></p><h1 id="Reactor"><a href="#Reactor" class="headerlink" title="Reactor"></a>Reactor</h1><p>Reactor 就是基于NIO中实现多路复用的一种模式</p><h3 id="单线程Reactor模式"><a href="#单线程Reactor模式" class="headerlink" title="单线程Reactor模式"></a>单线程Reactor模式</h3><p><a href="https://imgtu.com/i/bl9d29" target="_blank" rel="noopener"><img src="https://s4.ax1x.com/2022/03/01/bl9d29.jpg" alt="bl9d29.jpg"></a></p><p>如图，即和NIO的描述基本一致。</p><p>只有一个<code>select</code>循环接收请求，客户端（client）注册进来由<code>Reactor</code>接收注册事件，然后再由reactor分发（dispatch）出去，由下面的处理器（Handler）去处理。</p><p>等待数据是阻塞式多路复用，处理输出数据是阻塞式在accepter中。</p><p>单线程的问题实际上是很明显的。只要其中一个Handler方法阻塞了，那就会导致所有的client的Handler都被阻塞了，也会导致注册事件也无法处理，无法接收新的请求。所以这种模式用的比较少，因为不能充分利用到多核的资源。</p><p>这种模式仅仅只能处理Handler比较快速完成的场景。</p><p>实际上5.0及其以前的redis就是这个模式，因为redis的handler的确能快速完成。</p><p>IO多路复用程序接收到用户的请求后，全部推送到一个队列里，交给文件分派器。对于后续的操作，和在 reactor 单线程实现方案里看到的一样，整个过程都在一个线程里完成，因此 Redis 被称为是单线程的操作。</p><p><a href="https://imgtu.com/i/blPn6s" target="_blank" rel="noopener"><img src="https://s4.ax1x.com/2022/03/01/blPn6s.png" alt="blPn6s.png"></a></p><h3 id="Reactor模式-工作者线程池模式"><a href="#Reactor模式-工作者线程池模式" class="headerlink" title="Reactor模式-工作者线程池模式"></a>Reactor模式-工作者线程池模式</h3><p>我们应该将非I/O的业务逻辑操作从Reactor线程上卸载，以此来加速Reactor线程对I/O请求的响应。与单线程模式不同的是，添加了一个<strong>工作者线程池</strong>，并将非I/O操作从Reactor线程中移出转交给工作者线程池（Thread Pool）来执行。这样能够提高Reactor线程的I/O响应，不至于因为一些耗时的业务逻辑而延迟对后面I/O请求的处理。</p><p><a href="https://imgtu.com/i/blCeqx" target="_blank" rel="noopener"><img src="https://s4.ax1x.com/2022/03/01/blCeqx.png" alt="blCeqx.png"></a></p><p>6.0之后的redis即为该模式</p><p>在 Redis 中，单线程的性能瓶颈主要在网络IO操作上。也就是在读写网络 read/write 系统调用执行期间会占用大部分 CPU 时间。如果你要对一些大的键值对进行删除操作的话，在短时间内是删不完的，那么对于单线程来说就会阻塞后边的操作。</p><p>好像其实不是标准的工作者线程池模式</p><p>多线程大部分逻辑和之前的单线程模型是一致的，变动的地方仅仅是把读取客户端请求命令和回写响应数据的逻辑异步化了，交给 I/O 线程去完成，这里需要特别注意的一点是：<strong>I/O 线程仅仅是读取和解析客户端命令而不会真正去执行命令，客户端命令的执行最终还是要在主线程上完成</strong>。</p><p>Redis 把处理逻辑交还给 Master 线程，虽然一定程度上增加了模型复杂度，但也解决了线程并发安全等问题。</p><p><a href="https://imgtu.com/i/blkuXd" target="_blank" rel="noopener"><img src="https://s4.ax1x.com/2022/03/01/blkuXd.png" alt="blkuXd.png"></a></p><h3 id="多Reactor多线程模型"><a href="#多Reactor多线程模型" class="headerlink" title="多Reactor多线程模型"></a>多Reactor多线程模型</h3><p>是将Reactor分成两部分，</p><blockquote><ol><li><p>mainReactor负责监听server socket，用来处理新连接的建立，将建立的socketChannel指定注册给subReactor。</p></li><li><p>subReactor维护自己的selector, 基于mainReactor 注册的socketChannel多路分离IO读写事件，读写网 络数据，对业务处理的功能，另其扔给worker线程池来完成。</p></li></ol></blockquote><p>mainReactor 主要是用来处理网络IO 连接建立操作，通常一个线程就可以处理，而subReactor主要做和建立起来的socket做数据交互和事件业务处理操作，它的个数上一般是和CPU个数等同，每个subReactor一个线程来处理。</p><p>nginx和netty应该是使用这种模式</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;同步和阻塞&quot;&gt;&lt;a href=&quot;#同步和阻塞&quot; class=&quot;headerlink&quot; title=&quot;同步和阻塞&quot;&gt;&lt;/a&gt;同步和阻塞&lt;/h1&gt;&lt;p&gt;很多时候同步和阻塞是同义词，nio这里会分开说，怎么理解&lt;/p&gt;
&lt;p&gt;首先，所有的io分为两步，第一步等待数据，第
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="redis" scheme="https://arvenseyz.github.io/tags/redis/"/>
    
      <category term="计算机网络" scheme="https://arvenseyz.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>12306跨站卖票设计</title>
    <link href="https://arvenseyz.github.io/2022/03/01/3-1%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>https://arvenseyz.github.io/2022/03/01/3-1技术笔记-1/</id>
    <published>2022-03-01T03:14:24.000Z</published>
    <updated>2022-03-01T03:20:58.853Z</updated>
    
    <content type="html"><![CDATA[<p>我们以北京到西安这趟高铁为例，比如我的路线就是从北京到西安，车上如果只剩最后一张票了，那么如果有其他人，在北京到西安这条路线之间买任何一站，那么我都是买不了票的，换句话说，对于单个座位来说，必须是起点到目的地之间的所有站，都没有人买的话，那么才能被算是有票状态。</p><p>所以我们可以尝试用bitmap结合上位操作来实现这种场景，以上述北京到西安为例，我们把问题简化</p><ul><li><p>比如一个火车上只有4个座位</p></li><li><p>北京到西安，一共是4站，其实是三个区间的，分别为北京-&gt;石家庄，石家庄-&gt;郑州，郑州-&gt;西安</p></li></ul><h4 id="首先我们给每个区间构建一个空位图-0为有票，1为无票"><a href="#首先我们给每个区间构建一个空位图-0为有票，1为无票" class="headerlink" title="首先我们给每个区间构建一个空位图(0为有票，1为无票)"></a>首先我们给每个区间构建一个空位图(0为有票，1为无票)</h4><table><thead><tr><th>区间</th><th>1</th><th>2</th><th>3</th><th>4</th></tr></thead><tbody><tr><td>北京-深圳</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>深圳-郑州</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>郑州-西安</td><td>0</td><td>0</td><td>0</td><td>0</td></tr></tbody></table><h4 id="接下来，比如有人买了一张从北京到西安的票"><a href="#接下来，比如有人买了一张从北京到西安的票" class="headerlink" title="接下来，比如有人买了一张从北京到西安的票"></a>接下来，比如有人买了一张从北京到西安的票</h4><p>买票这个动作，比如被分配到的座位是编号为1的座位，那么我们直接把北京到西安的所有站，1号座位全部设置为1</p><table><thead><tr><th>区间</th><th>1</th><th>2</th><th>3</th><th>4</th></tr></thead><tbody><tr><td>北京-石家庄</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>石家庄-郑州</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>郑州-西安</td><td>1</td><td>0</td><td>0</td><td>0</td></tr></tbody></table><h4 id="接下来又有人买了一张从石家庄到西安的票"><a href="#接下来又有人买了一张从石家庄到西安的票" class="headerlink" title="接下来又有人买了一张从石家庄到西安的票"></a>接下来又有人买了一张从石家庄到西安的票</h4><p>比如这次分配的是座位2，那么我们把石家庄到西安的所有票全部设置为1就行了，如下图</p><table><thead><tr><th>区间</th><th>1</th><th>2</th><th>3</th><th>4</th></tr></thead><tbody><tr><td>北京-石家庄</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>石家庄-郑州</td><td>1</td><td>1</td><td>0</td><td>0</td></tr><tr><td>郑州-西安</td><td>1</td><td>1</td><td>0</td><td>0</td></tr></tbody></table><h4 id="如何知道还剩几张票？"><a href="#如何知道还剩几张票？" class="headerlink" title="如何知道还剩几张票？"></a>如何知道还剩几张票？</h4><p>其实解决这个问题很简单，我们直接把上述位图做一个或操作就可以了</p><table><thead><tr><th>区间</th><th>1</th><th>2</th><th>3</th><th>4</th></tr></thead><tbody><tr><td>北京-石家庄</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>石家庄-郑州</td><td>1</td><td>1</td><td>0</td><td>0</td></tr><tr><td>郑州-西安</td><td>1</td><td>1</td><td>0</td><td>0</td></tr><tr><td>或操作结果</td><td>1</td><td>1</td><td>0</td><td>0</td></tr></tbody></table><p>或操作结果有几个0，则说明还剩几张票。</p><p>其实解决这个问题主要在于位图的构建，因为火车票对于某一个座位来说，只要起点到终点中间某一个区间被占用了(置为1)，那么整个座位都是无效的这个特点，很容易想到用或操作的结果来判断买票结果，我们这里只用了4位是为了方便说明问题，实际中应该是火车上有多少座位，位图的长度就应该是多少</p><p>作者：程序员小饭<br>链接：<a href="https://juejin.cn/post/7012507519595577375" target="_blank" rel="noopener">https://juejin.cn/post/7012507519595577375</a><br>来源：稀土掘金<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;我们以北京到西安这趟高铁为例，比如我的路线就是从北京到西安，车上如果只剩最后一张票了，那么如果有其他人，在北京到西安这条路线之间买任何一站，那么我都是买不了票的，换句话说，对于单个座位来说，必须是起点到目的地之间的所有站，都没有人买的话，那么才能被算是有票状态。&lt;/p&gt;
&lt;
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="系统设计" scheme="https://arvenseyz.github.io/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>短链系统设计</title>
    <link href="https://arvenseyz.github.io/2022/02/28/2-28%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>https://arvenseyz.github.io/2022/02/28/2-28技术笔记-1/</id>
    <published>2022-02-28T06:09:59.000Z</published>
    <updated>2022-02-28T07:22:05.656Z</updated>
    
    <content type="html"><![CDATA[<h1 id="编码"><a href="#编码" class="headerlink" title="编码"></a>编码</h1><p>首先是短链怎么生成。</p><p>一个想法是id生成器，但是id生成首先需要考虑的是单点故障问题，优秀的id生成器应该是分布式发号器，每个生成器先从中央协调器（例如ZooKeeper）保留一块id序列，这些id生成器可以单独从他们的id序列中分配id，有必要的时候在自己的id序列中做一些清理。</p><p>另一个想法是哈希，比如md5，但是哈希的问题是冲突，当发生哈希冲突了，意味着两个长链接对应的短链是一样的，解决冲突的办法可以是布隆过滤器（一定不存在，可能存在），如果冲突了，需要重新编码，比如说再拼接一段特殊字符再编码，解码时取消掉即可。另外就是没必要使用加密型的哈希算法， 可以使用<strong>MurmurHash</strong>这种非加密的，好处是速度快。</p><h1 id="存储"><a href="#存储" class="headerlink" title="存储"></a>存储</h1><p>短链很多，存储压力较大，一个简便的分布式系存储比如mongo的确可以满足需要，但是考虑到使用场景，可能可以自动清理过期的。</p><h1 id="跳转"><a href="#跳转" class="headerlink" title="跳转"></a>跳转</h1><blockquote><p>301，代表 永久重定向，也就是说第一次请求拿到长链接后，下次浏览器再去请求短链的话，不会向短网址服务器请求了，而是直接从浏览器的缓存里拿，这样在 server 层面就无法获取到短网址的点击数了，如果这个链接刚好是某个活动的链接，也就无法分析此活动的效果。所以我们一般不采用 301。</p><p> 302，代表 临时重定向，也就是说每次去请求短链都会去请求短网址服务器（除非响应中用 Cache-Control 或 Expired 暗示浏览器缓存）,这样就便于 server 统计点击数，所以虽然用 302 会给 server 增加一点压力，但在数据异常重要的今天，这点代码是值得的，所以推荐使用 302！</p></blockquote><p>实际上可以直接跳过服务端，使用openResty等的HTTP服务器插件，前端直接访问数据库</p><h1 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h1><p>由几个不同部分去做这件事情生成访问流数据，收集整理，每过一段时间写到永久数据库中，用一个延迟较低的信息系统去暂时存储访问数据，然后将数据交给收集整理部分，面试者可能会问访问数据多久需要被更新一次。如果每天更新，一个比较合理的方法是存储在HDFS，用map/reduce去计算数据。 如果是要近乎实时的数据，收集整理的部分就要计算出所需的数据</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;编码&quot;&gt;&lt;a href=&quot;#编码&quot; class=&quot;headerlink&quot; title=&quot;编码&quot;&gt;&lt;/a&gt;编码&lt;/h1&gt;&lt;p&gt;首先是短链怎么生成。&lt;/p&gt;
&lt;p&gt;一个想法是id生成器，但是id生成首先需要考虑的是单点故障问题，优秀的id生成器应该是分布式发号器，每个
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="系统设计" scheme="https://arvenseyz.github.io/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>红包技术设计</title>
    <link href="https://arvenseyz.github.io/2022/02/25/2-25%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-2/"/>
    <id>https://arvenseyz.github.io/2022/02/25/2-25技术笔记-2/</id>
    <published>2022-02-25T07:41:01.000Z</published>
    <updated>2022-02-25T08:26:08.876Z</updated>
    
    <content type="html"><![CDATA[<p>红包是一种秒杀，秒杀的难点就是锁库存，大量用户同时“秒杀”同一商品时，第一个到达 DB 的请求锁住了这行库存记录。在第一个事务完成提交之前这个锁一直被第一个请求占用，后面的所有请求需要排队等待。同时参与“秒杀”的用户越多，并发进 DB 的请求越多，请求排队越严重。因此，并发请求抢锁，是典型的商品“秒杀”系统的设计难点。</p><p>一般有两个思路，第一个是秒杀不锁库存，在内存/redis维护一个库存，这样就不用锁库存，直接在内存/redis原子操作扣减，秒杀结束后再持久化。</p><p>第二个是用乐观锁，乐观锁抢锁失败直接返回用户秒杀失败即可。</p><p>这两个思路都不适合红包</p><p>对红包来说，一个能降低库存的压力的办法是分表，即不同的红包在不同的表。因为红包没有热点商品，这个是可以的。还可以按时间再分，这样红包表也不大。</p><p>第二是串行化时机提前，在服务端维护先进先出的队列串行化，请求量过大直接返回。</p><p>还有个策略是server也切分，这样server和db对应，好处是故障隔离，如果DB error了，直接屏蔽红包号段。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;红包是一种秒杀，秒杀的难点就是锁库存，大量用户同时“秒杀”同一商品时，第一个到达 DB 的请求锁住了这行库存记录。在第一个事务完成提交之前这个锁一直被第一个请求占用，后面的所有请求需要排队等待。同时参与“秒杀”的用户越多，并发进 DB 的请求越多，请求排队越严重。因此，并发
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="系统设计" scheme="https://arvenseyz.github.io/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>feed流设计</title>
    <link href="https://arvenseyz.github.io/2022/02/23/2-22%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>https://arvenseyz.github.io/2022/02/23/2-22技术笔记-1/</id>
    <published>2022-02-23T07:24:58.000Z</published>
    <updated>2022-02-23T08:11:56.558Z</updated>
    
    <content type="html"><![CDATA[<p>feed流有两种，一种是我关注的人/我好友的，比如说朋友圈，另一种是推荐的，比如头条。</p><p>这里看第一种。</p><h2 id="推拉模式"><a href="#推拉模式" class="headerlink" title="推拉模式"></a>推拉模式</h2><p>简单想到的实现方式就是，每一个内容发布者都有一个自己的发件箱，第一步加载用户所有好友，第二步加载这些好友的所有内容。即拉模式，读扩散。</p><p>这个模式有两个问题，第一是性能问题，关注的人数非常多时性能有问题。第二是业务问题，翻页时有问题。</p><p>有拉就有推，即每个用户都有个收件箱，当发布者发表一篇帖子的时候，除了往自己发件箱记录一下之外，还会遍历发布者的所有粉丝，往这些粉丝的收件箱也投放一份相同内容。这样阅读者来读Feed流时，直接从自己的收件箱读取即可。</p><p>比较适合朋友圈这种场景。比如微博，有人一亿粉丝，这种模式肯定用不了。</p><p>其实这种模式可以混合，粉丝量很少的人，可以用推模式。粉丝量多的人，只推给活跃粉丝。</p><p>非活跃粉丝刷feed流时，一方面要读自己的收件箱，另一方面也要拉关注的大v的发件箱。</p><h2 id="分页问题"><a href="#分页问题" class="headerlink" title="分页问题"></a>分页问题</h2><p>即加载第二页时，由于按时间排的，有新的内容导致第一页的内容被挤到第二页，这样又看见第一页的内容。</p><p>比较简单的方法是，加一个last_id</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;feed流有两种，一种是我关注的人/我好友的，比如说朋友圈，另一种是推荐的，比如头条。&lt;/p&gt;
&lt;p&gt;这里看第一种。&lt;/p&gt;
&lt;h2 id=&quot;推拉模式&quot;&gt;&lt;a href=&quot;#推拉模式&quot; class=&quot;headerlink&quot; title=&quot;推拉模式&quot;&gt;&lt;/a&gt;推拉模式&lt;/h2
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="系统设计" scheme="https://arvenseyz.github.io/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>Redis数据倾斜</title>
    <link href="https://arvenseyz.github.io/2022/02/21/2-21%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>https://arvenseyz.github.io/2022/02/21/2-21技术笔记-1/</id>
    <published>2022-02-21T08:46:56.000Z</published>
    <updated>2022-02-21T09:03:44.553Z</updated>
    
    <content type="html"><![CDATA[<p>热点读场景，某个热点帖子内容这样，所有的访问量都打到了redis一个实例。单实例压力过大。（我怀疑这种场景真的存在吗？redis单机读取qps能承受万级别）</p><p>产生原因：redis 根据key进行分片计算，分配到redis实例中的一个，导致大部分流量集中访问到同一个redis实例上，即所谓的“访问量倾斜”，导致redis实例达到性能瓶颈</p><p>解决方案：给hotkey加上后缀，把hotkey数量变成redis实例数N的倍数M，从而由访问一个redis key变成访问N*M个redis key</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//redis 实例数</span></span><br><span class="line"><span class="keyword">const</span> M = <span class="number">16</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//redis 实例数倍数（按需设计，2^n倍，n一般为1到4的整数）</span></span><br><span class="line"><span class="keyword">const</span> N = <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="comment">//获取 redis 实例 </span></span><br><span class="line">    c, err := redis.Dial(<span class="string">"tcp"</span>, <span class="string">"127.0.0.1:6379"</span>)</span><br><span class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">        fmt.Println(<span class="string">"Connect to redis error"</span>, err)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">defer</span> c.Close()</span><br><span class="line"></span><br><span class="line">    hotKey := <span class="string">"hotKey:abc"</span></span><br><span class="line">    <span class="comment">//随机数</span></span><br><span class="line">    randNum := GenerateRangeNum(<span class="number">1</span>, N*M)</span><br><span class="line">    <span class="comment">//得到对 hot key 进行打散的 key</span></span><br><span class="line">    tmpHotKey := hotKey + <span class="string">"_"</span> + strconv.Itoa(randNum)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//hot key 过期时间</span></span><br><span class="line">    expireTime := <span class="number">50</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">//过期时间平缓化的一个时间随机值</span></span><br><span class="line">    randExpireTime := GenerateRangeNum(<span class="number">0</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    data, err := redis.String(c.Do(<span class="string">"GET"</span>, tmpHotKey))</span><br><span class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">        data, err = redis.String(c.Do(<span class="string">"GET"</span>, hotKey))</span><br><span class="line">        <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">            data = GetDataFromDb()</span><br><span class="line">            c.Do(<span class="string">"SET"</span>, <span class="string">"hotKey"</span>, data, expireTime)</span><br><span class="line">            c.Do(<span class="string">"SET"</span>, tmpHotKey, data, expireTime + randExpireTime)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            c.Do(<span class="string">"SET"</span>, tmpHotKey, data, expireTime + randExpireTime)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;热点读场景，某个热点帖子内容这样，所有的访问量都打到了redis一个实例。单实例压力过大。（我怀疑这种场景真的存在吗？redis单机读取qps能承受万级别）&lt;/p&gt;
&lt;p&gt;产生原因：redis 根据key进行分片计算，分配到redis实例中的一个，导致大部分流量集中访问到同
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="redis" scheme="https://arvenseyz.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>RocketMQ 消息存储</title>
    <link href="https://arvenseyz.github.io/2021/12/14/12-14%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>https://arvenseyz.github.io/2021/12/14/12-14技术笔记-1/</id>
    <published>2021-12-14T09:04:05.000Z</published>
    <updated>2021-12-14T09:55:12.164Z</updated>
    
    <content type="html"><![CDATA[<h2 id="先回顾下kafka"><a href="#先回顾下kafka" class="headerlink" title="先回顾下kafka"></a>先回顾下kafka</h2><p><img src="https://cdn.jsdelivr.net/gh/arvenseyz/imageCloud/2a57c077-1ae2-460d-be0b-168329058e70.png" alt></p><p>Kafka 以 Topic 作为文件存储的基本单元，即每个 Topic 有其对应的数据文件和索引文件。消息直接存储在partition中，对单topic为顺序写。</p><p>这样预期结果是，磁盘顺序写+顺序读，性能很好。</p><p>但问题是，是分topic的，如果topic很多，要不停的切topic，顺序读写就被破坏了，降低了性能。</p><h2 id="RocketMQ-消息存储"><a href="#RocketMQ-消息存储" class="headerlink" title="RocketMQ 消息存储"></a>RocketMQ 消息存储</h2><p><img src="https://cdn.jsdelivr.net/gh/arvenseyz/imageCloud/d27e7402-138b-4654-9bed-1da9175417a1.png" alt></p><p>RocketMQ 既然号称能支持万级别topic，肯定不是kafka这么存的。</p><p>首先是存储上不分topic，所以这些topic的内容写在一块的。即CommitLog。</p><p>那既然不同topic，内容在一块，怎么读呢，答案是加一个索引，同时，由于消息仍需要以 Topic 为维度进行消费，因此 RocketMQ 基于 CommitLog 为每个 Topic 异步构建多个逻辑队列（ConsumeQueue），逻辑队列消息是定长的，因为只有表头，存储了这个Queue在CommiLog中的起始offset，log大小和MessageTag的hashCode。</p><p>既然是定长的，根据offset，就能找到消息在ConsumeQueue中的位置，然后再读到在CommiLog中的起始offset，最后从CommiLog读到消息内容。</p><p>消息存储只是把消息主体存储到了物理文件中，但是并没有把消息处理到consumeQueue文件中，那么到底是哪里存入的？答案是起一个线程，不停的轮询，将当前的consumeQueue中的offSet和commitLog中的offSet进行对比，将多出来的offSet进行解析，然后put到consumeQueue中的MapedFile中。</p><p>另外还有个index文件</p><p>index文件是为搜索场景而生的，如果没有搜索业务需求，则这个实现是意义不大的。一般这种搜索，主要用于后台查询验证类使用，或者有其他同的有妙用，不得而知。总之，一切为搜索。它更多的需要借助于时间限定，以key或者id进行查询。</p><p>　那么，如果要查找一个key, 应当如何查找呢？rocketmq会根据时间段找到一个index索引分版，然后再根据key做hash得到一个值，然后定位到 slotValue . 然后再从slotValue去取出索引数据的地址，找到索引数据，然后再回查 commitlog 文件。从而得到具体的消息数据。也就是，相当于搜索经历了四级查询： 索引分片文件查询 -&gt; slotValue 查询 -&gt; 索引数据查询 -&gt; commitlog 查询 。</p><p>看起来比较复杂，但搜索场景毕竟不多。</p><h2 id="RocketMQ-优缺点"><a href="#RocketMQ-优缺点" class="headerlink" title="RocketMQ 优缺点"></a>RocketMQ 优缺点</h2><p>上面的流程，优点是什么呢？</p><p>除了支持多topic外，因为consumequeue数据量小，绝大部分的访问还是Page Cache的访问，而不是磁盘访问。  </p><p>正式部署也可以将CommitLog和consumerQueue放在不同的物理SSD，避免多类文件进行IO竞争。  </p><p>缺点:</p><p>读取消息时，由于不同的topic消息都写在同一个文件，导致读取顺序不连续，造成随机读，降低了读IO。</p><h2 id="怎么降低缺点影响"><a href="#怎么降低缺点影响" class="headerlink" title="怎么降低缺点影响"></a>怎么降低缺点影响</h2><p>（硬件上的原因，缺点似乎不存在了，现在都是ssd，ssd随机读性能很好）</p><h3 id="Mmap"><a href="#Mmap" class="headerlink" title="Mmap"></a>Mmap</h3><p>Mmap内存映射和普通标准IO操作的本质区别在于它并不需要将文件中的数据先拷贝至OS的内核IO缓冲区，而是可以直接将用户进程私有地址空间中的一块区域与文件对象建立映射关系，这样程序就好像可以直接从内存中完成对文件读/写操作一样。只有当缺页中断发生时，直接将文件从磁盘拷贝至用户态的进程空间内，只进行了一次数据拷贝。对于容量较大的文件来说(文件大小一般需要限制在1.5~2G以下)，采用Mmap的方式其读/写的效率和性能都非常高。<br><em>JDK NIO</em>提供的MappedByteBuffer底层就是调用<em>mmap</em>来实现的</p><h3 id="PageCache机制"><a href="#PageCache机制" class="headerlink" title="PageCache机制"></a>PageCache机制</h3><p>PageCache是OS对文件的缓存，用于加速对文件的读写。一般来说，程序对文件进行顺序读写的速度几乎接近于内存的读写访问，这里的主要原因就是在于OS使用PageCache机制对读写访问操作进行了性能优化，将一部分的内存用作PageCache。(1)对于数据文件的读取，如果一次读取文件时出现未命中PageCache的情况，OS从物理磁盘上访问读取文件的同时，会顺序对其他相邻块的数据文件进行预读取(ps：顺序读入紧随其后的少数几个页面)。这样，只要下次访问的文件已经被加载至PageCache时，读取操作的速度基本等于访问内存。(2)对于数据文件的写入，OS会先写入至Cache内，随后通过异步的方式由pdflush内核线程将Cache内的数据刷盘至物理磁盘上。对于文件的顺序读写操作来说，读和写的区域都在OS的PageCache内，此时读写性能接近于内存。RocketMQ的大致做法是，将数据文件映射到OS的虚拟内存中(通过JDK NIO的MappedByteBuffer)，写消息的时候首先写入PageCache，并通过异步刷盘的方式将消息批量的做持久化(同时也支持同步刷盘)；订阅消费消息时(对CommitLog操作是随机读取)，由于PageCache的局部性热点原理且整体情况下还是从旧到新的有序读，因此大部分情况下消息还是可以直接从Page Cache中读取，不会产生太多的缺页(Page Fault)中断而从磁盘读取。</p><h4 id="预先分配MappedFile"><a href="#预先分配MappedFile" class="headerlink" title="预先分配MappedFile"></a>预先分配MappedFile</h4><p>在消息写入过程中(调用CommitLog的putMessage()方法)，CommitLog会先从MappedFileQueue队列中获取一个 MappedFile，如果没有就新建一个。这里，MappedFile的创建过程是将构建好的一个AllocateRequest请求(具体做法是，将下一个文件的路径、下下个文件的路径、文件大小为参数封装为AllocateRequest对象)添加至队列中，后台运行的AllocateMappedFileService服务线程(在Broker启动时，该线程就会创建并运行)，会不停地run，只要请求队列里存在请求，就会去执行MappedFile映射文件的创建和预分配工作，分配的时候有两种策略，一种是使用Mmap的方式来构建MappedFile实例，另外一种是从TransientStorePool堆外内存池中获取相应的DirectByteBuffer来构建MappedFile(ps：具体采用哪种策略，也与刷盘的方式有关)。并且，在创建分配完下个MappedFile后，还会将下下个MappedFile预先创建并保存至请求队列中等待下次获取时直接返回。RocketMQ中预分配MappedFile的设计非常巧妙，下次获取时候直接返回就可以不用等待MappedFile创建分配所产生的时间延迟。</p><h4 id="文件预热-amp-amp-mlock系统调用"><a href="#文件预热-amp-amp-mlock系统调用" class="headerlink" title="文件预热&amp;&amp;mlock系统调用"></a>文件预热&amp;&amp;mlock系统调用</h4><p>(1)mlock系统调用：其可以将进程使用的部分或者全部的地址空间锁定在物理内存中，防止其被交换到swap空间。对于RocketMQ这种的高吞吐量的分布式消息队列来说，追求的是消息读写低延迟，那么肯定希望尽可能地多使用物理内存，提高数据读写访问的操作效率。</p><p>(2)文件预热：预热的目的主要有两点；第一点，由于仅分配内存并进行mlock系统调用后并不会为程序完全锁定这些内存，因为其中的分页可能是写时复制的。因此，就有必要对每个内存页面中写入一个假的值。其中，RocketMQ是在创建并分配MappedFile的过程中，预先写入一些随机值至Mmap映射出的内存空间里。第二，调用Mmap进行内存映射后，OS只是建立虚拟内存地址至物理地址的映射表，而实际并没有加载任何文件至内存中。程序要访问数据时OS会检查该部分的分页是否已经在内存中，如果不在，则发出一次缺页中断。这里，可以想象下1G的CommitLog需要发生多少次缺页中断，才能使得对应的数据才能完全加载至物理内存中(ps：X86的Linux中一个标准页面大小是4KB)？RocketMQ的做法是，在做Mmap内存映射的同时进行madvise系统调用，目的是使OS做一次内存映射后对应的文件数据尽可能多的预加载至内存中，从而达到内存预热的效果。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;先回顾下kafka&quot;&gt;&lt;a href=&quot;#先回顾下kafka&quot; class=&quot;headerlink&quot; title=&quot;先回顾下kafka&quot;&gt;&lt;/a&gt;先回顾下kafka&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/arve
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="消息队列" scheme="https://arvenseyz.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>RocketMQ 推和拉</title>
    <link href="https://arvenseyz.github.io/2021/12/13/12-13%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0-1/"/>
    <id>https://arvenseyz.github.io/2021/12/13/12-13技术笔记-1/</id>
    <published>2021-12-13T06:48:17.000Z</published>
    <updated>2021-12-15T06:09:12.389Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是推和拉"><a href="#什么是推和拉" class="headerlink" title="什么是推和拉"></a>什么是推和拉</h2><p>说到推拉，其实只针对消费者和broker的行为，生产者只有推（不然生产者岂不是还得把消息持久化等着broker来取数据）。</p><p><strong>推模式</strong>指的是consumer与broker建立好网络长连接，broker有相关数据，直接通过长连接通道推送到consumer。其优点是及时，一旦有数据变更，consumer立马能感知到；另外对consumer来说逻辑简单，不需要关心有无数据这些逻辑处理。缺点是不知道consumer的数据消费能力，可能导致数据积压在consumer，来不及处理。</p><p><strong>拉模式</strong>指的是consumer主动向broker发出请求，拉取相关数据。其优点是此过程由consumer发起请求，故不存在推模式中数据积压的问题。缺点是可能不够及时，对consumer来说需要考虑数据拉取相关逻辑，何时去拉，拉的频率怎么控制等等。</p><h2 id="RocketMq的推拉"><a href="#RocketMq的推拉" class="headerlink" title="RocketMq的推拉"></a>RocketMq的推拉</h2><p>RocketMq其实只有拉。</p><p>推是帮填了些参数的拉。consumer把轮询过程封装了，并注册MessageListener监听器，取到消息后，唤醒MessageListener的consumeMessage()来消费，对用户而言，感觉消息是被推送（push）过来的。主要用的也是这种方式。</p><p>如果是拉的话，客户端代码可能得这么写：</p><ol><li><p>注册消费者实例到nameserver</p></li><li><p>查询对应的topic消息队列以便可以消费其下所有数据</p></li><li><p>获取消息队列，消费消息;</p></li><li><p>自行维护保存消费偏移量，以便为下一次消费提供依据;</p></li><li><p>循环以上操作;</p></li></ol><p>可以看见还是比较麻烦。推的话，只需要注册回调方法即可。</p><h3 id="推是用拉-长轮询实现"><a href="#推是用拉-长轮询实现" class="headerlink" title="推是用拉+长轮询实现"></a>推是用拉+长轮询实现</h3><p>后台会有个 RebalanceService 线程，这个线程会根据 topic 的队列数量和当前消费组的消费者个数做负载均衡，每个队列产生的 pullRequest 放入阻塞队列 pullRequestQueue 中。然后又有个 PullMessageService 线程不断的从阻塞队列 pullRequestQueue 中获取 pullRequest，然后通过网络请求 broker，这样实现的准实时拉取消息。</p><p>上面操作相当于帮做了拉的1、2步</p><p>具体怎么长轮询拉的呢</p><p><img src="https://cdn.jsdelivr.net/gh/arvenseyz/imageCloud/9182641-667ee972d01888f3.webp" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;什么是推和拉&quot;&gt;&lt;a href=&quot;#什么是推和拉&quot; class=&quot;headerlink&quot; title=&quot;什么是推和拉&quot;&gt;&lt;/a&gt;什么是推和拉&lt;/h2&gt;&lt;p&gt;说到推拉，其实只针对消费者和broker的行为，生产者只有推（不然生产者岂不是还得把消息持久化等着broke
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="消息队列" scheme="https://arvenseyz.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>RocketMQ Rebalance机制</title>
    <link href="https://arvenseyz.github.io/2021/12/10/12-10%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/"/>
    <id>https://arvenseyz.github.io/2021/12/10/12-10技术笔记/</id>
    <published>2021-12-10T06:51:50.000Z</published>
    <updated>2021-12-13T03:30:58.392Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Rebalance是什么"><a href="#Rebalance是什么" class="headerlink" title="Rebalance是什么"></a><strong>Rebalance是什么</strong></h1><p>Rebalance(再均衡)机制指的是：将一个Topic下的<strong>多个队列(或称之为分区)</strong>，在同一个消费者组(consumer group)下的<strong>多个消费者实例</strong>(consumer instance)之间进行重新分配。</p><p><strong>Rebalance机制本意是为了提升消息的并行处理能力。</strong>例如，一个Topic下5个队列，在只有1个消费者的情况下，那么这个消费者将负责处理这5个队列的消息。如果此时我们增加一个消费者，那么可以给其中一个消费者分配2个队列，给另一个分配3个队列，从而提升消息的并行处理能力。</p><p>但是Rebalance机制也存在明显的<strong>限制</strong>与<strong>危害</strong>。</p><p><strong>Rebalance限制：</strong></p><p>由于一个队列最多分配给一个消费者，因此当某个消费者组下的消费者实例数量大于队列的数量时，多余的消费者实例将分配不到任何队列。</p><p><strong>Rebalance危害：</strong></p><p>除了以上限制，更加严重的是，在发生Rebalance时，存在着一些危害，如下所述：</p><ul><li><strong>消费暂停：</strong>考虑在只有Consumer 1的情况下，其负责消费所有5个队列；在新增Consumer 2，触发Rebalance时，需要分配2个队列给其消费。那么Consumer 1就需要停止这2个队列的消费，等到这两个队列分配给Consumer 2后，这两个队列才能继续被消费。</li><li><strong>重复消费：</strong>Consumer 2 在消费分配给自己的2个队列时，必须接着从Consumer 1之前已经消费到的offset继续开始消费。然而默认情况下，offset是异步提交的，如consumer 1当前消费到offset为10，但是异步提交给broker的offset为8；那么如果consumer 2从8的offset开始消费，那么就会有2条消息重复。也就是说，Consumer 2 并不会等待Consumer1提交完offset后，再进行Rebalance，因此提交间隔越长，可能造成的重复消费就越多。</li><li><strong>消费突刺：</strong>由于rebalance可能导致重复消费，如果需要重复消费的消息过多；或者因为rebalance暂停时间过长，导致积压了部分消息。那么都有可能导致在rebalance结束之后瞬间可能需要消费很多消息。</li></ul><h1 id="什么时候Reblance"><a href="#什么时候Reblance" class="headerlink" title="什么时候Reblance"></a>什么时候Reblance</h1><p>从本质上来说，触发Rebalance的根本因素无非是两个：</p><p><strong>1. 订阅Topic的队列数量变化</strong> </p><p><strong>2. 消费者组信息变化。</strong> </p><p><strong>队列信息</strong>和<strong>消费者组信息</strong>称之为Rebalance元数据，Broker负责维护这些元数据，并在二者信息发生变化时，以某种通知机制告诉消费者组下所有实例，需要进行Rebalance。从这个角度来说，Broker在Rebalance过程中，是一个协调者的角色。</p><h1 id="怎么reblance"><a href="#怎么reblance" class="headerlink" title="怎么reblance"></a>怎么reblance</h1><p>Broker是通知每个消费者各自Rebalance，即每个消费者自己给自己重新分配队列，而不是Broker将分配好的结果告知Consumer。从这个角度，RocketMQ与Kafka Rebalance机制类似，二者Rebalance分配都是在客户端进行，不同的是：</p><ul><li><strong>Kafka：</strong>会在消费者组的多个消费者实例中，选出一个作为Group Leader，由这个Group Leader来进行分区分配，分配结果通过Cordinator(特殊角色的broker)同步给其他消费者。相当于Kafka的分区分配只有一个大脑，就是Group Leader。</li><li><strong>RocketMQ：</strong>每个消费者，自己负责给自己分配队列，相当于每个消费者都是一个大脑。</li></ul><p>如果RocketMQ是去中心化的，必然有如下两个问题：</p><ol><li><p>脑裂：因为每个消费者都不知道其他消费者分配的结果，会不会出现一个队列分配给了多个消费者，或者有的队列分配给了多个消费者。</p></li><li><p>如果某个消费者没有收到Rebalance通知怎么办</p></li></ol><p><strong>只要任意一个消费者组需要Rebalance，这台机器上启动的所有其他消费者，也都要进行Rebalance</strong>。</p><h2 id="单个Topic-Rebalance流程"><a href="#单个Topic-Rebalance流程" class="headerlink" title="单个Topic Rebalance流程"></a><strong>单个Topic Rebalance流程</strong></h2><p>单个Topic的Rebalance流程，是在RebalanceImpl类的rebalanceByTopic方法中进行的，整体上可以分为4大步骤：</p><p>1、从namesrv获取messageQueue信息</p><p>2、从broker获取consumer信息</p><p>3、选择Rebalance策略</p><p>4、三者结合实现Rebalance操作</p><p>消费者在Rebalance时需要获得：Topic的队列信息和消费者组实例信息。</p><p><strong>对于队列信息：</strong></p><p>会从之前的缓存的Topic路由信息中获取；Topic路由信息会定时的进行更新。</p><p><strong>对于消费者组实例信息：</strong></p><p>前面我们提到过Broker通过ConsumerManager维护了所有的消费者信息，findConsumerIdList方法内部会会发送<strong>GET_CONSUMER_LIST_BY_GROUP</strong>给请求给任意一个Broker进行获取。</p><p>每个消费者是自己给自己分配，相当于存在多个大脑。那么如何保证分配结果的一致呢？通过以下两个手段来保证：</p><ul><li>对Topic队列，以及消费者各自进行排序</li><li>每个消费者需要使用相同的分配策略。</li></ul><p>尽管每个消费者是各自给自己分配，但是因为使用的相同的分配策略，定位从队列列表中哪个位置开始给自己分配，给自己分配多少个队列，从而保证最终分配结果的一致。</p><h2 id="出发时机"><a href="#出发时机" class="headerlink" title="出发时机"></a>出发时机</h2><p>简单地来说，RocketMQ有三个时机会触发负载均衡：</p><ol><li><p>启动的时候，会立即触发</p></li><li><p>有消费实例数量的变更的时候。broker在接受到消费者的心跳包的时候如果发现这个实例是新的实例的时候，会广播一个消费者数量变更的事件给所有消费者实例；同理，当发现一个消费者实例的连接断了，也会广播这样的一个事件</p></li><li><p>定期触发（默认20秒）。</p></li></ol><p>第一个时机很好理解。启动的时候，消费者需要需要知道自己要分配什么队列，所以要触发Rebalance。</p><p>第二个时机实际也很好理解。因为有实例的数量变更，所以分配的结果肯定也需要调整的，这时候就要广播给各消费者。</p><p>第三点定期触发的原因实际上是一个补偿机制，为了避免第二点广播的时候因为网络异常等原因丢失了重分配的信号，或者还有别的场景实际上也需要重新计算分配结果（例如队列的数量变化、权限变化），所以需要一个定时任务做补偿。</p><p>所以rocketMQ去中心化Reblance的机制，导致，负载均衡的这个实现原理，就会导致RocketMQ消息重复比一般的消息中间件概率要大，而且严重不少（消息是批量重复的）。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Rebalance是什么&quot;&gt;&lt;a href=&quot;#Rebalance是什么&quot; class=&quot;headerlink&quot; title=&quot;Rebalance是什么&quot;&gt;&lt;/a&gt;&lt;strong&gt;Rebalance是什么&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;Rebalance(再均衡
      
    
    </summary>
    
      <category term="技术" scheme="https://arvenseyz.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="消息队列" scheme="https://arvenseyz.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
</feed>
